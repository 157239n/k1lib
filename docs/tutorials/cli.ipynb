{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fadcdd7",
   "metadata": {},
   "source": [
    "# k1lib.bioinfo.cli module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c16610",
   "metadata": {},
   "source": [
    "This tutorial is for the basics of the `k1lib.bioinfo.cli` module (docs at https://k1lib.github.io/latest/bioinfo/cli.html). As a quick reminder, this module allows you to use common cli tools from the linux cli inside of Python. The idea for this module came across while I was reading over the [Biostar Handbook](https://www.biostarhandbook.com/). They used a lot of cli tools, but all of them are sort of weird, unintuitive, not powerful, and just painful to work with. That's why I made this module to move everything to regular Python.\n",
    "\n",
    "We're going to go over the multilanguage names dataset from a [PyTorch RNN tutorial](https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html). The data folder is at [../cli_name_languages](../cli_name_languages) btw. My advice is to read this along with the docs page, and see the sources of functions that you're interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acf0ff0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.jp-OutputArea-output pre {white-space: pre;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>div.output_area pre {white-space: pre;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from k1lib.imports import *\n",
    "from k1lib.bioinfo.cli import *\n",
    "import unicodedata, string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f4369f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['cli_name_languages/names/Korean.txt',\n",
       "  'cli_name_languages/names/Spanish.txt',\n",
       "  'cli_name_languages/names/Greek.txt'],\n",
       " 18)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "namesFolder = \"cli_name_languages/names\"\n",
    "nameFiles = glob.glob(f\"{namesFolder}/*.txt\")\n",
    "withBareNames = insertColumn(*(nameFiles | split(\"/\", -1) | split(\".\", 0))) | display(None)\n",
    "nameFiles[:3], len(nameFiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5e60da",
   "metadata": {},
   "source": [
    "So, we have 18 files in total. Let's look over a few of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a8e6c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ahn\n",
      "Baik\n",
      "Bang\n"
     ]
    }
   ],
   "source": [
    "cat(nameFiles[0]) | headOut(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e955408",
   "metadata": {},
   "source": [
    "You can also pipe the file name in btw, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7af682ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ahn\n",
      "Baik\n",
      "Bang\n"
     ]
    }
   ],
   "source": [
    "nameFiles[0] | cat() | headOut(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2257b9c6",
   "metadata": {},
   "source": [
    "Let's convert all unicode chars to regular ascii (taken from the PyTorch doc):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b7360bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = string.ascii_letters + \".,;'\"\n",
    "def unicodeToAscii(s, notIn=False):\n",
    "    if notIn: # debug case\n",
    "        return \"\".join(c for c in unicodedata.normalize(\"NFD\", s) if unicodedata.category(c) != \"Mn\" and c not in letters)\n",
    "    else: # \"right\" case\n",
    "        return \"\".join(c for c in unicodedata.normalize(\"NFD\", s) if unicodedata.category(c) != \"Mn\" and c in letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8776cc80",
   "metadata": {},
   "source": [
    "How many names in total across files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "347e2839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20074"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nameFiles | cats() | joinStreams() | shape(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91811b0c",
   "metadata": {},
   "source": [
    "How many names with weird unicode characters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92361e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19962          99%   \n",
      "47             0%    \n",
      "3              0%    \n",
      "21      -      0%    \n",
      "2       --     0%    \n",
      "1              0%    \n",
      "23             0%    \n",
      "1       /      0%    \n",
      "3       1      0%    \n",
      "9       ß      0%    \n",
      "1       ł      0%    \n",
      "1       :      0%    \n"
     ]
    }
   ],
   "source": [
    "def unicodes(): return nameFiles | cats() | joinStreams() | apply(partial(unicodeToAscii, notIn=True))\n",
    "unicodes() | count() | display(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc508a4",
   "metadata": {},
   "source": [
    "See over https://k1lib.github.io/latest/bioinfo/streams for more info about how stuff like `cats()` and `joinStreams()` work. Also, `partial` is a pretty awesome function I might add, look over it at [Python functools docs](https://docs.python.org/3/library/functools.html#functools.partial). There're lots of empty names here, so let's get rid of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9cfad0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21   -    55%   \n",
      "2    --   5%    \n",
      "1    /    3%    \n",
      "3    1    8%    \n",
      "9    ß    24%   \n",
      "1    ł    3%    \n",
      "1    :    3%    \n"
     ]
    }
   ],
   "source": [
    "unicodes() | strip() | ~isValue(\"\") | count() | display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e619b548",
   "metadata": {},
   "source": [
    "Here, we're just stripping white spaces at both ends of each name (`strip()`) and filters them out (`~isValue(\"\")`). The tilde `~` sign common in front of every filter functions effectively inverts the filter's condition. How many duplicate names are there in a file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ebd1f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Korean       94     \n",
      "Spanish      296    \n",
      "Greek        193    \n",
      "Irish        226    \n",
      "Scottish     100    \n",
      "Portuguese   74     \n",
      "Russian      9342   \n",
      "Czech        503    \n",
      "French       273    \n",
      "German       706    \n",
      "Japanese     990    \n",
      "Polish       138    \n",
      "Arabic       108    \n",
      "English      3668   \n",
      "Chinese      246    \n",
      "Dutch        286    \n",
      "Italian      701    \n",
      "Vietnamese   71     \n"
     ]
    }
   ],
   "source": [
    "nameFiles | cats() | (count() | ~isValue(\"1\", 0) | shape(0)).all() | tableFromList() | withBareNames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f3bda8",
   "metadata": {},
   "source": [
    "Okay yeah there's a lot. Let's see how many unique names (of each file) that appear in other files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0939ed1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18015, 17458]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nameFiles | cats() | toSet().all() | joinStreams() | (identity() & toSet()) | shape(0).all() | dereference()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa763c7e",
   "metadata": {},
   "source": [
    "Let's see what are the actual Korean names that appear in other files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ab1bdf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spanish                                                                                                                                   \n",
      "Greek                                                                                                                                     \n",
      "Irish                                                                                                                                     \n",
      "Scottish                                                                                                                                  \n",
      "Portuguese                                                                                                                                \n",
      "Russian      Li      Han                                                                                                                  \n",
      "Czech                                                                                                                                     \n",
      "French                                                                                                                                    \n",
      "German       Wang                                                                                                                         \n",
      "Japanese     Ko      Seo    Jo                                                                                                            \n",
      "Polish                                                                                                                                    \n",
      "Arabic                                                                                                                                    \n",
      "English      Wang    Yang   Moon   Lee    Chong   Chung                                                                                   \n",
      "Chinese      Chang   Woo    Chou   Wang   Yang    Koo     Han     Sun   You   Kang   Chin   Chu   Song   Yun   Hong   Chong   Chi   Yim   \n",
      "Dutch                                                                                                                                     \n",
      "Italian                                                                                                                                   \n",
      "Vietnamese   Ho      Kim    Han    Ha     Chu     Ma      Chung                                                                           \n"
     ]
    }
   ],
   "source": [
    "nameFiles | AA_(0) | ((cat() | infinite()) + cats()) | joinColumns() | intersection().all()\\\n",
    "| insertColumn(*list(nameFiles | split(\"/\", -1) | split(\".\", 0))[1:]) | display(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae907978",
   "metadata": {},
   "source": [
    "`cat() | infinite()`'s branch essentially creates `Iterator[File]`, and each `File` is actually just `Iterator[str]`. Result of `cats()` is also `Iterator[File]`. We want to place these 2 lists' elements on each row, so we can actually operate on them. `joinColumns()` will output `Iterator[(File, File)]`. First file is the Korean one, second file is every other file. `intersection()` will find the common names between the 2 files, and `insertColumn()` just to have some nice formatting.\n",
    "\n",
    "How about we do this for every file and record how many names in that that is in other files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21571e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Korean       37    \n",
      "Spanish      104   \n",
      "Greek        1     \n",
      "Irish        78    \n",
      "Scottish     115   \n",
      "Portuguese   57    \n",
      "Russian      74    \n",
      "Czech        41    \n",
      "French       102   \n",
      "German       148   \n",
      "Japanese     9     \n",
      "Polish       24    \n",
      "Arabic       5     \n",
      "English      381   \n",
      "Chinese      52    \n",
      "Dutch        58    \n",
      "Italian      54    \n",
      "Vietnamese   20    \n"
     ]
    }
   ],
   "source": [
    "analyze2Files = intersection() | shape(0) # takes 2 files, and squish them into 1 value\n",
    "analyze1Combo = ((cat() | infinite()) + cats()) | joinColumns() | analyze2Files.all() | toSum() # summing all common values\n",
    "nameFiles | AA_(None) | analyze1Combo.all() | tableFromList() | withBareNames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c55b26",
   "metadata": {},
   "source": [
    "Nice. Anyway, hope you are as thrilled as I am about this. Really complicated loops and whatnot can be explored quite quickly without actually writing any loops, and that helps with bringing down iteration time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6648868",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch, numpy as np, time, k1lib, math, matplotlib.pyplot as plt\n",
    "from k1lib import getFirst\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Callback:\n",
    "    \"\"\"Represents a callback. Define specific functions\n",
    "    inside to intercept certain parts of the training\n",
    "    loop. Can reference Learner's attrs directly\n",
    "    using `self` like this:\n",
    "    >>> self.opt # actually accessing Learner.opt, if `opt` is not defined\n",
    "    \n",
    "    You can also set Learner's attributes like this:\n",
    "    >>> self.learner.xb = self.xb[None]\n",
    "    This takes x batch of learner, unsqueeze it at\n",
    "    the 0 position, then sets the x batch again.\n",
    "    \n",
    "    Normally, you will define a subclass of this and\n",
    "    define specific intercept functions, but if you\n",
    "    want to create a throwaway callback, then do this:\n",
    "    >>> Callback().withCheckpoint(\"startRun\", lambda: print(\"start running\"))\"\"\"\n",
    "    def __init__(self, name=None): self.learner = None; self._cbs = None; self._name = name or self.__class__.__name__\n",
    "    def _injectCbs(self, cbs): self._cbs = cbs; return self\n",
    "    def _injectLearner(self, learner): self.learner = learner; return self\n",
    "    def __getattr__(self, attr):\n",
    "        if hasattr(self.learner, attr): return getattr(self.learner, attr)\n",
    "        else: raise AttributeError\n",
    "    def _repr_html_(self): return f\"Callback `<code>{self._name}</code>`\"\n",
    "    def withCheckpoint(self, checkpoint:str, f:callable): setattr(self, checkpoint, lambda: f(self)); return self\n",
    "    def detach(self):\n",
    "        \"\"\"Detaches from the parent Callbacks object.\n",
    "        Remember to save the Callback somewhere to\n",
    "        reference it if needed.\"\"\"\n",
    "        self._cbs.remove(self._name); return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Callbacks:\n",
    "    \"\"\"Can reference each individual callbacks directly\n",
    "    by the class name.\"\"\"\n",
    "    def __init__(self): self.cbs = []; self.learner = None; self.dict = {}\n",
    "    def injectLearner(self, learner):\n",
    "        \"\"\"Intended to be used by Learner only. Injects\n",
    "        into all callbacks and update learner's dict.\"\"\"\n",
    "        self.learner = learner; learner._updateCbsDict()\n",
    "        [cb._injectLearner(learner) for cb in self.cbs]; return self\n",
    "    def append(self, cb, name=None):\n",
    "        \"\"\"Adds a callback to the collection.\"\"\"\n",
    "        name = name or cb._name\n",
    "        if name in self.dict:\n",
    "            i = 0\n",
    "            while f\"{name}{i}\" in self.dict: i += 1\n",
    "            name = f\"{name}{i}\"\n",
    "        cb._name = name; self.dict[name] = cb; self.__dict__[name] = cb\n",
    "        self.cbs.append(cb._injectLearner(self.learner)._injectCbs(self))\n",
    "        if self.learner is not None: self.learner._updateCbsDict()\n",
    "        return self\n",
    "    def remove(self, name):\n",
    "        \"\"\"Removes a callback from the collection.\"\"\"\n",
    "        if name not in self.dict: return print(f\"Callback `{name}` not found\")\n",
    "        self.cbs.remove(self.dict[name]); del self.dict[name]; return self\n",
    "    def __call__(self, checkpoint, *args, **kwargs):\n",
    "        \"\"\"Intended to be used by Learner only to fire\n",
    "        off events.\"\"\"\n",
    "        output = False\n",
    "        for cb in self.cbs:\n",
    "            if hasattr(cb, checkpoint):\n",
    "                if getattr(cb, checkpoint)(*args, **kwargs) != None:\n",
    "                    output = True\n",
    "        return output\n",
    "    def __getattr__(self, attr):\n",
    "        if attr in self.dict: return self.dict[attr]\n",
    "        else: raise AttributeError\n",
    "    def _repr_html_(self): return f\"<pre>Callbacks:<ul>{''.join([f'<li>{cbName}</li>' for cbName in self.dict])}</ul></pre>\"\n",
    "    @staticmethod\n",
    "    def standard(advanced=True):\n",
    "        \"\"\"Standard callbacks. Include advanced callbacks\n",
    "        if `advanced` is True. They can impact performance,\n",
    "        so it's possible to switch them off.\"\"\"\n",
    "        cbs = Callbacks().withProgressBar().withLoss()\n",
    "        if advanced: cbs.withHookModule().withHookParam()\n",
    "        return cbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _withInspectLoss(self, f:callable):\n",
    "    \"\"\"Expected `f` to take in 1 float.\"\"\"\n",
    "    class InspectLoss(Callback):\n",
    "        def endLoss(self): f(self.loss.detach())\n",
    "    return self.append(InspectLoss())\n",
    "Callbacks.withInspectLoss = _withInspectLoss\n",
    "def _withCuda(self):\n",
    "    self.withModifyBatch(lambda xb, yb: (xb.cuda(), yb.cuda()))\n",
    "    class Cuda(Callback):\n",
    "        def startRun(self): self.model.cuda()\n",
    "    return self.append(Cuda())\n",
    "Callbacks.withCuda = _withCuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _withInspectBatch(self, f:callable):\n",
    "    \"\"\"Expected `f` to take in 2 tensors.\"\"\"\n",
    "    class InspectBatch(Callback):\n",
    "        def startBatch(self): f(self.xb, self.yb)\n",
    "    return self.append(InspectBatch())\n",
    "Callbacks.withInspectBatch = _withInspectBatch\n",
    "def _withModifyBatch(self, f:callable):\n",
    "    \"\"\"Modifies xb and yb on the fly. Expected `f`\n",
    "    to take in 2 tensors and return 2 tensors.\"\"\"\n",
    "    class ModifyBatch(Callback):\n",
    "        def startBatch(self): self.learner.xb, self.learner.yb = f(self.xb, self.yb)\n",
    "    return self.append(ModifyBatch())\n",
    "Callbacks.withModifyBatch = _withModifyBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _withInspectOutput(self, f:callable):\n",
    "    \"\"\"Expected `f` to take in 1 tensor.\"\"\"\n",
    "    class InspectOutput(Callback):\n",
    "        def endPass(self): f(self.y)\n",
    "    return self.append(InspectOutput())\n",
    "Callbacks.withInspectOutput = _withInspectOutput\n",
    "def _withModifyOutput(self, f:callable):\n",
    "    class ModifyOutput(Callback):\n",
    "        def endPass(self): self.learner.y = f(self.y)\n",
    "    return self.append(ModifyOutput())\n",
    "Callbacks.withModifyOutput = _withModifyOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _withProgressBar(self):\n",
    "    \"\"\"Displays the current progress, epoch and batch\n",
    "    while running.\"\"\"\n",
    "    class ProgressBar(Callback):\n",
    "        def startRun(self): self.startTime = time.time()\n",
    "        def startBatch(self):\n",
    "            self.elapsedTime = time.time() - self.startTime\n",
    "            self.learner.progress = (self.batch / self.nBatches + self.epoch) / self.epochs\n",
    "            print(f\"\\rProgress: {round(100 * self.progress)}%, epoch: {self.epoch}/{self.epochs}, batch: {self.batch}/{self.nBatches}, elapsed: {np.round(self.elapsedTime, 2)}s         \", end=\"\")\n",
    "    return self.append(ProgressBar())\n",
    "Callbacks.withProgressBar = _withProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_docsLoss = \"\"\"\n",
    "Records losses after each batch.\n",
    "\n",
    "Methods:\n",
    "- Loss.plot()\n",
    "- Loss.epoch.plot()\n",
    "\n",
    "Fields:\n",
    "- Loss.train\n",
    "- Loss.valid\n",
    "- Loss.epoch.train\n",
    "- Loss.epoch.valid\"\"\"\n",
    "def _withLoss(self):\n",
    "    def nonEmptyList(_list): return [0] if _list == [] else _list\n",
    "    class Loss(Callback):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            def _plotStuff(obj):\n",
    "                plt.figure(figsize=(10, 3), dpi=100)\n",
    "                plt.subplot(1, 2, 1); plt.plot(obj.train); plt.title(\"Train loss\")\n",
    "                plt.subplot(1, 2, 2); plt.plot(obj.valid); plt.title(\"Valid loss\"); plt.show()\n",
    "            self.train = []; self.valid = [] # all stats all times\n",
    "            self.epoch = k1lib.Object.fromDict({\"train\": [], \"valid\": []}) # average stats for each epoch\n",
    "            self.plot = partial(_plotStuff, self); self.epoch.plot = partial(_plotStuff, self.epoch)\n",
    "            self._trainLosses = []; self._validLosses = []\n",
    "        def endLoss(self):\n",
    "            if self.model.training:\n",
    "                self._trainLosses.append(self.loss/self.xb.shape[0])\n",
    "            else: self._validLosses.append(self.loss/self.xb.shape[0])\n",
    "        def endEpoch(self):\n",
    "            self.train.extend(self._trainLosses); self.epoch.train.append(np.mean(nonEmptyList(self._trainLosses)))\n",
    "            self.valid.extend(self._validLosses); self.epoch.valid.append(np.mean(nonEmptyList(self._validLosses)))\n",
    "            self._trainLosses = []; self._validLosses = []\n",
    "    Loss.__doc__ = _docsLoss; return self.append(Loss())\n",
    "_withLoss.__doc__ = _docsLoss; Callbacks.withLoss = _withLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _withParamFinder(self, param=\"lr\"):\n",
    "    \"\"\"Automatically finds out the right value for\n",
    "    a specific parameter\"\"\"\n",
    "    class ParamFinder(Callback):\n",
    "        def __init__(self, param):\n",
    "            self.exps = np.linspace(-6, 2, 50); self.values = 10**self.exps; self.idx = 0\n",
    "            self.bestLoss = 1e9; self.param = param; self.losses = []\n",
    "        def startBatch(self):\n",
    "            if self.idx >= len(self.exps): raise k1lib.CancelRunException\n",
    "            for paramGroup in self.opt.param_groups: paramGroup[self.param] = self.values[self.idx]\n",
    "            self.idx += 1\n",
    "        def endLoss(self):\n",
    "            loss = self.loss/self.xb.shape[0]\n",
    "            if loss < self.bestLoss: self.bestLoss = loss\n",
    "            if loss > self.bestLoss * 10: raise k1lib.CancelRunException\n",
    "            self.losses.append(loss)\n",
    "        def run(self): self.learner.run(10); self.plot(); return self\n",
    "        def plot(self):\n",
    "            if len(self.losses) == 0: print(\"Has not run param finder yet.\")\n",
    "            else:\n",
    "                plt.plot(self.values[:len(self.losses)], self.losses)\n",
    "                plt.xscale(\"log\"); plt.xlabel(self.param); plt.ylabel(\"Loss\"); plt.show()\n",
    "    return self.append(ParamFinder(param))\n",
    "Callbacks.withParamFinder = _withParamFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_docsHookModule=\"\"\"\n",
    "Records means and std of output of individual\n",
    "modules on both forward and backward pass. Erases\n",
    "info before each run.\n",
    "\n",
    "Can pass through additional forward and backward\n",
    "callbacks. There are several methods for that:\n",
    "    .withForwardHook(). This literally just appends the\n",
    "        hook to the variable `.forwardFns`\n",
    "    .withBackwardHook(). This literally just appends the\n",
    "        hook to the variable `.backwardFns`\n",
    "    .withHook(). Just calls the 2 functions above\n",
    "\n",
    "You can manipulate `.forwardFns` and `.backwardFns`\n",
    "directly. But if you need quality of life stuff, here\n",
    "are more methods:\n",
    "    .clearHooks()\n",
    "\n",
    "After a learner is created and bound with a Callbacks,\n",
    "you can add a hook like this:\n",
    ">>> learner.HookModule.withMeanRecorder()\n",
    "\n",
    "There are a few built in hooks that you can check out:\n",
    "    .withMeanRecorder()\n",
    "    .withStdRecorder()\n",
    "    .withMinRecorder()\n",
    "    .withMaxRecorder()\n",
    "    .withHistRecorder()\n",
    "\n",
    "By default, this will analyze `learner.model`, but\n",
    "you can change that like this:\n",
    ">>> learner.HookModule.module = <intended nn.Module object>\n",
    "\n",
    "After a run, you can access a module's data by exploring these:\n",
    ">>> learner.HookModule[i].forward.<field>\n",
    ">>> learner.HookModule[i].backward.<field>\n",
    "`<field>` is any field you pass to `data` in the hook\n",
    "you passed to `.withHook`\n",
    "\n",
    "If your field is just a simple list of numbers, you\n",
    "can plot all values in all modules using `.plot()`:\n",
    ">>> learner.HookModule.plot()\"\"\"\n",
    "def _withHookModule(self):\n",
    "    def hook(fns, *args): [fn(*args) for fn in fns]\n",
    "    class HookModule(Callback):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self._handles = [] # the hook handles returned by pytorch at startRun, so that \n",
    "            self._moduleDatas = []; self._moduleNames = []\n",
    "            self.forwardFns = []; self.backwardFns = [] # lsit of forward and backward hooks\n",
    "            self.cleanFns = []; self._module = None\n",
    "        def withForwardHook(self, hook:callable, name=None):\n",
    "            \"\"\"Adds a hook to the forward pass. See `.withHook()` for more information\"\"\"\n",
    "            hook.name = name; self.forwardFns += [hook]; return self\n",
    "        def withBackwardHook(self, hook:callable, name=None):\n",
    "            \"\"\"Adds a hook to the backward pass. See `.withHook()` for more information\"\"\"\n",
    "            hook.name = name; self.backwardFns += [hook]; return self\n",
    "        def withHook(self, hook:callable, name=None):\n",
    "            \"\"\"Adds a hook to both the forward and backward pass.\n",
    "            Params:\n",
    "                `hook` function is expected to take in these parameters: (data, module, inp, out)\n",
    "                    data: the injected dependency for you to store stuff.\n",
    "                        Initially, `data` is an empty object, so you have to\n",
    "                        check whether it has your field like so:\n",
    "                        >>> if not hasattr(data, \"min\"): data.min = float(\"inf\")\n",
    "                        >>> data.min = torch.min(data.min, out)\n",
    "\n",
    "                        If you do not do this, then undefined variables will\n",
    "                        automatically be an empty list, so that this is fine:\n",
    "                        >>> data.max.append() # okay\n",
    "\n",
    "                        Later on, you can do things like:\n",
    "                        >>> HookModule[i].forward.min\n",
    "                        and get the data you saved from the hook.\n",
    "                    module: the module this function hooks into. Please\n",
    "                        refer to `torch.nn.Module.register_forward_hook()` to\n",
    "                        know more.\n",
    "                    inp: input (or grad of input) to the module\n",
    "                    out: output (or grad of output) to the module\n",
    "                `name`: custom name for the function for nice displaying\n",
    "            \"\"\"\n",
    "            return self.withForwardHook(hook, name).withBackwardHook(hook, name)\n",
    "        def clearHooks(self): self.forwardFns = []; self.backwardFns = []; self.cleanFns = []; return self\n",
    "        def withModule(self, module): self._module = module; return self\n",
    "        @property\n",
    "        def module(self): return self._module or self.model\n",
    "        @module.setter\n",
    "        def module(self, module): self._module = module\n",
    "        def withMeanRecorder(self): return self.withHook(lambda data, m, inp, out: data.means.append(getFirst(out).data.mean().item()), \"mean\")\n",
    "        def withStdRecorder(self): return self.withHook(lambda data, m, inp, out: data.stds.append(getFirst(out).data.std().item()), \"std\")\n",
    "        def withMinRecorder(self): return self.withHook(lambda data, m, inp, out: data.mins.append(getFirst(out).data.min().item()), \"min\")\n",
    "        def withMaxRecorder(self): return self.withHook(lambda data, m, inp, out: data.maxs.append(getFirst(out).data.max().item()), \"max\")\n",
    "        def withHistRecorder(self, bounds=[-50, 50], bins:int=100, fieldName:str=\"hist\"):\n",
    "            \"\"\"Records a histogram of the output and places in\n",
    "            data.`fieldName`. If you want multiple recordings,\n",
    "            you have to use different `fieldName`s.\n",
    "            \n",
    "            `bounds` and `bins` are just fields passed to `torch.histc()`.\n",
    "            \n",
    "            A good use case for multiple field names may be:\n",
    "            >>> .withHistRecorder(bounds=[-50, 50], \"histWide\")\n",
    "            >>> .withHistRecorder(bounds=[-5, 5], \"histNarrow\")\"\"\"\n",
    "            def cleanPart(data):\n",
    "                hists = getattr(data, fieldName)\n",
    "                if len(hists) == 0: return\n",
    "                setattr(data, f\"{fieldName}Img\", torch.stack(hists).T)\n",
    "            self.cleanFns.append(lambda forwardData, backwardData: (cleanPart(forwardData), cleanPart(backwardData)))\n",
    "            hook = lambda data, m, inp, out: getattr(data, fieldName).append(k1lib.getFirst(out).data.histc(bins, *bounds))\n",
    "            return self.withHook(hook, fieldName)\n",
    "        def plotHist(self, fieldName:str=\"hist\"):\n",
    "            \"\"\"Plots the recorded histogram with a `fieldName`\n",
    "            specified in `.withHistRecorder()`.\"\"\"\n",
    "            def _plot(objF):\n",
    "                n = len(self); plt.figure(dpi=100, figsize=(10, math.ceil(n/4) * 2))\n",
    "                for i, (data, name) in enumerate(zip(self, self._moduleNames)):\n",
    "                    plt.subplot(math.ceil(n/4), 4, i+1); plt.title(f\"{i}.{name}\"); plt.axis(\"off\")\n",
    "                    try: plt.imshow(getattr(objF(data), f\"{fieldName}Img\"))\n",
    "                    except: pass\n",
    "                plt.show()\n",
    "            print(\"Forward\"); _plot(lambda data: data.forward); print(\"Backward\"); _plot(lambda data: data.backward)\n",
    "        def plotHistRatio(self, _slice:slice=slice(49, 51), fieldName=\"hist\"):\n",
    "            \"\"\"Plots how much elements are in a certain bin\n",
    "            `_slice` compared to every slice. This may be\n",
    "            useful in determining if the gradients stay at\n",
    "            0 too much.\"\"\"\n",
    "            def _plot(objF):\n",
    "                n = len(self); plt.figure(dpi=100, figsize=(10, math.ceil(n/4) * 2))\n",
    "                for i, (data, name) in enumerate(zip(self, self._moduleNames)):\n",
    "                    plt.subplot(math.ceil(n/4), 4, i+1); plt.title(f\"{i}.{name}\")\n",
    "                    try: a = getattr(objF(data), f\"{fieldName}Img\"); plt.ylim(0, 1); plt.xticks([], []); plt.yticks([], []); plt.plot(a[_slice].sum(dim=0) / a.sum(dim=0))\n",
    "                    except: pass\n",
    "                plt.show()\n",
    "            print(\"Forward\"); _plot(lambda data: data.forward); print(\"Backward\"); _plot(lambda data: data.backward)\n",
    "        def startRun(self):\n",
    "            self._moduleDatas = []; self._moduleNames = []; self._handles = []\n",
    "            for idx, module in enumerate(self.module):\n",
    "                data = k1lib.Object.fromDict({\"forward\": k1lib.Object().withAutoDeclare(lambda: []),\n",
    "                                             \"backward\": k1lib.Object().withAutoDeclare(lambda: []),\n",
    "                                             \"name\": module.__class__.__name__})\n",
    "                self._moduleDatas.append(data); self._moduleNames.append(module.__class__.__name__)\n",
    "                self._handles.append(module.register_forward_hook(partial(hook, self.forwardFns, data.forward)))\n",
    "                self._handles.append(module.register_backward_hook(partial(hook, self.backwardFns, data.backward)))\n",
    "        def endRun(self):\n",
    "            for moduleData in self._moduleDatas:\n",
    "                for cleanFn in self.cleanFns:\n",
    "                    cleanFn(moduleData.forward, moduleData.backward)\n",
    "            for handle in self._handles:\n",
    "                handle.remove()\n",
    "        def __getitem__(self, idx): return self._moduleDatas[idx]\n",
    "        def __len__(self): return len(self._moduleDatas)\n",
    "        def _repr_html_(self):\n",
    "            f = f\"<ul>{''.join([f'<li>{fn.name or str(fn)}</li>' for fn in self.forwardFns])}</ul>\"\n",
    "            b = f\"<ul>{''.join([f'<li>{fn.name or str(fn)}</li>' for fn in self.backwardFns])}</ul>\"\n",
    "            #s = f\", {len(self[0].forward.means)} means and stds each\" if len(self) > 0 else \"\"\n",
    "            n = f\"<ol start='0'>{''.join([f'<li><code>{name}</code></li>' for name in self._moduleNames])}</ol>\"\n",
    "            return f\"{super()._repr_html_()}: {len(self)} modules:{n}Forward hooks:{f}Backward hooks:{b}\"\n",
    "        def plot(self, fields=[\"means\", \"stds\"], _slice:slice=slice(None, None, None), logScale:bool=False):\n",
    "            logScale = \"log\" if logScale else \"linear\"\n",
    "            def _plot(i, objF, title):\n",
    "                plt.subplot(len(fields), 2, i)\n",
    "                for module in self: obj = objF(module); plt.plot(range(len(obj))[_slice], obj[_slice])\n",
    "                plt.title(title); plt.yscale(logScale)\n",
    "            plt.figure(figsize=(10, 3*len(fields)), dpi=100)\n",
    "            for i, field in enumerate(fields):\n",
    "                _plot(i*2+1, lambda m: getattr(m.forward, field), f\"Forward {field}\")\n",
    "                _plot(i*2+2, lambda m: getattr(m.backward, field), f\"Backward {field}\")\n",
    "            plt.figlegend(self._moduleNames, loc='center right'); plt.show()\n",
    "    HookModule.__doc__ = _docsHookModule; return self.append(HookModule().withMeanRecorder().withStdRecorder())\n",
    "_withHookModule.__doc__ = _docsHookModule; Callbacks.withHookModule = _withHookModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_docsHookParam=\"\"\"\n",
    "Records means and stds of all parameters.\n",
    "\n",
    "Methods:\n",
    "- HookParam.plot()\n",
    "\n",
    "Fields:\n",
    "- HookParam[i].means\n",
    "- HookParam[i].stds\"\"\"\n",
    "def _withHookParam(self):\n",
    "    class HookParam(Callback, k1lib.ListContainer):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self._setField(\"_parameterDatas\"); self._parameters = []; self._paramNames = []\n",
    "        def startRun(self):\n",
    "            self._parameters = list(self.model.parameters())\n",
    "            self._parameterDatas = [k1lib.Object.fromDict({\"means\": [], \"stds\": []}) for param in self._parameters]\n",
    "            self._paramNames = [param[0] for param in self.model.named_parameters()]\n",
    "        def startBatch(self):\n",
    "            for data, param in zip(self._parameterDatas, self._parameters):\n",
    "                data.means.append(param.detach().mean().item())\n",
    "                data.stds.append(param.detach().std().item())\n",
    "        def _repr_html_(self):\n",
    "            s = f\", {len(self[0].means)} means and stds each\" if len(self) > 0 else \"\"\n",
    "            names = \"\".join([f\"<li><code>{name}</code></li>\" for name in self._paramNames])\n",
    "            return f\"{super()._repr_html_()}: {len(self)} params{s}:<ol start='0'>{names}</ol>\"\n",
    "        def plot(self, _slice:slice=slice(None, None, None), logScale=False):\n",
    "            logScale = \"log\" if logScale else \"linear\"\n",
    "            def _plot(i, objF, title):\n",
    "                plt.subplot(1, 2, i)\n",
    "                for m in self: obj = objF(m); plt.plot(range(len(obj))[_slice], obj[_slice])\n",
    "                plt.title(title); plt.yscale(logScale)\n",
    "            plt.figure(figsize=(10, 3), dpi=100); _plot(1, lambda m: m.means, \"Means\"); _plot(2, lambda m: m.stds, \"Stds\")\n",
    "            plt.figlegend(self._paramNames, loc='right'); plt.show()\n",
    "    HookParam.__doc__ = _docsHookParam; return self.append(HookParam())\n",
    "_withHookParam.__doc__ = _docsHookParam; Callbacks.withHookParam = _withHookParam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kelvin/repos/labs/k1lib/k1lib\n",
      "Current dir: 0, /home/kelvin/repos/labs/k1lib/export.py\n",
      "File: /home/kelvin/repos/labs/k1lib/k1lib/callbacks.py\n",
      "running bdist_wheel\n",
      "running build\n",
      "installing to build/bdist.linux-x86_64/wheel\n",
      "running install\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "writing k1lib.egg-info/PKG-INFO\n",
      "writing dependency_links to k1lib.egg-info/dependency_links.txt\n",
      "writing top-level names to k1lib.egg-info/top_level.txt\n",
      "reading manifest file 'k1lib.egg-info/SOURCES.txt'\n",
      "writing manifest file 'k1lib.egg-info/SOURCES.txt'\n",
      "Copying k1lib.egg-info to build/bdist.linux-x86_64/wheel/k1lib-0.1.0-py3.8.egg-info\n",
      "running install_scripts\n",
      "creating build/bdist.linux-x86_64/wheel/k1lib-0.1.0.dist-info/WHEEL\n",
      "creating 'dist/k1lib-0.1.0-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
      "adding 'k1lib-0.1.0.dist-info/METADATA'\n",
      "adding 'k1lib-0.1.0.dist-info/WHEEL'\n",
      "adding 'k1lib-0.1.0.dist-info/top_level.txt'\n",
      "adding 'k1lib-0.1.0.dist-info/RECORD'\n",
      "removing build/bdist.linux-x86_64/wheel\n",
      "Processing /home/kelvin/repos/labs/k1lib/dist/k1lib-0.1.0-py3-none-any.whl\n",
      "Installing collected packages: k1lib\n",
      "  Attempting uninstall: k1lib\n",
      "    Found existing installation: k1lib 0.1.0\n",
      "    Uninstalling k1lib-0.1.0:\n",
      "      Successfully uninstalled k1lib-0.1.0\n",
      "Successfully installed k1lib-0.1.0\n"
     ]
    }
   ],
   "source": [
    "!exportnb callbacks.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs = Callbacks.standard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-1929f8a88833>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcbs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProgressBar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr_html_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-44-2e5ce7b3429b>\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mCallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \"\"\"Can reference each individual callbacks directly\n",
      "\u001b[0;31mAttributeError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cbs.ProgressBar._repr_html_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Callbacks at 0x7f0ededeef90>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbs.withProgressBar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    def __init__(self): pass\n",
    "    def fa(self, x): return x + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fb(self, x): return x + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.fb = fb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = A()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.fb(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

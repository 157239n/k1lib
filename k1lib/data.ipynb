{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch, math, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Sampler:\n",
    "    def __init__(self, dataset, batchSize:int):\n",
    "        \"\"\"\n",
    "        Creates a random sampler. `dataset` expected to have __len__() and __getitem__() defined.\n",
    "        \n",
    "        Basically, when given a dataset with length n and batch size, this will split\n",
    "        things up into n/batchSize batches. Then, when indexed by an integer, this will return a range of the dataset\n",
    "        \"\"\"\n",
    "        n = len(dataset)\n",
    "        self.dataset = dataset\n",
    "        self.nBatches = math.ceil(n / batchSize)\n",
    "        self.batchSize = batchSize\n",
    "        self.idxs = np.random.permutation(n)\n",
    "    def __len__(self):\n",
    "        return self.nBatches\n",
    "    def __getitem__(self, i):\n",
    "        items = self.idxs[i*self.batchSize:(i+1)*self.batchSize]\n",
    "        return torch.Tensor([self.dataset[item] for item in items]).T\n",
    "    def __iter__(self):\n",
    "        return (self[i] for i in range(self.nBatches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DataLoader:\n",
    "    \"\"\"\n",
    "    Represents a data loader, meaning can do stuff like:\n",
    "    \n",
    "    >>> for xb in xDataLoader:\n",
    "    >>>     # do something\n",
    "    \"\"\"\n",
    "    def __init__(self, fGenerator:callable, length:int): self.fGenerator = fGenerator; self.length = length\n",
    "    def __call__(self): return self.fGenerator()\n",
    "    def __len__(self): return self.length\n",
    "    def __iter__(self):\n",
    "        for elem in self.fGenerator(): yield elem\n",
    "class Data:\n",
    "    \"\"\"Just a shell, containing 2 DataLoaders, `train` and `valid`\"\"\"\n",
    "    def __init__(self, train:DataLoader, valid:DataLoader):\n",
    "        \"\"\"Expecting train and valid to each return a generator when called upon\"\"\"\n",
    "        self.train = train; self.valid = valid\n",
    "    @staticmethod\n",
    "    def fromDataset(dataset, batchSize, trainSplit=0.8):\n",
    "        sampler = Sampler(dataset, batchSize); numBatches = len(sampler)\n",
    "        trainRange = range(math.ceil(trainSplit * numBatches))\n",
    "        testRange = range(math.ceil(trainSplit * numBatches), numBatches)\n",
    "        def common(_range):\n",
    "            return DataLoader(lambda: (sampler[idx] for idx in _range), len(_range))\n",
    "        return Data(common(trainRange), common(testRange))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kelvin/repos/labs/k1lib/k1lib\n",
      "Current dir: 0, /home/kelvin/repos/labs/k1lib/export.py\n",
      "File: /home/kelvin/repos/labs/k1lib/k1lib/data.py\n",
      "running bdist_wheel\n",
      "running build\n",
      "installing to build/bdist.linux-x86_64/wheel\n",
      "running install\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "writing k1lib.egg-info/PKG-INFO\n",
      "writing dependency_links to k1lib.egg-info/dependency_links.txt\n",
      "writing top-level names to k1lib.egg-info/top_level.txt\n",
      "reading manifest file 'k1lib.egg-info/SOURCES.txt'\n",
      "writing manifest file 'k1lib.egg-info/SOURCES.txt'\n",
      "Copying k1lib.egg-info to build/bdist.linux-x86_64/wheel/k1lib-0.1.0-py3.8.egg-info\n",
      "running install_scripts\n",
      "creating build/bdist.linux-x86_64/wheel/k1lib-0.1.0.dist-info/WHEEL\n",
      "creating 'dist/k1lib-0.1.0-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
      "adding 'k1lib-0.1.0.dist-info/METADATA'\n",
      "adding 'k1lib-0.1.0.dist-info/WHEEL'\n",
      "adding 'k1lib-0.1.0.dist-info/top_level.txt'\n",
      "adding 'k1lib-0.1.0.dist-info/RECORD'\n",
      "removing build/bdist.linux-x86_64/wheel\n",
      "Processing /home/kelvin/repos/labs/k1lib/dist/k1lib-0.1.0-py3-none-any.whl\n",
      "Installing collected packages: k1lib\n",
      "  Attempting uninstall: k1lib\n",
      "    Found existing installation: k1lib 0.1.0\n",
      "    Uninstalling k1lib-0.1.0:\n",
      "      Successfully uninstalled k1lib-0.1.0\n",
      "Successfully installed k1lib-0.1.0\n"
     ]
    }
   ],
   "source": [
    "!exportnb data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

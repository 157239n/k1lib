{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "515bcbec-ee55-451c-a6be-c22bd1a8c543",
   "metadata": {},
   "source": [
    "Functionalities relating to applyCl. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a74db032-fa3f-4cdc-b530-8b0dae694d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from k1lib.imports import *\n",
    "def distributedInstall(): # installs the library in all nodes, should take 8-15s to complete\n",
    "    base = \"/home/kelvin/repos/labs/k1lib\"\n",
    "    applyCl.nodeIds(False) | applyCl.aS(lambda: None | cmd(f\"rm -rf {base} && mkdir -p {base}\") | deref()) | deref()\n",
    "    None | cmd(f\"cd {base} && ./distribute.sh\") | ignore()\n",
    "    with k1.captureStdout(True):\n",
    "        applyCl.nodeIds(False) | applyCl.aS(lambda: None | cmd(f\"cd {base} && unzip dist.pth && pip install .\") | deref()) | ignore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60275897-c754-446f-bbea-23f9d187def0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "distributedInstall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11dcc4ee-5cb3-46a3-8085-7d18a11240bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "__all__ = [\"dummy\"]\n",
    "def dummy():\n",
    "    \"\"\"Does nothing. Only here for you to checkout the source code\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9043c451-1e1c-4568-bceb-fa96c1fc7b47",
   "metadata": {},
   "source": [
    "# loadTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "165c2084-3b64-4616-a663-fba05bf3141a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "from k1lib.imports import *; import hashlib\n",
    "def hashF(msg:str) -> str: m = hashlib.sha256(); m.update(f\"{msg}\".encode()); return k1.encode(m.digest())\n",
    "def cpuHash() -> str: return None | cmd(\"lscpu\") | head() | join(\"\\n\") | aS(hashF)\n",
    "loadTestFn = \"~/.k1lib/applyCl_loadTest.pth\"\n",
    "def load_loadTest(): return cat(loadTestFn, False) | aS(dill.loads) if os.path.exists(os.path.expanduser(loadTestFn)) else dict()\n",
    "def good_loadTest(): # whether the underlying architecture has been load-tested before\n",
    "    obj = load_loadTest(); return None | applyCl.aS(lambda: cpuHash()) | cut(1) | ~inSet(obj) | shape(0) == 0\n",
    "def loadTestS(nodeId, cpus, hash_):\n",
    "    with k1.timer() as t1:\n",
    "        [nodeId]*cpus*4 | insertIdColumn(begin=False) | applyCl(lambda x: range(300_000_000) | toSum(), pre=True) | deref()\n",
    "    with k1.timer() as t2:\n",
    "        [nodeId]*cpus*4 | insertIdColumn(begin=False) | applyCl(lambda x: range(30_000_000) | apply(op()+2) | toSum(), pre=True) | deref()\n",
    "    return [nodeId, cpus, hash_, t1(), t2()]\n",
    "def loadTest():\n",
    "    data = None | applyCl.aS(lambda: [os.cpu_count(), cpuHash()] | deref()) | ~apply(lambda x,y: [x,*y]) | deref()\n",
    "    a = data | ~applyTh(loadTestS, timeout=3600) | deref()\n",
    "    alpha1, alpha2 = a | cut(1, 3, 4) | ~apply(lambda x,y,z: [y, z]) | transpose() | toMax().all() | deref()\n",
    "    obj = a | ~apply(lambda idx,cpu,h,t1,t2: [h, (alpha1/(t1), alpha2/(t2)) | toMean()]) | toDict() | deref()\n",
    "    obj | aS(dill.dumps) | file(loadTestFn)\n",
    "def loadTestGuard(guard=True, rounded=True): # returns Dict[nodeId, cpus]\n",
    "    if guard and not good_loadTest():\n",
    "        ans = input(\"\"\"applyCl has not load-tested your system yet, so running\n",
    "the requested operation might be unbalanced on the cluster (some\n",
    "nodes finish before others, wasting computational time). Would you\n",
    "like to perform a load test now? Should take 1-2 minutes. Y/n: \"\"\")\n",
    "        if ans.lower()[0] == \"y\": loadTest()\n",
    "    data = None | applyCl.aS(lambda: [cpuHash(), os.cpu_count()]) | apply(wrapList(), 0) | joinStreams().all() | deref() # List[nodeId, cpu hash, #cpus]\n",
    "    obj = {**data | cut(1, 2) | apply(\"1\", 1) | toDict(), **load_loadTest()}\n",
    "    return data | lookup(obj, 1) | ~apply(lambda nodeId,mul,cpu: [nodeId, mul*cpu | (aS(round) if rounded else iden())]) | toDict()\n",
    "def balancedNodeIds(): a = loadTestGuard().items(); return a | ~apply(lambda x,y: [x]*y) | joinStreams() | randomize(None) | repeatFrom() | randomize(a | cut(1) | toSum() | op()*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee66a92-20e0-4036-8932-26c3ee21b051",
   "metadata": {},
   "source": [
    "# balanceFolder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b104cdb-985f-464c-807b-9ff83e424bca",
   "metadata": {},
   "source": [
    "## Log scale file sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdfc571e-f0e8-4d75-bf7d-e98d1ffe96b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from k1lib.imports import *\n",
    "base = \"~/repos/labs/k1lib/k1lib/cli/test/applyCl.balance\"; #base = \"~/ssd2/test\"\n",
    "applyCl.cmd(f\"rm -r {base}\"); applyCl.cmd(f\"mkdir -p {base}\")\n",
    "torch.loglinspace(10, 1e5, 20).int() | apply(lambda x: \"x\"*x) | insertIdColumn() | ~apply(lambda idx, contents: contents | file(f\"{base}/{idx}.txt\")) | deref();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36810f9d-bf36-42d0-8964-910f3839ff45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "from k1lib.imports import *\n",
    "getFolderSize = ls() | filt(os.path.isdir).split() | apply(lambda x: x | (tryout(0) | getFolderSize)) + apply(os.path.getsize) | toSum().all() | toSum() | deref()\n",
    "getFilesInFolder = aS(os.walk) | cut(0, 2) | ungroup() | join(os.sep).all()\n",
    "def getIr(base): return None | applyCl.aS(lambda: ls(base) | iden() & apply(lambda x: x | (tryout(0) | (aS(os.path.getsize) if os.path.isfile(x) else getFolderSize))) | transpose() | deref()) | ungroup(False) | insertIdColumn(True) | deref()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7adda9d-7e3e-4e62-9cee-202fae5e866d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0,\n",
       "  '244f4e340443f74ab302822376195329f45858b65998b4a77f5f4732',\n",
       "  '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/15.txt',\n",
       "  14385],\n",
       " [1,\n",
       "  '244f4e340443f74ab302822376195329f45858b65998b4a77f5f4732',\n",
       "  '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/0.txt',\n",
       "  11]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir = getIr(base); ir | head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad964f4-d720-4f24-954c-217c3db6583b",
   "metadata": {},
   "source": [
    "ir = intermediate representation: `[id, node id, url, size]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c92ee22-ca70-41f0-ba67-1fbf31f81a0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def normalize(d):\n",
    "    d = d | deref(); s = d | cut(1) | toSum()\n",
    "    return d | apply(op()/s, 1) | sort(0, False) | deref()\n",
    "@lru_cache\n",
    "def statsCpu(nodeIds):\n",
    "    cpu = loadTestGuard(False).items() | inSet(nodeIds, 0) | sort(0, False) | deref()\n",
    "    cpuF = loadTestGuard(False).items() | inSet(nodeIds, 0) | aS(normalize); cpuF # \"cpuF\" = cpu fraction. List[nodeId, cpu fraction]\n",
    "    return [cpu, cpuF]\n",
    "@lru_cache\n",
    "def statsNodeId(): return applyCl.nodeIds()\n",
    "_statsS1 = statsNodeId() | apply(wrapList() | insert(0, False)) | toDict()\n",
    "def stats(ir, nodeIds):\n",
    "    cpu, cpuF = statsCpu(nodeIds)\n",
    "    # size fraction. List[nodeId, size fraction]\n",
    "    sizeF = normalize({**_statsS1, **ir | groupBy(1, True) | apply(cut(2) | toSum(), 1) | toDict()}.items()); sizeF\n",
    "    return *statsCpu(nodeIds), sizeF\n",
    "def scores(ir, nodeIds): cpu, cpuF, sizeF = stats(ir, nodeIds); return [cpuF, sizeF] | cut(1).all() | transpose() | ~apply(lambda c,s: s-c) | deref() # negpos\n",
    "def score(ir, nodeIds): return scores(ir, nodeIds) | apply(lambda x: abs(x)**2) | toSum() # pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31e57140-c03a-4d30-834a-9f259c5ebd1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def move(ir, nA:str, nB:str, idx:int):\n",
    "    ir1 = ir | deref(); ir1[idx][1] = nB; a = ir1 | pretty() | join('\\n'); return ir1\n",
    "def optimize(ir, nodeIds):\n",
    "    cpu, cpuF, sizeF = stats(ir, nodeIds); scs = scores(ir, nodeIds); a = np.argmax(scs); b = np.argmin(scs)\n",
    "    # print(scs, a, b)\n",
    "    nodeIds = nodeIds | sort(None, False) | deref()\n",
    "    files = {**nodeIds | apply(wrapList() | insert([], False)) | toDict(), **ir | groupBy(1, True) | toDict()}.items() | sort(0, False) | deref()\n",
    "    fA = files[a]; fB = files[b] # files A. [nodeId, List[idx, url, size]]\n",
    "    # print(fA); print(fB)\n",
    "    nA = nodeIds[a]; nB = nodeIds[b] # A node id\n",
    "    sA, sB = [fA, fB] | apply(op()[1] | cut(2) | deref() | aS(np.array, dtype=int)) # file sizes A\n",
    "    # print(f\"sA: {sA} {sB}\")\n",
    "    spA = sA.sum() - sA; spB = sB.sum() + sA # sum prime A, array[files]\n",
    "    sp = spA + spB; sfA = spA/sp; sfB = spB/sp\n",
    "    cA = cpu[a][1]; cB = cpu[b][1] # cpu A\n",
    "    c = cA + cB; cfA = cA/c; cfB = cB/c # cpu fraction A\n",
    "    # print(f\"sfA: {sfA}, cfA: {cfA}\")\n",
    "    exp = 5 # intuition says that exp should be even. But that doesn't work. Odd values work tho, but I have no idea why\n",
    "    idx = fA[1][((sfA-cfA)**exp + (sfB-cfB)**exp).argmin()][0]\n",
    "    ir2 = move(ir, nA, nB, idx)\n",
    "    return ir2, [nA, nB, idx, score(ir2, nodeIds | aS(tuple))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "17cbfb4b-c426-42b0-b8d1-8af8d027163f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def traj(ir, maxSteps=20, nodeIds=None):\n",
    "    sc = score(ir, nodeIds); aux = None; auxs = []; irs = []\n",
    "    maxSteps = maxSteps if maxSteps is not None else int(1e10)\n",
    "    for i in range(maxSteps):\n",
    "        print(f\"\\rVirtually moving files and folders around. Step {i} of total max steps ({maxSteps})...\", end=\"\")\n",
    "        ir, aux = optimize(ir, nodeIds)\n",
    "        if aux[3] > sc: break\n",
    "        irs.append(ir); auxs.append(aux); sc = aux[3]\n",
    "    print(); return irs, auxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "507f43e0-a71c-4b84-9e20-9a7574a45c86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244f4e340443f74ab302822376195329f45858b65998b4a77f5f4732   1fee395d9c928cf2d816b99a7c6e08d297e6ed4a1fc90932a0d67e9b   0    1.0822664696035837    \n",
      "244f4e340443f74ab302822376195329f45858b65998b4a77f5f4732   1fee395d9c928cf2d816b99a7c6e08d297e6ed4a1fc90932a0d67e9b   1    1.0821433302210242    \n",
      "244f4e340443f74ab302822376195329f45858b65998b4a77f5f4732   1fee395d9c928cf2d816b99a7c6e08d297e6ed4a1fc90932a0d67e9b   8    0.257887409190956     \n",
      "244f4e340443f74ab302822376195329f45858b65998b4a77f5f4732   1fee395d9c928cf2d816b99a7c6e08d297e6ed4a1fc90932a0d67e9b   13   0.2563133261101207    \n",
      "244f4e340443f74ab302822376195329f45858b65998b4a77f5f4732   1fee395d9c928cf2d816b99a7c6e08d297e6ed4a1fc90932a0d67e9b   2    0.25219192530965784   \n",
      "244f4e340443f74ab302822376195329f45858b65998b4a77f5f4732   1fee395d9c928cf2d816b99a7c6e08d297e6ed4a1fc90932a0d67e9b   12   0.2496689609745758    \n",
      "244f4e340443f74ab302822376195329f45858b65998b4a77f5f4732   1fee395d9c928cf2d816b99a7c6e08d297e6ed4a1fc90932a0d67e9b   9    0.22218484728658494   \n",
      "244f4e340443f74ab302822376195329f45858b65998b4a77f5f4732   1fee395d9c928cf2d816b99a7c6e08d297e6ed4a1fc90932a0d67e9b   11   0.1813015496371873    \n",
      "244f4e340443f74ab302822376195329f45858b65998b4a77f5f4732   1fee395d9c928cf2d816b99a7c6e08d297e6ed4a1fc90932a0d67e9b   5    0.05864751172873886   \n",
      "244f4e340443f74ab302822376195329f45858b65998b4a77f5f4732   bb09a2d34473af60b2274afc49b5b7f8ee11255bd7faf58b48c89dd1   3    0.0559354490763192    \n",
      "244f4e340443f74ab302822376195329f45858b65998b4a77f5f4732   ef95788f939f2409d731d963c3ea9281aa1b42f3a091faebc42f65bc   6    0.05587803867853041   \n",
      "244f4e340443f74ab302822376195329f45858b65998b4a77f5f4732   ef95788f939f2409d731d963c3ea9281aa1b42f3a091faebc42f65bc   17   0.05160469784169362   \n",
      "244f4e340443f74ab302822376195329f45858b65998b4a77f5f4732   bb09a2d34473af60b2274afc49b5b7f8ee11255bd7faf58b48c89dd1   4    0.03868209440619509   \n"
     ]
    }
   ],
   "source": [
    "traj(ir, nodeIds=tuple(applyCl.nodeIds()))[1] | display(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2417959e-89c4-41c1-89b7-ae1eed49276b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def collapse(it):\n",
    "    a, b = it | rows(0, -1); c = [a[0], b[1], a[2], b[3]]\n",
    "    return [] if c[0] == c[1] else [c]\n",
    "def traj2(ir, traj): # just looks up the file names really, no processing involved\n",
    "    idx2FileName = ir | apply(lambda arr: [arr[0], arr[2]]) | toDict()\n",
    "    a = traj | groupBy(2) | filt(lambda x: len(x) > 1).split() | (apply(collapse)) + iden() | joinStreams(2) | deref()\n",
    "    return a | lookup(idx2FileName, 2) | deref()\n",
    "def moveFile(fileName:str, sourceNodeId:str, destNodeId:str, timeout=60): # old, slow, corrupted version\n",
    "    \"\"\"Moves file from the current node to the destination node. Usually executed on other nodes than the driver node\"\"\"\n",
    "    fn = os.path.expanduser(fileName); dirname = os.path.dirname(fn)\n",
    "    applyCl.cmd(f\"mkdir -p {dirname}\", nodeIds=[destNodeId]); applyCl.cmd(f\"rm -f {fn}\", nodeIds=[destNodeId])\n",
    "    for chunk in cat(fn, False, True): [destNodeId] | applyCl.aS(lambda: chunk >> file(fn), timeout=timeout) | deref()\n",
    "    None | cmd(f\"rm {fn}\") | deref(); return \"ok1\"\n",
    "def moveFile(fn:str, sourceN:str, destN:str, timeout=60): # runs on dest node\n",
    "    fn = os.path.expanduser(fn); dirname = os.path.dirname(fn)\n",
    "    windows = [sourceN] | applyCl.aS(lambda: range(os.path.getsize(fn)) | batched(settings.cli.cat.chunkSize, True) | apply(\"[x.start, x.stop]\") | deref()) | cut(1) | item() | deref()\n",
    "    for chunk in [[sourceN]*len(windows), windows] | transpose() | ~applyCl(lambda sB,eB: cat(fn, False, sB=sB, eB=eB), pre=True, prefetch=20) | cut(1): chunk >> file(fn)\n",
    "    [sourceN] | applyCl.aS(lambda: None | cmd(f\"rm {fn}\") | deref()) | deref()\n",
    "    return \"ok file\"\n",
    "def moveFF(ff:str, sourceN:str, destN:str, timeout=60): # runs on dest node\n",
    "    \"\"\"Moves file or folder from the current node to the destination node\"\"\"\n",
    "    ff = os.path.expanduser(ff); isfile = [sourceN] | applyCl.aS(lambda: os.path.isfile(ff)) | cut(1) | item()\n",
    "    if isfile: return moveFile(ff, sourceN, destN, timeout)\n",
    "    [sourceN] | applyCl.aS(lambda: ff | getFilesInFolder | deref()) | cut(1) | item() | apply(aS(moveFile, sourceN, destN, timeout)) | deref()\n",
    "    None | cmd(f\"rm -rf {ff}\") | ignore(); return f\"ok folder: {ff}\"\n",
    "def moveAll(tr, timeout=60):\n",
    "    groups = tr | groupBy(1) | deref() # grouping by destination\n",
    "    with ray.progress(len(groups), \"Moving files around\") as rp:\n",
    "        def process(idx, arrs): # processing requests for dest node\n",
    "            for i, arr in enumerate(arrs): # moveFF(fn, a, b)\n",
    "                [[arr[1], arr]] | ~applyCl(lambda a,b,fn,sc: moveFF(fn, a, b), pre=True, timeout=timeout) | deref() # move 1 file on dest node\n",
    "                rp.update.remote(idx, (i+1)/len(arrs))\n",
    "        groups | insertIdColumn() | ~applyTh(process, timeout=None) | deref()\n",
    "    # tr | apply(lambda arr: [arr[0], arr]) | ~applyCl(lambda a,b,fn,sc: moveFF(fn, b), pre=True, timeout=timeout) | deref() # old version without progress bar\n",
    "def balanceFolder(base, audit=False, maxSteps=1000, timeout=60): # currently executing each move step serially, will change in the future if it's too slow\n",
    "    loadTestGuard(); applyCl.cmd(f\"mkdir -p {base}\"); ir = getIr(base)\n",
    "    tr = traj2(ir, traj(ir, maxSteps, tuple(applyCl.nodeIds()))[1]); return tr if audit else moveAll(tr)\n",
    "def decommissionFolderTraj(base:str, nAs:List[str]): # nAs are the ones to decommission\n",
    "    ir = getIr(base); targetNodes = applyCl.nodeIds() | ~inSet(nAs) | repeatFrom(); irs = []; auxs = []\n",
    "    seis = ir | inSet(nAs, 1) | cut(0, 1) | ~apply(lambda idx, startNode: [startNode, next(targetNodes), idx, 0]) | deref() # List[start, end, index, score]\n",
    "    for sei in seis: ir = move(ir, *sei[:3]); irs.append(ir); auxs.append(sei)\n",
    "    return irs, auxs\n",
    "def decommissionFolder(base:str, nAs:List[str], audit=False, maxSteps=1000, timeout=60):\n",
    "    loadTestGuard(); irs, auxs = decommissionFolderTraj(base, nAs)\n",
    "    irs2, auxs2 = traj(irs[-1] if len(irs) > 0 else getIr(base), maxSteps, applyCl.nodeIds() | ~inSet(nAs) | aS(tuple))\n",
    "    irs = [*irs, *irs2]; auxs = [*auxs, *auxs2]\n",
    "    if len(irs) == 0: return\n",
    "    tr = traj2(irs[-1], auxs); return tr if audit else moveAll(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a9e26b15-e280-4996-ab40-64c52a5ed18a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "applyCl.cmd(f\"rm -r {base}\"); applyCl.cmd(f\"mkdir -p {base}\")\n",
    "torch.loglinspace(10, 1e5, 100).int() | apply(lambda x: \"x\"*x) | insertIdColumn() | ~apply(lambda idx, contents: contents | file(f\"{base}/{idx}.txt\")) | deref();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "576e9b31-8805-49c8-b267-25367cf7704e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1fee395d9c928cf2d816b99a7c6e08d297e6ed4a1fc90932a0d67e9b', 0],\n",
       " ['244f4e340443f74ab302822376195329f45858b65998b4a77f5f4732', 1125606],\n",
       " ['ef95788f939f2409d731d963c3ea9281aa1b42f3a091faebc42f65bc', 0],\n",
       " ['bb09a2d34473af60b2274afc49b5b7f8ee11255bd7faf58b48c89dd1', 0]]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "None | applyCl.aS(lambda: ls(base) | apply(os.path.getsize) | toSum()) | deref()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1f5107be-f5ef-4033-8b3c-5ca4ee3d9826",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "applyCl has not load-tested your system yet, so running\n",
      "the requested operation might be unbalanced on the cluster (some\n",
      "nodes finish before others, wasting computational time). Would you\n",
      "like to perform a load test now? Should take 1-2 minutes. Y/n:  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virtually moving files and folders around. Step 96 of total max steps (1000)...\n",
      "Moving files around: 100%, 3s elapsed         \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[['1fee395d9c928cf2d816b99a7c6e08d297e6ed4a1fc90932a0d67e9b', 781519],\n",
       "  ['244f4e340443f74ab302822376195329f45858b65998b4a77f5f4732', 198262],\n",
       "  ['ef95788f939f2409d731d963c3ea9281aa1b42f3a091faebc42f65bc', 83022],\n",
       "  ['bb09a2d34473af60b2274afc49b5b7f8ee11255bd7faf58b48c89dd1', 62803]],\n",
       " 1125606]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanceFolder(base, False, 1000)\n",
    "None | applyCl.aS(lambda: ls(base) | apply(os.path.getsize) | toSum()) | iden() & (cut(1) | toSum()) | deref()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b3b07bf9-a241-4f9e-8df9-91f89bbc86e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virtually moving files and folders around. Step 21 of total max steps (1000)...\n",
      "Moving files around: 100%, 2s elapsed         \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[['1fee395d9c928cf2d816b99a7c6e08d297e6ed4a1fc90932a0d67e9b', 950715],\n",
       "  ['244f4e340443f74ab302822376195329f45858b65998b4a77f5f4732', 237232],\n",
       "  ['ef95788f939f2409d731d963c3ea9281aa1b42f3a091faebc42f65bc', 83022],\n",
       "  ['bb09a2d34473af60b2274afc49b5b7f8ee11255bd7faf58b48c89dd1', 114944]],\n",
       " 1385913]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert None | applyCl.aS(lambda: ls(base) | apply(os.path.getsize) | toSum()) | cut(1) | toProd() > 0\n",
    "torch.loglinspace(10, 1e5, 20).int() | apply(lambda x: \"x\"*x) | insertIdColumn() | ~apply(lambda idx, contents: contents | file(f\"{base}/{idx+100}.txt\")) | deref();\n",
    "balanceFolder(base)\n",
    "assert None | applyCl.aS(lambda: ls(base) | apply(os.path.getsize) | toSum()) | cut(1) | toProd() > 0\n",
    "None | applyCl.aS(lambda: ls(base) | apply(os.path.getsize) | toSum()) | iden() & (cut(1) | toSum()) | deref()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "07278440-7300-4fe5-8bac-2c9a476cba47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virtually moving files and folders around. Step 999 of total max steps (1000)...\n",
      "Moving files around: 100% | 100%, 6s elapsed         \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[['1fee395d9c928cf2d816b99a7c6e08d297e6ed4a1fc90932a0d67e9b', 0],\n",
       "  ['244f4e340443f74ab302822376195329f45858b65998b4a77f5f4732', 0],\n",
       "  ['ef95788f939f2409d731d963c3ea9281aa1b42f3a091faebc42f65bc', 756348],\n",
       "  ['bb09a2d34473af60b2274afc49b5b7f8ee11255bd7faf58b48c89dd1', 629565]],\n",
       " 1385913]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decommissionFolder(base, applyCl.nodeIds()[:2])\n",
    "None | applyCl.aS(lambda: ls(base) | apply(os.path.getsize) | toSum()) | iden() & (cut(1) | toSum()) | deref()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cd487a-e6ad-4f52-abf2-366b29a2a442",
   "metadata": {},
   "source": [
    "## Files integrity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d35b37a-9079-498e-bb0a-1233f4663e85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    div.jp-OutputArea-output pre {white-space: pre;}\n",
       "    div.output_area pre {white-space: pre;}\n",
       "    div.CodeMirror > div.highlight {overflow-y: auto;}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 13:45:01,706\tINFO worker.py:1364 -- Connecting to existing Ray cluster at address: 192.168.1.35:6379...\n",
      "2023-05-24 13:45:01,710\tINFO worker.py:1544 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\u001b[2m\u001b[36m(<lambda> pid=590423, ip=192.168.1.57)\u001b[0m 2023-05-24 13:45:05,772\tINFO worker.py:1364 -- Connecting to existing Ray cluster at address: 192.168.1.35:6379...\n",
      "\u001b[2m\u001b[36m(<lambda> pid=269790, ip=192.168.1.53)\u001b[0m 2023-05-24 13:45:05,782\tINFO worker.py:1364 -- Connecting to existing Ray cluster at address: 192.168.1.35:6379...\n",
      "\u001b[2m\u001b[36m(<lambda> pid=3088074, ip=192.168.1.43)\u001b[0m 2023-05-24 13:45:05,816\tINFO worker.py:1364 -- Connecting to existing Ray cluster at address: 192.168.1.35:6379...\n",
      "\u001b[2m\u001b[36m(<lambda> pid=2576004)\u001b[0m 2023-05-24 13:45:05,930\tINFO worker.py:1364 -- Connecting to existing Ray cluster at address: 192.168.1.35:6379...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virtually moving files and folders around. Step 82 of total max steps (10000000000)...\n",
      "Moving files around: 100% | 100% | 100%, 63s elapsed         \r"
     ]
    }
   ],
   "source": [
    "from k1lib.imports import *\n",
    "base = \"~/ssd2/test\"; applyCl.cmd(f\"rm -rf {base}\"); None | cmd(f\"mkdir -p {base}\")\n",
    "def genBinary(size=1000): return None | cmd(f\"cat /dev/urandom | head -{size}\", text=False) | aS(b\"\".join)\n",
    "range(100) | apply(lambda i: genBinary(10000) | file(f\"{base}/{i}.pth\")) | deref();\n",
    "con1 = ls(base) | iden() & apply(cat(text=False)) | transpose() | deref() | sort(0, False) | deref() | aS(k1.Wrapper)\n",
    "applyCl.balanceFolder(base)\n",
    "con2 = None | applyCl.aS(lambda: ls(base) | iden() & apply(cat(text=False)) | transpose() | deref()) | cut(1) | joinStreams() | sort(0, False) | deref() | aS(k1.Wrapper)\n",
    "assert con1() == con2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "514e495f-4fb7-41bd-a8c0-edee8e1a231c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1fee395d9c928cf2d816b99a7c6e08d297e6ed4a1fc90932a0d67e9b', 371339],\n",
       " ['244f4e340443f74ab302822376195329f45858b65998b4a77f5f4732', 96900],\n",
       " ['ef95788f939f2409d731d963c3ea9281aa1b42f3a091faebc42f65bc', 36535],\n",
       " ['bb09a2d34473af60b2274afc49b5b7f8ee11255bd7faf58b48c89dd1', 36523]]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "None | applyCl.aS(lambda: ls(base) | apply(os.path.getsize) | toSum()) | deref()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b44f1f6-49b4-49a3-9b72-ed9b8690c369",
   "metadata": {},
   "source": [
    "## Linear scale file sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f9de969-7dc8-4f98-a671-8894946ddd72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['51306d246cd47ada0addf519f27c0d313953d20aa3fe9e2080f2bb0d', 521059],\n",
       " ['244f4e340443f74ab302822376195329f45858b65998b4a77f5f4732', 301581],\n",
       " ['ef95788f939f2409d731d963c3ea9281aa1b42f3a091faebc42f65bc', 124212],\n",
       " ['bb09a2d34473af60b2274afc49b5b7f8ee11255bd7faf58b48c89dd1', 153159]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = \"~/repos/labs/k1lib/k1lib/cli/test/applyCl.balance\"; #base = \"~/ssd2/test\"\n",
    "applyCl.cmd(f\"rm -r {base}\"); applyCl.cmd(f\"mkdir -p {base}\")\n",
    "torch.linspace(1e4, 1e5, 20).int() | apply(lambda x: \"x\"*x) | insertIdColumn() | ~apply(lambda idx, contents: contents | file(f\"{base}/{idx}.txt\")) | deref();\n",
    "balanceFolder(base); None | applyCl.aS(lambda: ls(base) | apply(os.path.getsize) | toSum()) | deref()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26bfb5fc-4707-4b88-ac38-a5bdfbda76ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['51306d246cd47ada0addf519f27c0d313953d20aa3fe9e2080f2bb0d', 1079484],\n",
       " ['244f4e340443f74ab302822376195329f45858b65998b4a77f5f4732', 580533],\n",
       " ['ef95788f939f2409d731d963c3ea9281aa1b42f3a091faebc42f65bc', 253161],\n",
       " ['bb09a2d34473af60b2274afc49b5b7f8ee11255bd7faf58b48c89dd1', 286844]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(1e4, 1e5, 20).int() | apply(lambda x: \"x\"*x) | insertIdColumn() | ~apply(lambda idx, contents: contents | file(f\"{base}/{idx+20}.txt\")) | deref();\n",
    "balanceFolder(base); None | applyCl.aS(lambda: ls(base) | apply(os.path.getsize) | toSum()) | deref()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f553dd87-ed9a-47d8-af80-676ebcebf0f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2200022"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "None | applyCl.aS(lambda: ls(base) | apply(os.path.getsize) | toSum()) | cut(1) | toSum() | deref()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a08245ef-c21a-4d35-853b-48ed51f4c95b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2200022)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(1e4, 1e5, 20).int() | toSum() | op()*2+40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7da17232-4917-4953-80df-da0938224c29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['51306d246cd47ada0addf519f27c0d313953d20aa3fe9e2080f2bb0d',\n",
       "  ['/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/23.txt',\n",
       "   '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/32.txt',\n",
       "   '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/12.txt',\n",
       "   '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/19.txt',\n",
       "   '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/2.txt',\n",
       "   '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/35.txt',\n",
       "   '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/0.txt',\n",
       "   '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/29.txt',\n",
       "   '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/6.txt',\n",
       "   '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/10.txt',\n",
       "   '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/36.txt',\n",
       "   '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/34.txt',\n",
       "   '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/18.txt',\n",
       "   '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/9.txt',\n",
       "   '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/15.txt',\n",
       "   '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/38.txt',\n",
       "   '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/14.txt']],\n",
       " ['244f4e340443f74ab302822376195329f45858b65998b4a77f5f4732',\n",
       "  ['/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/31.txt',\n",
       "   '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/33.txt',\n",
       "   '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/25.txt',\n",
       "   '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/30.txt',\n",
       "   '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/22.txt',\n",
       "   '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/13.txt',\n",
       "   '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/8.txt',\n",
       "   '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/20.txt',\n",
       "   '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/21.txt',\n",
       "   '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/1.txt',\n",
       "   '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/4.txt',\n",
       "   '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/11.txt',\n",
       "   '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/26.txt',\n",
       "   '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/28.txt']],\n",
       " ['ef95788f939f2409d731d963c3ea9281aa1b42f3a091faebc42f65bc',\n",
       "  ['/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/39.txt',\n",
       "   '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/17.txt',\n",
       "   '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/24.txt',\n",
       "   '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/5.txt']],\n",
       " ['bb09a2d34473af60b2274afc49b5b7f8ee11255bd7faf58b48c89dd1',\n",
       "  ['/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/37.txt',\n",
       "   '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/16.txt',\n",
       "   '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/3.txt',\n",
       "   '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/7.txt',\n",
       "   '/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.balance/27.txt']]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "None | applyCl.aS(lambda: ls(base)) | deref()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c5e33b-5728-40c6-b1c0-1d831abc0502",
   "metadata": {},
   "source": [
    "Looks about right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21499bfa-9e4a-4eb6-ba42-e7358e6f1136",
   "metadata": {},
   "source": [
    "# Advanced split file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c590e30-a27e-4847-b087-11fb976419d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    div.jp-OutputArea-output pre {white-space: pre;}\n",
       "    div.output_area pre {white-space: pre;}\n",
       "    div.CodeMirror > div.highlight {overflow-y: auto;}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 13:49:11,461\tINFO worker.py:1364 -- Connecting to existing Ray cluster at address: 192.168.1.35:6379...\n",
      "2023-05-15 13:49:11,480\tINFO worker.py:1544 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['867dc6c8f88045aa165af30a64125aee311f1f64a32f1c43c6ed4dc0', 110001],\n",
       " ['244f4e340443f74ab302822376195329f45858b65998b4a77f5f4732', 110001],\n",
       " ['4ffae9ae502fde1a76a7b54a0146c943be6d0ac9bba8f7c3e07fdb4d', 0]]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from k1lib.imports import *\n",
    "base = \"/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.advSplit\"\n",
    "fn = f\"{base}/a.txt\"\n",
    "def reset(n=10000):\n",
    "    applyCl.cmd(f\"rm -r {base}\"); applyCl.cmd(f\"mkdir -p {base}\")\n",
    "    applyCl.nodeIds() | head(2) | applyCl.aS(lambda: \"0123456789\\n\"*n | file(fn)) | deref()\n",
    "def status(): return None | applyCl.aS(lambda: fn | (tryout(0) | cat(text=False) | shape(0))) | deref()\n",
    "nodeIds = applyCl.nodeIds(); reset(); status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61b84f07-129f-4db3-8f46-8b8a933b747f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['867dc6c8f88045aa165af30a64125aee311f1f64a32f1c43c6ed4dc0', [0, 4567]],\n",
       " ['244f4e340443f74ab302822376195329f45858b65998b4a77f5f4732', [1234, 12345]]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nse = [applyCl.nodeIds()[:2], [0, 1234], [4567, 12345]] | transpose() | apply(lambda arr: [arr[0], arr[1:]]) | deref(); nse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82fe311a-ced7-4318-842c-072a48d3ea71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def a_transfer(fn, nse, nodeB, rpF:callable=iden()):\n",
    "    \"\"\"Transfers a lot of blocks from a bunch of nodes to nodeB. Does not delete from those node though\n",
    "\n",
    "nse = List[nodeAId, [sB, eB]]\n",
    "\n",
    "Runs on driver process, blocks, so better use applyTh outside of this\n",
    "\n",
    ":param rpF: ray progress function\"\"\"\n",
    "    blockSize = settings.cli.cat.chunkSize\n",
    "    def inner():\n",
    "        totalBytes = nse | cut(1) | ~apply(lambda x,y:y-x) | toSum(); currentByte = 0\n",
    "        for chunk in nse | ~apply(lambda x, y: range(x, y) | batched(blockSize, True) | apply(\"[x.start, x.stop]\"), 1) | ungroup() | deref()\\\n",
    "            | ~applyCl(lambda sB, eB: cat(fn, False, sB=sB, eB=eB), pre=True, timeout=None, prefetch=20) | cut(1):\n",
    "            chunk >> file(fn); currentByte += len(chunk); rpF(currentByte/totalBytes)\n",
    "    [nodeB] | applyCl.aS(inner, timeout=None) | item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adf1b6e1-67ba-4db8-b338-9b0a1852f025",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.8 ms, sys: 0 ns, total: 18.8 ms\n",
      "Wall time: 155 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reset()\n",
    "a_transfer(fn, nse, applyCl.nodeIds()[2])\n",
    "assert None | applyCl.aS(lambda: cat(fn, False) | shape(0)) | deref() | op()[2][1] == 4567+11111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dff96082-56bd-472c-b9be-0c64926a37a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def decommission(fn:str, nodeAs:List[str], nodeBs:List[str], rS):\n",
    "    \"\"\"Spreads out a particular file in nodeAs to all nodeBs, to prepare\n",
    "to decomission nodeAs. The 2 sets should be mutually exclusive\n",
    "\n",
    ":param rS: instance of refineSeek\"\"\"\n",
    "    nodeAs, nodeBs = [nodeAs, nodeBs] | deref()\n",
    "    if len(nodeAs) == 0: return\n",
    "    if len(nodeBs) == 0: raise Exception(\"Unsupported configuration! Trying to move data from A+B to C+D. Has to have some shared nodes, like moving data from A+B+C to B+C+D. This is not a fundamental limitation, but just can't be done with the current architecture. Might be fixed in the future.\")\n",
    "    # some initial metadata\n",
    "    nodeIds = applyCl.nodeIds(); nodeId_cpu = loadTestGuard(False).items() | deref(); nodeId2Cpu = nodeId_cpu | toDict()\n",
    "    ws = nodeId_cpu | inSet(nodeBs, 0) | cut(1) | deref() # weights to split files on nodeAs into\n",
    "    # splitting file on nodeAs into chunks first, to plan things out\n",
    "    a = nodeAs | applyCl.aS(lambda: fn | splitSeek(ws=ws) | rS | window(2) | deref() | insertColumn(nodeBs) | insert(applyCl.nodeId()).all() | deref()) | cut(1) | joinStreams() | deref()\n",
    "    # actually transferring chunks\n",
    "    with ray.progress(a | groupBy(1) | shape(0), \"Decommissioning\") as rp:\n",
    "        c = b = a | groupBy(1, True) | apply(iden() + apply(lambda arr: [arr[0], arr[1:]]) | reverse() | insert(fn)) | deref()\n",
    "        enumerate(c) | applyTh(~aS(lambda idx, e: a_transfer(*e, rpF=aS(lambda p: ray.get(rp.update.remote(idx, p))))), timeout=None) | deref()\n",
    "    # deleting files from nodeAs\n",
    "    nodeAs | applyCl.aS(lambda: None | cmd(f\"rm -rf {fn}\") | ignore()) | deref()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a975b0e6-7369-401a-a540-41c8f46ddc93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "867dc6c8f88045aa165af30a64125aee311f1f64a32f1c43c6ed4dc0   110001   \n",
      "244f4e340443f74ab302822376195329f45858b65998b4a77f5f4732   110001   \n",
      "4ffae9ae502fde1a76a7b54a0146c943be6d0ac9bba8f7c3e07fdb4d   0        \n",
      "Decommissioning: 100% | 100%\r"
     ]
    }
   ],
   "source": [
    "reset(); status() | display()\n",
    "decommission(fn, *applyCl.nodeIds() | splitW(1, 2))\n",
    "assert status() | ~head(1) | cut(1) | toProd() == 6723517725"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82c31c8f-4558-401e-b0da-7b048252232d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['867dc6c8f88045aa165af30a64125aee311f1f64a32f1c43c6ed4dc0', 0],\n",
       " ['244f4e340443f74ab302822376195329f45858b65998b4a77f5f4732', 183327],\n",
       " ['4ffae9ae502fde1a76a7b54a0146c943be6d0ac9bba8f7c3e07fdb4d', 36675]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0afd49f-1639-492d-9306-740c48239f22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nAs = [\"867dc6c8f88045aa165af30a64125aee311f1f64a32f1c43c6ed4dc0\", \"244f4e340443f74ab302822376195329f45858b65998b4a77f5f4732\"]\n",
    "nBs = [\"4ffae9ae502fde1a76a7b54a0146c943be6d0ac9bba8f7c3e07fdb4d\"]\n",
    "ns = [*nAs, *nBs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6f8fffe-4a29-4745-957d-361ea687c3bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "ranges2Seeks = apply(\"[x.start, x.stop]\") | joinStreams() | aS(set) | sort(None) | deref()\n",
    "def spreadOut(fn:str, nAs:List[str], nBs:List[str], rS):\n",
    "    \"\"\"Spreads out a file from nodes A to B, where B fully contains A (no decomissioning).\n",
    "A and B should be mutually exclusive. Initial nodes are A, final nodes are A + B\"\"\"\n",
    "    nAs, nBs = [nAs, nBs] | deref(); rS.fn = fn\n",
    "    if len(nBs) == 0: return # no need to spread out\n",
    "    nBs | applyCl.aS(lambda: None | cmd(f\"mkdir -p {os.path.dirname(fn)}\") | deref(), timeout=None) | deref()\n",
    "    nBs | applyCl.aS(lambda: None | cmd(f\"rm -rf {fn}\") | deref(), timeout=None) | deref()\n",
    "    # some initial metadata\n",
    "    nodeIds = applyCl.nodeIds(); nodeId_cpu = loadTestGuard(False).items() | deref(); nodeId2Cpu = nodeId_cpu | toDict()\n",
    "    sizes = nAs | applyCl.aS(lambda: os.path.getsize(fn) if os.path.exists(fn) else 0) | deref(); totalSize = sizes | cut(1) | toSum()\n",
    "    ns = [*nAs, *nBs]; totalCpu = ns | lookup(nodeId2Cpu) | toSum(); bytePerCpu = totalSize/totalCpu; wsB = nBs | lookup(nodeId2Cpu) | deref()\n",
    "    # prepares segments and metadata, List[nodeId, [sB, eB]], where sB and eB are the ranges of nAs that they're willing to share\n",
    "    sizePost = sizes | ~apply(lambda idx, size: [idx, nodeId2Cpu[idx]/totalCpu*totalSize/size]) | deref() # size fraction to retain\n",
    "    invalidNodes = sizePost | ~filt(lambda x: 0 <= x <= 1, 1) | cut(0) | deref()\n",
    "    if len(invalidNodes) > 0: raise Exception(f\"Unsupported configuration! These nodes have too little data to share: {invalidNodes}. This couldn't have happen using applyCl alone. Data is not corrupted, but you'll have to combine data from all files into 1 and spread them back out again.\")\n",
    "    inter = sizePost | ~apply(lambda idx, x: [idx, [x, 1-x]]) | applyCl(lambda ws: fn | splitSeek(ws=ws) | rS | ~head(1), pre=True) | deref() | filt(~aS(lambda x,y: y-x>0), 1) | deref() # filter at the end to eliminate files that don't want to share anything (x == y)\n",
    "    # actually transferring data to new nodes\n",
    "    meta = inter | apply(~aS(range) | splitW(*wsB) | ranges2Seeks | apply(lambda x: splitSeek.backward(fn, x)) | deref() | rS | window(2) | deref() | apply(wrapList()) | insertColumn(nBs), 1) | ungroup(False) | groupBy(1, True) | deref()\n",
    "    with ray.progress(len(meta), \"Transferring data to new nodes\") as rp:\n",
    "        meta | insertIdColumn(True) | applyTh(~aS(lambda idx, nB, nse: a_transfer(fn, nse, nB, rpF=aS(lambda p: ray.get(rp.update.remote(idx, p))))), timeout=24*3600) | deref()\n",
    "    # truncates the files in nAs nodes\n",
    "    inter | ~apply(lambda idx,se: [idx,se[0]]) | applyCl(lambda sB: open(fn, 'a').truncate(sB), pre=True, timeout=None) | deref()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6e05cdd-7e8c-461d-a732-bff4897af027",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def balanceFile(fn:str, nAs:List[str]=None, nBs:List[str]=None, rS=None):\n",
    "    fn = os.path.expanduser(fn); rS = rS or refineSeek(); rS.injectFn(fn); loadTestGuard()\n",
    "    if nAs is None: nAs = None | applyCl.aS(lambda: os.path.exists(fn)) | filt(op(), 1) | cut(0) | deref()\n",
    "    if nBs is None: nBs = applyCl.nodeIds()\n",
    "    decommission(fn, *nAs | inSet(nBs).split() | reverse(), rS)\n",
    "    spreadOut(fn, *nBs | inSet(nAs).split(), rS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2af6c8e-4143-4988-8085-e78c9f87d8f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['867dc6c8f88045aa165af30a64125aee311f1f64a32f1c43c6ed4dc0', 110001],\n",
       " ['244f4e340443f74ab302822376195329f45858b65998b4a77f5f4732', 165002],\n",
       " ['4ffae9ae502fde1a76a7b54a0146c943be6d0ac9bba8f7c3e07fdb4d', 0]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset(10000); \"0123456789\\n\"*5000 >> file(fn); status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5df6f742-7d43-47db-ad84-6082349f5932",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferring data to new nodes: 100%\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['867dc6c8f88045aa165af30a64125aee311f1f64a32f1c43c6ed4dc0', 68750],\n",
       " ['244f4e340443f74ab302822376195329f45858b65998b4a77f5f4732', 137501],\n",
       " ['4ffae9ae502fde1a76a7b54a0146c943be6d0ac9bba8f7c3e07fdb4d', 68752]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanceFile(fn); status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7462b52e-0f25-486d-aef5-6e575fb9e0f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decommissioning: 100% | 100%\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['867dc6c8f88045aa165af30a64125aee311f1f64a32f1c43c6ed4dc0', 137500],\n",
       " ['244f4e340443f74ab302822376195329f45858b65998b4a77f5f4732', 0],\n",
       " ['4ffae9ae502fde1a76a7b54a0146c943be6d0ac9bba8f7c3e07fdb4d', 137503]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanceFile(fn, nBs=[\"867dc6c8f88045aa165af30a64125aee311f1f64a32f1c43c6ed4dc0\", \"4ffae9ae502fde1a76a7b54a0146c943be6d0ac9bba8f7c3e07fdb4d\"]); status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "147086b5-6dd2-4f11-85f1-1f3a4829f9e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decommissioning: 100%\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['867dc6c8f88045aa165af30a64125aee311f1f64a32f1c43c6ed4dc0', 0],\n",
       " ['244f4e340443f74ab302822376195329f45858b65998b4a77f5f4732', 0],\n",
       " ['4ffae9ae502fde1a76a7b54a0146c943be6d0ac9bba8f7c3e07fdb4d', 275003]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanceFile(fn, nBs=[\"4ffae9ae502fde1a76a7b54a0146c943be6d0ac9bba8f7c3e07fdb4d\"]); status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "636b2d8b-8a18-4413-8d87-65cd416f039d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferring data to new nodes: 100% | 100%\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['867dc6c8f88045aa165af30a64125aee311f1f64a32f1c43c6ed4dc0', 68754],\n",
       " ['244f4e340443f74ab302822376195329f45858b65998b4a77f5f4732', 137509],\n",
       " ['4ffae9ae502fde1a76a7b54a0146c943be6d0ac9bba8f7c3e07fdb4d', 68740]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanceFile(fn); status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40daa4e1-1c36-44f9-a2f9-8f97b730bc74",
   "metadata": {},
   "source": [
    "## File integrity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b79e638-dc08-4707-8121-93f0efaf4155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from k1lib.imports import *\n",
    "base = \"~/ssd2/test\"; fn = f\"{base}/a.txt\"; applyCl.cmd(f\"rm -rf {base} && mkdir -p {base}\")\n",
    "def genBinary(size=1000): return None | cmd(f\"cat /dev/urandom | head -{size}\", text=False)\n",
    "genBinary(1_000_000) | apply(k1.encode) | sort(None, False) | file(fn)\n",
    "con1 = cat(fn) | sort(None, False) | aS(list) | aS(k1.Wrapper)\n",
    "applyCl.balanceFile(fn)\n",
    "con2 = applyCl.cat(fn, filt(op()) | deref()) | joinStreams() | sort(None, False) | aS(list) | aS(k1.Wrapper)\n",
    "applyCl.decommissionFile(fn, [\"2fd74a5de08d96d323420c575ae514fdcb58f2987b7b621bfde3485c\"])\n",
    "con3 = applyCl.cat(fn, filt(op()) | deref()) | joinStreams() | sort(None, False) | aS(list) | aS(k1.Wrapper)\n",
    "assert con1() == con2(); assert con2() == con3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e23e35-78bf-48f4-a822-01f1f0ab9b06",
   "metadata": {},
   "source": [
    "# diskScan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5a404e-7eb8-4cd5-a66e-17f1bfefb386",
   "metadata": {},
   "source": [
    "Tries to scan the disk of all nodes to figure out where are the distributed files and folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7b09bb8-e974-4fab-9b10-72aac939da35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from k1lib.imports import *\n",
    "base = \"/home/kelvin/ssd2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f17d3175-d841-489c-8d8a-d9a544ff7b64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def diskScan1(base:str) -> List[str]: # like ls(), but returns files and folders that appear at least on 2 nodes\n",
    "    isdir, base = base.split(\"\\ue000\")\n",
    "    if not isdir: return []\n",
    "    return None | applyCl.aS(lambda: base | (tryout([]) | ls() | apply(os.path.isdir) & iden() | transpose() | ~apply(lambda x,y: f\"{x*1}\\ue000{y}\")) | deref(), timeout=60) | cut(1) | joinStreams() | count() | filt(op()>1, 0) | cut(1) | deref()\n",
    "def diskScan2(base:str) -> Tuple[List[str], List[str]]: # returns list of distributed folders and list of distributed files\n",
    "    dFolders = []; folders, files = diskScan1(base) | op().split(\"\\ue000\").all() | toInt(0) | filt(op(), 0).split() | (join(\"\\ue000\")).all(2) | deref()\n",
    "    # print(\"2--\", folders, files, base)\n",
    "    for folder in folders:\n",
    "        fol, fil = diskScan2(folder); dFolders.extend(fol); files.extend(fil)\n",
    "        if len(fol) + len(fil) == 0: dFolders.append(folder) # no shared contents, must be a distributed folder\n",
    "        else: files.extend(fil)\n",
    "    # print(\"3--\", [dFolders, files], base)\n",
    "    return [dFolders, files]\n",
    "def diskScan3(base:str): base = os.path.expanduser(base); return diskScan2(f\"1\\ue000{base}\") | op().split(\"\\ue000\")[1].all(2) | deref()\n",
    "def diskScan4(base:str, sortSize=True): # fully featured data\n",
    "    folders, files = diskScan3(base)\n",
    "    folders = [folders, None | applyCl.aS(lambda: folders | apply(lambda x: (x | getFolderSize) if os.path.exists(x) else 0) | deref(), timeout=60) | cut(1) | transpose()] | transpose() | deref()\n",
    "    files   = [files,   None | applyCl.aS(lambda: files   | apply(lambda x: os.path.getsize(x)  if os.path.exists(x) else 0) | deref(), timeout=60) | cut(1) | transpose()] | transpose() | deref()\n",
    "    post = apply(~sortF(toSum(), 1)) if sortSize else iden()\n",
    "    return [folders, files] | wrapList() + filt(filt(op() > 0) | count() | shape(0) | (op() == 1), 1).split() | joinStreams() | apply(unique(0)) | post | deref()\n",
    "def diskScan5(base:str, sortSize=True): # displays it in a nice format\n",
    "    d4 = diskScan4(base, sortSize); lens = d4 | apply(len) | deref(); nodeNames = None | applyCl.aS(lambda: os.cpu_count()) | apply(op()[:5], 0) | apply('f\"{x} thr\"', 1) | join(\", \").all() | deref(); nodeNames\n",
    "    d5 = d4 | apply(~apply(lambda path, sizes: [path, sizes | toSum() | aS(fmt.size), sizes | apply(fmt.size)]) | insert([\"-\"*40, \"-\"*10, [\"-\"*12]*len(nodeNames)]) | insert([\"\", \"\", nodeNames])) | deref(); d5\n",
    "    ws = d5 | shape(0).all() | deref()\n",
    "    d6 = d5 | joinStreams() | cut(0, 1) & (cut(2) | pretty() | wrapList().all()) | transpose() | joinStreams().all() | splitW(*ws) | insert([\"Path\", \"Total size\", \"Size on each node (node id and thread count)\"]).all() | joinStreams() | pretty() | splitW(*ws | apply(op()+1)) | deref()\n",
    "    explainers = [\"\\nA distributed folder is a folder that has many files and folders inside, but their names\\nare all different from each other. It's managed by applyCl.balanceFolder()\",\n",
    "                  \"\\nA replicated file is a file that has been copied to multiple nodes. Size of all file\\ncopies should be the same. It's managed by applyCl.replicateFile()\",\n",
    "                  \"\\nA distributed file is a file that has been split into multiple pieces and sent to other\\nnodes. It's managed by applyCl.balanceFile()\"]\n",
    "    arr = [d6, [\"Distributed folders\", \"Replicated files\", \"Distributed files\"] | (aS(lambda x: [[\"-\"*60, x, \"-\"*60] | join(\" \")])).all()] | transpose() | permute(1, 0) | (joinStreams() | join(\"\\n\")).all() | wrapList() | insert(explainers, False) | transpose() | join(\"\\n\").all() | deref()\n",
    "    [arr, lens] | transpose() | filt(op(), 1) | cut(0) | join(\"\\n\"*2) | wrapList() | stdout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eef0e1b7-e13f-490d-a5af-1777abf5021e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['/home/kelvin/ssd2/test',\n",
       "  '/home/kelvin/ssd2/data/genome/go/release_geneontology_org',\n",
       "  '/home/kelvin/ssd2/data/genome/genbank/ch1',\n",
       "  '/home/kelvin/ssd2/data/genome/genbank/ch1.dat.gz',\n",
       "  '/home/kelvin/ssd2/data/genome/RegulationFeatureActivity',\n",
       "  '/home/kelvin/ssd2/data/genome/RegulationFeatureActivity.backup',\n",
       "  '/home/kelvin/ssd2/data/genome/00-common_all.idx'],\n",
       " ['/home/kelvin/ssd2/data/genome/dummy.txt',\n",
       "  '/home/kelvin/ssd2/data/genome/00-common_all.vcf',\n",
       "  '/home/kelvin/ssd2/data/genome/00-All.vcf',\n",
       "  '/home/kelvin/ssd2/data/genome/MotifFeatures/homo_sapiens.GRCh38.motif_features.gff',\n",
       "  '/home/kelvin/ssd2/data/genome/MotifFeatures/homo_sapiens.GRCh38.motif_features.gff',\n",
       "  '/home/kelvin/ssd2/data/genome/dummy.txt',\n",
       "  '/home/kelvin/ssd2/data/genome/00-common_all.vcf',\n",
       "  '/home/kelvin/ssd2/data/genome/00-All.vcf',\n",
       "  '/home/kelvin/ssd2/data/genome/MotifFeatures/homo_sapiens.GRCh38.motif_features.gff',\n",
       "  '/home/kelvin/ssd2/data/genome/MotifFeatures/homo_sapiens.GRCh38.motif_features.gff',\n",
       "  '/home/kelvin/ssd2/data/genome/dummy.txt',\n",
       "  '/home/kelvin/ssd2/data/genome/00-common_all.vcf',\n",
       "  '/home/kelvin/ssd2/data/genome/00-All.vcf',\n",
       "  '/home/kelvin/ssd2/data/genome/MotifFeatures/homo_sapiens.GRCh38.motif_features.gff',\n",
       "  '/home/kelvin/ssd2/data/genome/MotifFeatures/homo_sapiens.GRCh38.motif_features.gff',\n",
       "  '/home/kelvin/ssd2/data/genome/dummy.txt',\n",
       "  '/home/kelvin/ssd2/data/genome/00-common_all.vcf',\n",
       "  '/home/kelvin/ssd2/data/genome/00-All.vcf',\n",
       "  '/home/kelvin/ssd2/data/genome/MotifFeatures/homo_sapiens.GRCh38.motif_features.gff',\n",
       "  '/home/kelvin/ssd2/data/genome/MotifFeatures/homo_sapiens.GRCh38.motif_features.gff']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diskScan3(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb58c2a7-dba1-49c4-8dc7-412821e47997",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['/home/kelvin/ssd2/data/genome/RegulationFeatureActivity',\n",
       "   [0, 7912834090, 4113489746, 4164314316]],\n",
       "  ['/home/kelvin/ssd2/data/genome/go/release_geneontology_org',\n",
       "   [0, 4172737915, 2071645117, 2107005131]],\n",
       "  ['/home/kelvin/ssd2/data/genome/RegulationFeatureActivity.backup',\n",
       "   [0, 552888466, 568878496, 600610083]],\n",
       "  ['/home/kelvin/ssd2/data/genome/00-common_all.idx',\n",
       "   [0, 671136833, 341738564, 0]],\n",
       "  ['/home/kelvin/ssd2/data/genome/genbank/ch1.dat.gz',\n",
       "   [0, 0, 25356744, 25356764]],\n",
       "  ['/home/kelvin/ssd2/data/genome/genbank/ch1', [0, 0, 0, 0]]],\n",
       " [['/home/kelvin/ssd2/data/genome/dummy.txt', [0, 1101, 1101, 1101]]],\n",
       " [['/home/kelvin/ssd2/data/genome/00-All.vcf',\n",
       "   [0, 65475018903, 32737509360, 32737509588]],\n",
       "  ['/home/kelvin/ssd2/data/genome/MotifFeatures/homo_sapiens.GRCh38.motif_features.gff',\n",
       "   [27927710370, 13963854708, 6981927367, 6981927374]],\n",
       "  ['/home/kelvin/ssd2/data/genome/00-common_all.vcf',\n",
       "   [0, 4707803470, 2353901811, 2353901831]],\n",
       "  ['/home/kelvin/ssd2/test/balanceFile/a.txt',\n",
       "   [3600000000, 1800000000, 900000000, 900000000]]]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diskScan4(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0e2bcb2-623d-47a1-af9e-7f1a261a867c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------ Distributed folders ------------------------------------------------------------\n",
      "Path                                                                                 Total size   Size on each node (node id and thread count)     \n",
      "                                                                                                  ae5f4, 8 thr   244f4, 16 thr   f776e, 8 thr      \n",
      "----------------------------------------                                             ----------   ------------   ------------    ------------      \n",
      "/home/kelvin/ssd2/data/genome/RegulationFeatureActivity                              16.19 GB     4.11 GB        7.91 GB         4.16 GB           \n",
      "/home/kelvin/ssd2/data/genome/go/release_geneontology_org                            8.35 GB      2.07 GB        4.17 GB         2.11 GB           \n",
      "/home/kelvin/ssd2/data/genome/RegulationFeatureActivity.backup                       1.72 GB      568.88 MB      552.89 MB       600.61 MB         \n",
      "/home/kelvin/ssd2/data/genome/00-common_all.idx                                      1.01 GB      341.74 MB      671.14 MB       0.0 B             \n",
      "/home/kelvin/ssd2/data/genome/genbank/ch1.dat.gz                                     50.71 MB     25.36 MB       0.0 B           25.36 MB          \n",
      "/home/kelvin/ssd2/test                                                               546.03 kB    136.15 kB      273.53 kB       136.35 kB         \n",
      "/home/kelvin/ssd2/data/genome/genbank/ch1                                            0.0 B        0.0 B          0.0 B           0.0 B             \n",
      "\n",
      "A distributed folder is a folder that has many files and folders inside, but their names\n",
      "are all different from each other. It's managed by applyCl.balanceFolder()\n",
      "\n",
      "------------------------------------------------------------ Replicated files ------------------------------------------------------------\n",
      "Path                                                                                 Total size   Size on each node (node id and thread count)     \n",
      "                                                                                                  ae5f4, 8 thr   244f4, 16 thr   f776e, 8 thr      \n",
      "----------------------------------------                                             ----------   ------------   ------------    ------------      \n",
      "/home/kelvin/ssd2/data/genome/dummy.txt                                              3.3 kB       1.1 kB         1.1 kB          1.1 kB            \n",
      "\n",
      "A replicated file is a file that has been copied to multiple nodes. Size of all file\n",
      "copies should be the same. It's managed by applyCl.replicateFile()\n",
      "\n",
      "------------------------------------------------------------ Distributed files ------------------------------------------------------------\n",
      "Path                                                                                 Total size   Size on each node (node id and thread count)     \n",
      "                                                                                                  ae5f4, 8 thr   244f4, 16 thr   f776e, 8 thr      \n",
      "----------------------------------------                                             ----------   ------------   ------------    ------------      \n",
      "/home/kelvin/ssd2/data/genome/00-All.vcf                                             130.95 GB    32.74 GB       65.48 GB        32.74 GB          \n",
      "/home/kelvin/ssd2/data/genome/MotifFeatures/homo_sapiens.GRCh38.motif_features.gff   55.86 GB     13.96 GB       27.93 GB        13.96 GB          \n",
      "/home/kelvin/ssd2/data/genome/00-common_all.vcf                                      9.42 GB      2.35 GB        4.71 GB         2.35 GB           \n",
      "\n",
      "A distributed file is a file that has been split into multiple pieces and sent to other\n",
      "nodes. It's managed by applyCl.balanceFile()\n"
     ]
    }
   ],
   "source": [
    "diskScan5(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4002561e-045d-46db-8683-3a63278a8686",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../docs/literals/diskScan.rst'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with k1.captureStdout() as out: diskScan5(base)\n",
    "out() | apply(lambda x: f\"   {x}\") | insert(\"\") | insert(\".. code-block:: text\") | file(\"../../docs/literals/diskScan.rst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0fe1279-865e-43f3-8ba3-819b11552066",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current dir: /home/kelvin/repos/labs/k1lib, /home/kelvin/repos/labs/k1lib/k1lib/cli/../../export.py\n",
      "rm: cannot remove '__pycache__': No such file or directory\n",
      "Found existing installation: k1lib 1.4\n",
      "Uninstalling k1lib-1.4:\n",
      "  Successfully uninstalled k1lib-1.4\n",
      "running install\n",
      "/home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "/home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages/setuptools/command/easy_install.py:144: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "creating k1lib.egg-info\n",
      "writing k1lib.egg-info/PKG-INFO\n",
      "writing dependency_links to k1lib.egg-info/dependency_links.txt\n",
      "writing requirements to k1lib.egg-info/requires.txt\n",
      "writing top-level names to k1lib.egg-info/top_level.txt\n",
      "writing manifest file 'k1lib.egg-info/SOURCES.txt'\n",
      "reading manifest file 'k1lib.egg-info/SOURCES.txt'\n",
      "adding license file 'LICENSE'\n",
      "writing manifest file 'k1lib.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "creating build/lib/k1lib\n",
      "copying k1lib/_learner.py -> build/lib/k1lib\n",
      "copying k1lib/fmt.py -> build/lib/k1lib\n",
      "copying k1lib/_k1a.py -> build/lib/k1lib\n",
      "copying k1lib/_context.py -> build/lib/k1lib\n",
      "copying k1lib/selector.py -> build/lib/k1lib\n",
      "copying k1lib/imports.py -> build/lib/k1lib\n",
      "copying k1lib/_baseClasses.py -> build/lib/k1lib\n",
      "copying k1lib/_basics.py -> build/lib/k1lib\n",
      "copying k1lib/viz.py -> build/lib/k1lib\n",
      "copying k1lib/_higher.py -> build/lib/k1lib\n",
      "copying k1lib/__init__.py -> build/lib/k1lib\n",
      "copying k1lib/_monkey.py -> build/lib/k1lib\n",
      "copying k1lib/knn.py -> build/lib/k1lib\n",
      "copying k1lib/p5.py -> build/lib/k1lib\n",
      "copying k1lib/graphEqn.py -> build/lib/k1lib\n",
      "copying k1lib/schedule.py -> build/lib/k1lib\n",
      "copying k1lib/_perlin.py -> build/lib/k1lib\n",
      "copying k1lib/eqn.py -> build/lib/k1lib\n",
      "creating build/lib/k1lib/_hidden\n",
      "copying k1lib/_hidden/hiddenFile.py -> build/lib/k1lib/_hidden\n",
      "copying k1lib/_hidden/__init__.py -> build/lib/k1lib/_hidden\n",
      "creating build/lib/k1lib/cli\n",
      "copying k1lib/cli/bio.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/cif.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/structural.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/modifier.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/gb.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/output.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/kxml.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/nb.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/inp.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/mol.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/mgi.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/_applyCl.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/grep.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/sam.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/trace.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/__init__.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/typehint.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/filt.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/utils.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/init.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/conv.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/optimizations.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/kcsv.py -> build/lib/k1lib/cli\n",
      "creating build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/loss_accuracy.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/progress.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/limits.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/hookParam.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/profiler.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/callbacks.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/paramFinder.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/core.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/__init__.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/landscape.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/confusionMatrix.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/recorder.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/shorts.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/hookModule.py -> build/lib/k1lib/callbacks\n",
      "creating build/lib/k1lib/callbacks/profilers\n",
      "copying k1lib/callbacks/profilers/time.py -> build/lib/k1lib/callbacks/profilers\n",
      "copying k1lib/callbacks/profilers/memory.py -> build/lib/k1lib/callbacks/profilers\n",
      "copying k1lib/callbacks/profilers/__init__.py -> build/lib/k1lib/callbacks/profilers\n",
      "copying k1lib/callbacks/profilers/io.py -> build/lib/k1lib/callbacks/profilers\n",
      "copying k1lib/callbacks/profilers/computation.py -> build/lib/k1lib/callbacks/profilers\n",
      "creating build/lib/k1lib/callbacks/lossFunctions\n",
      "copying k1lib/callbacks/lossFunctions/accuracy.py -> build/lib/k1lib/callbacks/lossFunctions\n",
      "copying k1lib/callbacks/lossFunctions/__init__.py -> build/lib/k1lib/callbacks/lossFunctions\n",
      "copying k1lib/callbacks/lossFunctions/shorts.py -> build/lib/k1lib/callbacks/lossFunctions\n",
      "creating build/lib/k1lib/_mo\n",
      "copying k1lib/_mo/atom.py -> build/lib/k1lib/_mo\n",
      "copying k1lib/_mo/parseM.py -> build/lib/k1lib/_mo\n",
      "copying k1lib/_mo/substance.py -> build/lib/k1lib/_mo\n",
      "copying k1lib/_mo/system.py -> build/lib/k1lib/_mo\n",
      "copying k1lib/_mo/__init__.py -> build/lib/k1lib/_mo\n",
      "creating build/lib/k1lib/serve\n",
      "copying k1lib/serve/suffix.py -> build/lib/k1lib/serve\n",
      "copying k1lib/serve/suffix-dash.py -> build/lib/k1lib/serve\n",
      "copying k1lib/serve/__init__.py -> build/lib/k1lib/serve\n",
      "copying k1lib/serve/main.py -> build/lib/k1lib/serve\n",
      "creating build/lib/k1lib/k1ui\n",
      "copying k1lib/k1ui/__init__.py -> build/lib/k1lib/k1ui\n",
      "copying k1lib/k1ui/main.py -> build/lib/k1lib/k1ui\n",
      "creating build/bdist.linux-x86_64\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/_learner.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "creating build/bdist.linux-x86_64/egg/k1lib/serve\n",
      "copying build/lib/k1lib/serve/suffix.py -> build/bdist.linux-x86_64/egg/k1lib/serve\n",
      "copying build/lib/k1lib/serve/suffix-dash.py -> build/bdist.linux-x86_64/egg/k1lib/serve\n",
      "copying build/lib/k1lib/serve/__init__.py -> build/bdist.linux-x86_64/egg/k1lib/serve\n",
      "copying build/lib/k1lib/serve/main.py -> build/bdist.linux-x86_64/egg/k1lib/serve\n",
      "copying build/lib/k1lib/fmt.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/_k1a.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/_context.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/selector.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/imports.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "creating build/bdist.linux-x86_64/egg/k1lib/k1ui\n",
      "copying build/lib/k1lib/k1ui/__init__.py -> build/bdist.linux-x86_64/egg/k1lib/k1ui\n",
      "copying build/lib/k1lib/k1ui/main.py -> build/bdist.linux-x86_64/egg/k1lib/k1ui\n",
      "copying build/lib/k1lib/_baseClasses.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/_basics.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "creating build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/bio.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/cif.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/structural.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/modifier.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/gb.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/output.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/kxml.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/nb.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/inp.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/mol.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/mgi.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/_applyCl.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/grep.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/sam.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/trace.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/__init__.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/typehint.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/filt.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/utils.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/init.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/conv.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/optimizations.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/kcsv.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/viz.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/_higher.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/__init__.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/_monkey.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "creating build/bdist.linux-x86_64/egg/k1lib/_mo\n",
      "copying build/lib/k1lib/_mo/atom.py -> build/bdist.linux-x86_64/egg/k1lib/_mo\n",
      "copying build/lib/k1lib/_mo/parseM.py -> build/bdist.linux-x86_64/egg/k1lib/_mo\n",
      "copying build/lib/k1lib/_mo/substance.py -> build/bdist.linux-x86_64/egg/k1lib/_mo\n",
      "copying build/lib/k1lib/_mo/system.py -> build/bdist.linux-x86_64/egg/k1lib/_mo\n",
      "copying build/lib/k1lib/_mo/__init__.py -> build/bdist.linux-x86_64/egg/k1lib/_mo\n",
      "copying build/lib/k1lib/knn.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/p5.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/graphEqn.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/schedule.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "creating build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/loss_accuracy.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/progress.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/limits.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/hookParam.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/profiler.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/callbacks.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/paramFinder.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/core.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "creating build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers\n",
      "copying build/lib/k1lib/callbacks/profilers/time.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers\n",
      "copying build/lib/k1lib/callbacks/profilers/memory.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers\n",
      "copying build/lib/k1lib/callbacks/profilers/__init__.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers\n",
      "copying build/lib/k1lib/callbacks/profilers/io.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers\n",
      "copying build/lib/k1lib/callbacks/profilers/computation.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers\n",
      "copying build/lib/k1lib/callbacks/__init__.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/landscape.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/confusionMatrix.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/recorder.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/shorts.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/hookModule.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "creating build/bdist.linux-x86_64/egg/k1lib/callbacks/lossFunctions\n",
      "copying build/lib/k1lib/callbacks/lossFunctions/accuracy.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks/lossFunctions\n",
      "copying build/lib/k1lib/callbacks/lossFunctions/__init__.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks/lossFunctions\n",
      "copying build/lib/k1lib/callbacks/lossFunctions/shorts.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks/lossFunctions\n",
      "copying build/lib/k1lib/_perlin.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "creating build/bdist.linux-x86_64/egg/k1lib/_hidden\n",
      "copying build/lib/k1lib/_hidden/hiddenFile.py -> build/bdist.linux-x86_64/egg/k1lib/_hidden\n",
      "copying build/lib/k1lib/_hidden/__init__.py -> build/bdist.linux-x86_64/egg/k1lib/_hidden\n",
      "copying build/lib/k1lib/eqn.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_learner.py to _learner.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/serve/suffix.py to suffix.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/serve/suffix-dash.py to suffix-dash.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/serve/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/serve/main.py to main.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/fmt.py to fmt.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_k1a.py to _k1a.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_context.py to _context.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/selector.py to selector.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/imports.py to imports.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/k1ui/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/k1ui/main.py to main.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_baseClasses.py to _baseClasses.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_basics.py to _basics.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/bio.py to bio.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/cif.py to cif.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/structural.py to structural.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/modifier.py to modifier.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/gb.py to gb.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/output.py to output.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/kxml.py to kxml.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/nb.py to nb.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/inp.py to inp.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/mol.py to mol.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/mgi.py to mgi.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/_applyCl.py to _applyCl.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/grep.py to grep.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/sam.py to sam.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/trace.py to trace.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/typehint.py to typehint.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/filt.py to filt.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/utils.py to utils.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/init.py to init.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/conv.py to conv.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/optimizations.py to optimizations.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/kcsv.py to kcsv.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/viz.py to viz.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_higher.py to _higher.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_monkey.py to _monkey.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_mo/atom.py to atom.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_mo/parseM.py to parseM.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_mo/substance.py to substance.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_mo/system.py to system.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_mo/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/knn.py to knn.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/p5.py to p5.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/graphEqn.py to graphEqn.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/schedule.py to schedule.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/loss_accuracy.py to loss_accuracy.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/progress.py to progress.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/limits.py to limits.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/hookParam.py to hookParam.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/profiler.py to profiler.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/callbacks.py to callbacks.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/paramFinder.py to paramFinder.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/core.py to core.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers/time.py to time.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers/memory.py to memory.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers/io.py to io.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers/computation.py to computation.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/landscape.py to landscape.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/confusionMatrix.py to confusionMatrix.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/recorder.py to recorder.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/shorts.py to shorts.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/hookModule.py to hookModule.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/lossFunctions/accuracy.py to accuracy.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/lossFunctions/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/lossFunctions/shorts.py to shorts.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_perlin.py to _perlin.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_hidden/hiddenFile.py to hiddenFile.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_hidden/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/eqn.py to eqn.cpython-39.pyc\n",
      "installing package data to build/bdist.linux-x86_64/egg\n",
      "running install_data\n",
      "copying k1lib/serve/main.html -> build/bdist.linux-x86_64/egg/k1lib/serve\n",
      "copying k1lib/k1ui/mouseKey.pth -> build/bdist.linux-x86_64/egg/k1lib/k1ui\n",
      "copying k1lib/k1ui/256.model.state_dict.pth -> build/bdist.linux-x86_64/egg/k1lib/k1ui\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying k1lib.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying k1lib.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying k1lib.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying k1lib.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying k1lib.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "k1lib.cli.__pycache__.init.cpython-39: module MAY be using inspect.trace\n",
      "k1lib.k1ui.__pycache__.main.cpython-39: module MAY be using inspect.getabsfile\n",
      "k1lib.k1ui.__pycache__.main.cpython-39: module MAY be using inspect.stack\n",
      "k1lib.serve.__pycache__.main.cpython-39: module MAY be using inspect.getsource\n",
      "k1lib.serve.__pycache__.main.cpython-39: module MAY be using inspect.getabsfile\n",
      "creating dist\n",
      "creating 'dist/k1lib-1.4-py3.9.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing k1lib-1.4-py3.9.egg\n",
      "creating /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages/k1lib-1.4-py3.9.egg\n",
      "Extracting k1lib-1.4-py3.9.egg to /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Adding k1lib 1.4 to easy-install.pth file\n",
      "\n",
      "Installed /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages/k1lib-1.4-py3.9.egg\n",
      "Processing dependencies for k1lib==1.4\n",
      "Searching for validators==0.20.0\n",
      "Best match: validators 0.20.0\n",
      "Adding validators 0.20.0 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for wurlitzer==3.0.3\n",
      "Best match: wurlitzer 3.0.3\n",
      "Adding wurlitzer 3.0.3 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for forbiddenfruit==0.1.4\n",
      "Best match: forbiddenfruit 0.1.4\n",
      "Adding forbiddenfruit 0.1.4 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for dill==0.3.6\n",
      "Best match: dill 0.3.6\n",
      "Adding dill 0.3.6 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for matplotlib==3.7.1\n",
      "Best match: matplotlib 3.7.1\n",
      "Adding matplotlib 3.7.1 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for numpy==1.24.2\n",
      "Best match: numpy 1.24.2\n",
      "Adding numpy 1.24.2 to easy-install.pth file\n",
      "Installing f2py script to /home/kelvin/anaconda3/envs/ray2/bin\n",
      "Installing f2py3 script to /home/kelvin/anaconda3/envs/ray2/bin\n",
      "Installing f2py3.9 script to /home/kelvin/anaconda3/envs/ray2/bin\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for decorator==5.1.1\n",
      "Best match: decorator 5.1.1\n",
      "Adding decorator 5.1.1 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for importlib-resources==5.12.0\n",
      "Best match: importlib-resources 5.12.0\n",
      "Adding importlib-resources 5.12.0 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for python-dateutil==2.8.2\n",
      "Best match: python-dateutil 2.8.2\n",
      "Adding python-dateutil 2.8.2 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for pyparsing==3.0.9\n",
      "Best match: pyparsing 3.0.9\n",
      "Adding pyparsing 3.0.9 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for Pillow==9.5.0\n",
      "Best match: Pillow 9.5.0\n",
      "Adding Pillow 9.5.0 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for packaging==23.1\n",
      "Best match: packaging 23.1\n",
      "Adding packaging 23.1 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for kiwisolver==1.4.4\n",
      "Best match: kiwisolver 1.4.4\n",
      "Adding kiwisolver 1.4.4 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for fonttools==4.39.3\n",
      "Best match: fonttools 4.39.3\n",
      "Adding fonttools 4.39.3 to easy-install.pth file\n",
      "Installing fonttools script to /home/kelvin/anaconda3/envs/ray2/bin\n",
      "Installing pyftmerge script to /home/kelvin/anaconda3/envs/ray2/bin\n",
      "Installing pyftsubset script to /home/kelvin/anaconda3/envs/ray2/bin\n",
      "Installing ttx script to /home/kelvin/anaconda3/envs/ray2/bin\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for cycler==0.11.0\n",
      "Best match: cycler 0.11.0\n",
      "Adding cycler 0.11.0 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for contourpy==1.0.7\n",
      "Best match: contourpy 1.0.7\n",
      "Adding contourpy 1.0.7 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for zipp==3.15.0\n",
      "Best match: zipp 3.15.0\n",
      "Adding zipp 3.15.0 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for six==1.16.0\n",
      "Best match: six 1.16.0\n",
      "Adding six 1.16.0 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Finished processing dependencies for k1lib==1.4\n"
     ]
    }
   ],
   "source": [
    "!../../export.py cli/_applyCl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163b0d67-bde0-446c-827e-4c8fdb43457d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

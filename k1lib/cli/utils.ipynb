{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da619625",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\"\"\"\n",
    "This is for all short and random quality-of-life utilities.\"\"\"\n",
    "from k1lib.cli.init import patchDefaultDelim, BaseCli, yieldT\n",
    "import k1lib.cli as cli, k1lib.cli.init as init, numbers, numpy as np, dis\n",
    "from k1lib.cli.typehint import *\n",
    "from typing import overload, Iterator, Any, List, Set, Union, Callable\n",
    "import k1lib, time, math, os, json, dill\n",
    "from collections import defaultdict\n",
    "try: import torch; hasTorch = True\n",
    "except: torch = k1lib.Object().withAutoDeclare(lambda: type(\"RandomClass\", (object, ), {})); hasTorch = False\n",
    "try: import PIL; hasPIL = True\n",
    "except: hasPIL = False\n",
    "plt = k1lib.dep.plt\n",
    "try: import genpy, rosbag; hasRos1 = True\n",
    "except: hasRos1 = False\n",
    "try: import pandas as pd; pd.core; hasPandas = True\n",
    "except: hasPandas = False\n",
    "__all__ = [\"size\", \"shape\", \"resize\", \"item\", \"rItem\", \"iden\", \"join\", \"wrapList\",\n",
    "           \"equals\", \"reverse\", \"ignore\", \"rateLimit\", \"timeLimit\", \"tab\", \"indent\",\n",
    "           \"clipboard\", \"deref\", \"bindec\", \"smooth\", \"disassemble\",\n",
    "           \"tree\", \"lookup\", \"lookupRange\", \"getitems\", \"backup\", \"sketch\", \"syncStepper\", \"zeroes\", \"normalize\", \"branch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9d952a8-8580-4500-adaa-8a7e96758707",
   "metadata": {},
   "outputs": [],
   "source": [
    "cli.init.patchNumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea6fad1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "settings = k1lib.settings.cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fc147ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def exploreSize(it):\n",
    "    \"\"\"Returns first element and length of array. Returns [first item, length]\"\"\"\n",
    "    if isinstance(it, str): return None, len(it)\n",
    "    try: return it[0], len(it)\n",
    "    except: pass\n",
    "    sentinel = object(); it = iter(it)\n",
    "    o = next(it, sentinel); count = 1\n",
    "    if o is sentinel: return None, 0\n",
    "    try:\n",
    "        while True: next(it); count += 1\n",
    "    except StopIteration: pass\n",
    "    return o, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "165c54ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class size(BaseCli):\n",
    "    def __init__(self, idx=None):\n",
    "        \"\"\"Returns number of rows and columns in the input.\n",
    "Example::\n",
    "\n",
    "    [[2, 3], [4, 5, 6], [3]]    | shape()  # returns (3, 2)\n",
    "    [[2, 3], [4, 5, 6], [3]]    | shape(0) # returns 3\n",
    "    [[2, 3], [4, 5, 6], [3]]    | shape(1) # returns 2\n",
    "    [[], [2, 3]]                | shape()  # returns (2, 0)\n",
    "    [2, 3, 5]                   | shape()  # returns (3,)\n",
    "    [2, 3, 5]                   | shape(0) # returns 3\n",
    "    [[[2, 1], [0, 6, 7]], 3, 5] | shape()  # returns (3, 2, 2)\n",
    "    [\"abc\"]                     | shape()  # returns (1, 3)\n",
    "    [torch.randn(2, 3)]         | shape()  # returns (1, 2, 3)\n",
    "    shape()(np.random.randn(2, 3, 5))      # returns (2, 3, 5)\n",
    "    \"some_img.jpg\" | toImg()    | shape()  # returns (width, height) for a particular image\n",
    "    some_pandas_data_frame      | shape()  # returns dataframe's (#rows, #columns)\n",
    "\n",
    ":class:`shape` is an alias of this cli. Use whichever is more intuitive for you.\n",
    "\n",
    ":param idx: if not specified, returns a tuple of ints. If specified,\n",
    "    then returns the specific index of the tuple\"\"\"\n",
    "        super().__init__(); self.idx = idx;\n",
    "        if idx is not None: self._f = cli.item(idx)\n",
    "    def _all_array_opt(self, it, level):\n",
    "        res = np.array(it.shape[level:])[tuple([None]*level)] + np.zeros(it.shape[:level], dtype=int)[(*[slice(None)]*level, None)]\n",
    "        return res if self.idx is None else res | cli.rItem(self.idx).all(level)\n",
    "    def _typehint(self, inp):\n",
    "        if self.idx is not None: return int\n",
    "        return tList(int)\n",
    "    def __ror__(self, it:Iterator[str]):\n",
    "        idx = self.idx\n",
    "        if idx == 0: # super quick path for the really common case\n",
    "            try: return len(it)\n",
    "            except:\n",
    "                try: return exploreSize(it)[1]\n",
    "                except: pass\n",
    "        if hasPIL and isinstance(it, PIL.Image.Image): return it.size if idx is None else it.size[idx]\n",
    "        if hasPandas and isinstance(it, pd.core.frame.DataFrame): s = (len(it), it.size//len(it)); return s if idx is None else s[idx]\n",
    "        if hasattr(it, \"_shape\"): return it._shape(self.idx)\n",
    "        if idx is None:\n",
    "            answer = []\n",
    "            try:\n",
    "                while True:\n",
    "                    if isinstance(it, settings.arrayTypes):\n",
    "                        return tuple(answer + list(it.shape))\n",
    "                    it, s = exploreSize(it); answer.append(s)\n",
    "            except TypeError: pass\n",
    "            return tuple(answer)\n",
    "        return exploreSize(it | self._f)[1]\n",
    "    def _jsF(self, meta):\n",
    "        fIdx = init._jsFAuto(); dataIdx = init._jsDAuto()\n",
    "        post = \"\" if self.idx is None else f\"[{cli.kjs.v(self.idx)}]\"\n",
    "        return f\"{fIdx} = ({dataIdx}) => {dataIdx}.shape(){post}\", fIdx\n",
    "shape = size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6e63a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert [[2, 3], [4, 5, 6], [3]] | tCheck() | size() == (3, 2)\n",
    "assert [[2, 3], [4, 5, 6], [3]] | tCheck() | size(0) == 3\n",
    "assert [[2, 3], [4, 5, 6], [3]] | tCheck() | size(1) == 2\n",
    "assert [[], [2, 3]] | tCheck() | size() == (2, 0)\n",
    "assert [2, 3, 5] | tCheck() | size() == (3,)\n",
    "assert [2, 3, 5] | tCheck() | size(0) == 3\n",
    "assert torch.randn(3, 4) | tCheck() | size() == (3, 4)\n",
    "assert [[[2, 1], [0, 6, 7]], 3, 5] | tCheck() | size() == (3, 2, 2)\n",
    "assert [\"abc\"] | tCheck() | size() == (1, 3)\n",
    "assert [torch.randn(2, 3)] | tCheck() | size() == (1, 2, 3)\n",
    "assert size()(np.random.randn(2, 3, 5)) | tCheck() == (2, 3, 5)\n",
    "assert np.random.randn(3, 4, 5, 6) | shape().all(2) | cli.op().shape == (3, 4, 2)\n",
    "df1 = pd.DataFrame({\"A\": [1.0,2,3,4], \"B\": pd.Timestamp(\"20130102\"), \"C\": pd.Series(1, index=list(range(4)), dtype=\"float32\"), \"D\": np.array([3] * 4, dtype=\"int32\"), \"E\": pd.Categorical([\"test\", \"train\", \"test\", \"train\"]), \"F\": \"foo\",})\n",
    "assert df1 | shape() == (4, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b55d9bf-31ee-4c70-bf58-d244f636b32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class resize(BaseCli):\n",
    "    def __init__(self, width=0, height=0, max=0):\n",
    "        \"\"\"Resizes the image coming in to a new value.\n",
    "Example::\n",
    "\n",
    "    img = \"path/some_img.jpg\" | toImg() # loads image up\n",
    "    img | shape()                       # returns (400, 600) in this example, meaning width is 400, height is 600\n",
    "    img | resize(200)                   # resizes image to (200, 300), keeping aspect ratio\n",
    "    img | resize(height=300)            # resizes image to (200, 300), keeping aspect ratio)\n",
    "    img | resize(200, 200)              # resizes image to (200, 200), disregarding aspect ratio\n",
    "    img | resize(max=200)               # resizes image so that the biggest length is 200\n",
    "\"\"\"\n",
    "        self.width = width; self.height = height; self.max = max\n",
    "    def __ror__(self, it):\n",
    "        width = self.width; height = self.height; max = self.max\n",
    "        if hasPIL and isinstance(it, PIL.Image.Image):\n",
    "            rWidth = it.size[0]; rHeight = it.size[1]; ratio = 1 # real width & height\n",
    "            if width > 0 and height > 0:\n",
    "                if (max < width or max < height) and max > 0: raise Exception(f\"max value ({max}) lower than width or height \")\n",
    "                try: return it.resize((width, height), resample=PIL.Image.Resampling.LANCZOS)\n",
    "                except: return it.resize((width, height))\n",
    "            if width > 0 and height == 0: ratio = width / rWidth\n",
    "            if height > 0 and width == 0: ratio = height / rHeight\n",
    "            if max > 0: ratio = min(ratio, max/rWidth, max/rHeight)\n",
    "            try: return it.resize((int(rWidth*ratio), int(rHeight*ratio)), resample=PIL.Image.Resampling.LANCZOS)\n",
    "            except: return it.resize((int(rWidth*ratio), int(rHeight*ratio)))\n",
    "        raise Exception(f\"Doesn't know how to resize object of type {type(it)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4681726-2592-443b-aa4d-f3553c55a4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert [\"abc\", \"def\"] | cli.toImg() | resize(50) | shape(0) == 50\n",
    "assert [\"abc\", \"def\"] | cli.toImg() | resize(height=50) | shape(1) == 50\n",
    "assert [\"abc\", \"def\"] | cli.toImg() | resize(max=30) | shape(1) == 30\n",
    "assert [\"abc\", \"def\"] | cli.toImg() | resize(50, 50) | shape() == (50, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf21e1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "noFill = object()\n",
    "class item(BaseCli):\n",
    "    def __init__(self, amt:int=1, fill=noFill):\n",
    "        \"\"\"Returns the first element of the input iterator.\n",
    "Example::\n",
    "\n",
    "    # returns 0\n",
    "    range(5) | item()\n",
    "    # returns torch.Size([5])\n",
    "    torch.randn(3,4,5) | item(2) | shape()\n",
    "    # returns 3\n",
    "    [] | item(fill=3)\n",
    "\n",
    ":param amt: how many times do you want to call item() back to back?\n",
    ":param fill: if iterator length is 0, return this\"\"\"\n",
    "        self.amt = amt; self.fill = fill\n",
    "        self.fillP = [fill] if fill != noFill else [] # preprocessed, to be faster\n",
    "        if self.amt != 1: self._f = cli.serial(*(item(fill=self.fill) for _ in range(self.amt)))\n",
    "    def _all_array_opt(self, it, level): return it[(*[slice(None, None, None) for i in range(level)], 0)]\n",
    "    def _typehint(self, inp):\n",
    "        if isinstance(inp, tListIterSet): return inp.child\n",
    "        if isinstance(inp, tCollection): return inp.children[0]\n",
    "        if isinstance(inp, tArrayTypes):\n",
    "            if inp.rank is None: return inp.__class__(inp.child, None)\n",
    "            if inp.rank - self.amt >= 1: return inp.__class__(inp.child, inp.rank-self.amt)\n",
    "            return inp.child\n",
    "        return tAny()\n",
    "    def __ror__(self, it:Iterator[str]):\n",
    "        if self.amt != 1: return it | self._f\n",
    "        if isinstance(it, settings.arrayTypes): return it[0]\n",
    "        if hasPandas and isinstance(it, pd.DataFrame): return it[:1].to_numpy()[0]\n",
    "        return next(iter(init.dfGuard(it)), *self.fillP)\n",
    "    def _jsF(self, meta):\n",
    "        fIdx = init._jsFAuto(); dataIdx = init._jsDAuto(); _slice = \"\".join([\"[0]\"]*self.amt)\n",
    "        return f\"{fIdx} = ({dataIdx}) => {dataIdx}{_slice}\", fIdx\n",
    "    def _pyF(self, expr, **kw): return \"\", \"\", f\"{expr}[0]\", {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98244e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert iter(range(5)) | tCheck() | item() == 0\n",
    "assert torch.randn(3,4,5) | tCheck() | item(2) | shape() == torch.Size([5])\n",
    "assert [] | item(fill=3) == 3\n",
    "assert \"test/crew dragon.jpg\" | cli.toImg() | shape() == (1280, 853)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "128d9373-660b-4166-ba96-8691227c0f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n\\ndef _pyF_350_11(_pyF_350_10):return _pyF_350_10[0]']\n"
     ]
    }
   ],
   "source": [
    "a = cli.toPyFunc() | item(); assert range(10) | a == 0; print([a.program])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50afebfc-578c-40b5-9458-32b7bfa159d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class rItem(BaseCli):\n",
    "    def __init__(self, idx:int):\n",
    "        \"\"\"Combines ``rows(idx) | item()``, as this is a pretty common pattern.\n",
    "Example::\n",
    "\n",
    "    iter(range(10)) | rItem(4) # returns 4\n",
    "\"\"\"\n",
    "        self.idx = idx; self.arrayTypes = (*settings.arrayTypes, list, tuple)\n",
    "    def _all_array_opt(self, it, level:int): return it[(*[slice(None, None, None) for i in range(level)], self.idx)]\n",
    "    def __ror__(self, it):\n",
    "        idx = self.idx\n",
    "        if isinstance(it, self.arrayTypes): return it[idx]\n",
    "        if hasPandas and isinstance(it, pd.DataFrame): return it[idx:idx+1].to_numpy()[0]\n",
    "        for i, e in zip(range(self.idx+1), it): pass\n",
    "        return e\n",
    "    def _jsF(self, meta):\n",
    "        fIdx = init._jsFAuto(); dataIdx = init._jsDAuto()\n",
    "        return f\"{fIdx} = ({dataIdx}) => {dataIdx}[{cli.kjs.v(self.idx)}]\", fIdx\n",
    "    def _pyF(self, expr, **kw): return \"\", \"\", f\"{expr}[{self.idx}]\", {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b53420b5-de03-4b5c-98d0-0b254c3c1648",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert iter(range(10)) | rItem(0) == 0\n",
    "assert iter(range(10)) | rItem(4) == 4\n",
    "assert iter(range(10)) | rItem(9) == 9\n",
    "assert np.random.randn(3, 4, 5, 6) | rItem(1) | cli.op().shape == (4, 5, 6)\n",
    "assert np.random.randn(3, 4, 5, 6) | rItem(1).all() | cli.op().shape == (3, 5, 6)\n",
    "assert isinstance(df1 | item(), np.ndarray)\n",
    "assert isinstance(df1 | rItem(1), np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34070d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class iden(BaseCli):\n",
    "    def __init__(self):\n",
    "        \"\"\"Yields whatever the input is. Useful for multiple streams.\n",
    "Example::\n",
    "\n",
    "    # returns range(5)\n",
    "    range(5) | iden()\"\"\"\n",
    "        super().__init__()\n",
    "    def _all_array_opt(self, it, level): return it\n",
    "    def _typehint(self, inp): return inp\n",
    "    def __ror__(self, it:Iterator[Any]): return it\n",
    "    def _jsF(self, meta):\n",
    "        fIdx = init._jsFAuto(); dataIdx = init._jsDAuto()\n",
    "        return f\"{fIdx} = ({dataIdx}) => {dataIdx}\", fIdx\n",
    "    def _pyF(self, expr, **kw): return \"\", \"\", expr, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14fe9733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n\\ndef _pyF_350_17(_pyF_350_16):return _pyF_350_16']\n"
     ]
    }
   ],
   "source": [
    "assert range(5) | tCheck() | iden() == range(5)\n",
    "a = cli.toPyFunc() | iden(); 3 | a == 3; print([a.program])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f25d7ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class join(BaseCli):\n",
    "    def __init__(self, delim:str=None):\n",
    "        r\"\"\"Merges all strings into 1, with `delim` in the middle. Basically\n",
    ":meth:`str.join`. Example::\n",
    "\n",
    "    # returns '2\\na'\n",
    "    [2, \"a\"] | join(\"\\n\")\"\"\"\n",
    "        super().__init__(); self.delim = patchDefaultDelim(delim)\n",
    "    def _typehint(self, inp): return str\n",
    "    def __ror__(self, it:Iterator[str]): return self.delim.join(init.dfGuard(it) | cli.apply(str))\n",
    "    def _jsF(self, meta): fIdx = init._jsFAuto(); dataIdx = init._jsDAuto(); return f\"{fIdx} = ({dataIdx}) => {dataIdx}.join({json.dumps(self.delim)})\", fIdx\n",
    "    def _pyF(self, expr, **kw): delimN = init._pyFAuto(); xN = init._pyFAuto(); return \"\", \"\", f\"{delimN}.join([str({xN}) for {xN} in {expr}])\", {delimN: self.delim}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73ca088e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert [2, \"a\"] | tCheck() | join(\"\\n\") == '2\\na'\n",
    "assert [2, \"a\"] | (cli.toPyFunc() | join(\"\\n\")) == '2\\na'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "056ae336-2d96-4327-a658-8d2705a5fd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class wrapList(BaseCli):\n",
    "    def __init__(self):\n",
    "        \"\"\"Wraps inputs inside a list. There's a more advanced cli tool\n",
    "built from this, which is :meth:`~k1lib.cli.structural.unsqueeze`. Example::\n",
    "\n",
    "    # returns [5]\n",
    "    5 | wrapList()\"\"\"\n",
    "        super().__init__()\n",
    "    def _all_array_opt(self, it, level): return it[(*[slice(None)]*level, None)]\n",
    "    def _typehint(self, inp): return tList(inp)\n",
    "    def __ror__(self, it) -> List[Any]:\n",
    "        if isinstance(it, settings.arrayTypes): return it[None]\n",
    "        return [it]\n",
    "    def _jsF(self, meta): fIdx = init._jsFAuto(); dataIdx = init._jsDAuto(); return f\"{fIdx} = ({dataIdx}) => [{dataIdx}]\", fIdx\n",
    "    def _pyF(self, expr, **kw): return \"\", \"\", f\"[{expr}]\", {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62ae215a-1a20-4a55-83d1-156377927c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.random.randn(3, 4, 5) | wrapList().all() | cli.op().shape == (3, 1, 4, 5)\n",
    "assert np.random.randn(3, 4, 5) | wrapList() | cli.op().shape == (1, 3, 4, 5)\n",
    "assert [2, 3, 1] | (cli.toPyFunc() | wrapList()) == [[2, 3, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30f212ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _EarlyExp(Exception): pass\n",
    "class equals:\n",
    "    def __init__(self):\n",
    "        \"\"\"Checks if all incoming columns/streams are identical\"\"\"\n",
    "        super().__init__()\n",
    "    def __ror__(self, streams:Iterator[Iterator[str]]):\n",
    "        streams = list(streams)\n",
    "        for row in zip(*streams):\n",
    "            sampleElem = row[0]\n",
    "            try:\n",
    "                for elem in row:\n",
    "                    if sampleElem != elem: yield False; raise _EarlyExp()\n",
    "                yield True\n",
    "            except _EarlyExp: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61b75438-0d10-4435-a133-89e2ace68294",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(10)[slice(None, None, -1)] | cli.deref()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54b35911",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class reverse(BaseCli):\n",
    "    def __init__(self):\n",
    "        \"\"\"Reverses incoming list.\n",
    "Example::\n",
    "\n",
    "    # returns [3, 5, 2]\n",
    "    [2, 5, 3] | reverse() | deref()\"\"\"\n",
    "        super().__init__()\n",
    "    def _all_array_opt(self, it, level): return it[(*[slice(None)]*level, slice(None, None, -1))]\n",
    "    def _typehint(self, inp):\n",
    "        if isinstance(inp, tListIterSet): return tIter(inp.child)\n",
    "        return tAny()\n",
    "    def __ror__(self, it:Iterator[str]) -> List[str]:\n",
    "        if isinstance(it, settings.arrayTypes): return it[::-1]\n",
    "        if hasPandas and isinstance(it, pd.core.arraylike.OpsMixin): return it[::-1]\n",
    "        return reversed(list(it))\n",
    "    def _jsF(self, meta): fIdx = init._jsFAuto(); dataIdx = init._jsDAuto(); return f\"{fIdx} = ({dataIdx}) => [...{dataIdx}].reverse()\", fIdx\n",
    "    def _pyF(self, expr, **kw): return \"\", \"\", f\"list(reversed({expr}))\", {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03a81772",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert [2, 5, 3] | tCheck() | reverse() | cli.deref() == [3, 5, 2]\n",
    "assert [2, 5, 3] | (cli.toPyFunc() | reverse()) == [3, 5, 2]\n",
    "assert np.random.randn(3, 4, 5) | reverse().all() | cli.op().shape == (3, 4, 5)\n",
    "assert isinstance(df1 | reverse(), pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "009bee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ignore(BaseCli):\n",
    "    def __init__(self):\n",
    "        r\"\"\"Just loops through everything, ignoring the output.\n",
    "Example::\n",
    "\n",
    "    # will just return an iterator, and not print anything\n",
    "    [2, 3] | apply(lambda x: print(x))\n",
    "    # will prints \"2\\n3\"\n",
    "    [2, 3] | apply(lambda x: print(x)) | ignore()\"\"\"\n",
    "        super().__init__()\n",
    "    def _all_array_opt(self, it, level): return it\n",
    "    def _typehint(self, inp): return type(None)\n",
    "    def __ror__(self, it:Iterator[Any]):\n",
    "        if isinstance(it, settings.arrayTypes): return\n",
    "        if hasPandas and isinstance(it, pd.core.arraylike.OpsMixin): return\n",
    "        for _ in it: pass\n",
    "    def _jsF(self, meta): fIdx = init._jsFAuto(); dataIdx = init._jsDAuto(); return f\"{fIdx} = ({dataIdx}) => {dataIdx}\", fIdx\n",
    "    def _pyF(self, expr, **kw): return \"\", \"\", f\"[None for x in {expr}] and None\", {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9b78fb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "with k1lib.captureStdout() as out:\n",
    "    [2, 3] | cli.apply(lambda x: print(x))\n",
    "assert len(out()) == 1\n",
    "with k1lib.captureStdout() as out:\n",
    "    [2, 3] | tCheck() | cli.apply(lambda x: print(x)) | ignore()\n",
    "assert out() == [\"2\", \"3\", '']\n",
    "assert [2, 3] | (cli.toPyFunc() | ignore()) == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53bc0810-f77a-462c-851c-328eb6ce22ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class rateLimit(BaseCli):\n",
    "    def __init__(self, f, delay=0.1):\n",
    "        \"\"\"Limits the execution flow rate upon a condition.\n",
    "Example::\n",
    "\n",
    "    s = 0; semaphore = 0\n",
    "    def heavyAsyncOperation(i):\n",
    "        global semaphore, s\n",
    "        semaphore += 1\n",
    "        s += i; time.sleep(1)\n",
    "        semaphore -= 1; return i**2\n",
    "\n",
    "    # returns (20,), takes 1s to run\n",
    "    range(20) | applyTh(heavyAsyncOperation, 100) | shape()\n",
    "    # returns (20,), takes 4s to run (20/5 = 4)\n",
    "    range(20) | rateLimit(lambda: semaphore < 5) | applyTh(heavyAsyncOperation, 100) | shape()\n",
    "\n",
    "The first test case is not rate-limited, so it will run all 20 threads at the\n",
    "same time, and all of them will finish after 1 second.\n",
    "\n",
    "The second test case is rate-limited, so that there can only be 5 concurrently\n",
    "executing threads because of the semaphore count check. Therefore this takes\n",
    "around 4 seconds to run.\n",
    "\n",
    ":param f: checking function. Should return true if execution is allowed\n",
    ":param delay: delay in seconds between calling ``f()``\"\"\"\n",
    "        self.f = f; self.delay = delay\n",
    "    def _typehint(self, inp):\n",
    "        if isinstance(inp, tListIterSet): return tIter(inp.child)\n",
    "        if isinstance(inp, tArrayTypes):\n",
    "            if inp.rank is None: return tIter(inp)\n",
    "            if inp.rank >= 2: return tIter(inp.__class__(inp.child, inp.rank - 1))\n",
    "            return tIter(inp.child)\n",
    "        if isinstance(inp, tCollection): return inp\n",
    "        return tAny()\n",
    "    def __ror__(self, it):\n",
    "        f = self.f; delay = self.delay\n",
    "        for e in init.dfGuard(it):\n",
    "            while not f(): time.sleep(delay)\n",
    "            yield e\n",
    "    @staticmethod\n",
    "    def cpu(maxUtilization=90):\n",
    "        \"\"\"Limits flow rate when cpu utilization is more than a specified\n",
    "percentage amount. Needs to install the package ``psutil`` to actually work.\n",
    "Example::\n",
    "\n",
    "    # returns [0, 1, 4, 9, 16]\n",
    "    range(5) | rateLimit.cpu() | apply(op()**2) | deref()\"\"\"\n",
    "        import psutil\n",
    "        return rateLimit(lambda: psutil.cpu_percent() < maxUtilization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86b68858-d598-49ae-bac9-37b23653d17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0; semaphore = 0\n",
    "def heavyAsyncOperation(i):\n",
    "    global semaphore, s\n",
    "    semaphore += 1\n",
    "    s += i; time.sleep(1)\n",
    "    semaphore -= 1; return i**2\n",
    "with k1lib.timer() as t:\n",
    "    assert range(20) | rateLimit(lambda: semaphore < 5) | cli.applyTh(heavyAsyncOperation, 100) | cli.shape() == (20,)\n",
    "assert 3.5 < t() < 4.5\n",
    "with k1lib.timer() as t:\n",
    "    assert range(20) | cli.applyTh(heavyAsyncOperation, 100) | cli.shape() == (20,)\n",
    "assert 0.5 < t() < 1.5\n",
    "assert range(5) | rateLimit.cpu() | cli.apply(cli.op()**2) | cli.deref() == [0, 1, 4, 9, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58487d75-7a25-4cf8-b801-3196994d110a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class timeLimit(BaseCli):\n",
    "    def __init__(self, t):\n",
    "        \"\"\"Caps the flow after a specified amount of time has\n",
    "passed. Example::\n",
    "\n",
    "    # returns 20, or roughly close to that\n",
    "    repeatF(lambda: time.sleep(0.1)) | timeLimit(2) | shape(0)\"\"\"\n",
    "        self.t = t\n",
    "    def _typehint(self, inp):\n",
    "        if isinstance(inp, tListIterSet): return tIter(inp.child)\n",
    "        if isinstance(inp, tArrayTypes):\n",
    "            if inp.rank is None: return tIter(inp)\n",
    "            if inp.rank >= 2: return tIter(inp.__class__(inp.child, inp.rank - 1))\n",
    "            return tIter(inp.child)\n",
    "        if isinstance(inp, tCollection): return inp\n",
    "        return tAny()\n",
    "    def __ror__(self, it):\n",
    "        _time = time.time; endTime = _time() + self.t\n",
    "        for e in init.dfGuard(it):\n",
    "            yield e\n",
    "            if _time() > endTime: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e929e96-fc0f-4291-b5d6-8f8ff7a6645f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert cli.repeatF(lambda: time.sleep(0.1)) | timeLimit(2) | shape(0) | cli.op() - 20 | cli.aS(abs) | cli.op() < 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c2ec3176-8cd7-436f-acd7-54e324a49eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class tab(BaseCli):\n",
    "    def __init__(self, pad:str=\" \"*4):\n",
    "        \"\"\"Indents incoming string iterator.\n",
    "Example::\n",
    "\n",
    "    # prints out indented 0 to 9\n",
    "    range(10) | tab() | headOut()\"\"\"\n",
    "        self.pad = pad\n",
    "    def __ror__(self, it):\n",
    "        pad = self.pad\n",
    "        for x in it: yield f\"{pad}{x}\"\n",
    "    def _pyF(self, expr, **kw):\n",
    "        return \"\", \"\", f\"('{self.pad}' + str(x) for x in {expr})\", {}\n",
    "indent = tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7ed5095a-1ab2-4dc1-932b-bd80c7554a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert range(2) | tab() | cli.join(\"|\") == '    0|    1'\n",
    "assert range(2) | (cli.toPyFunc() | tab() | cli.join(\"|\")) == '    0|    1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0bf05ed4-4779-48d5-b0b3-156a3a739049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class clipboard(BaseCli):\n",
    "    def __init__(self):\n",
    "        \"\"\"Saves the input to clipboard.\n",
    "Example::\n",
    "\n",
    "    # copies \"abc\" into the clipboard. Just use Ctrl+V to paste as usual\n",
    "    \"abc\" | clipboard()\"\"\"\n",
    "        import pyperclip; self.pyperclip = pyperclip\n",
    "    def _typehint(self, inp): return type(None)\n",
    "    def __ror__(self, s): self.pyperclip.copy(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34177a17-2ac3-4f3d-9f91-ed7e38176d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert \"def2r\" | tCheck() | clipboard() == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4320628",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "a = [numbers.Number, np.number, str, bool, bytes, k1lib.UValue, cli.conv.Audio]\n",
    "if hasTorch: a.append(torch.nn.Module)\n",
    "if hasRos1: a.append(rosbag.bag.BagMessage)\n",
    "if hasPandas: a.append(pd.core.arraylike.OpsMixin)\n",
    "settings.atomic.add(\"deref\", tuple(a), \"used by deref\")\n",
    "Tensor = torch.Tensor; atomic = settings.atomic\n",
    "class inv_dereference(BaseCli):\n",
    "    def __init__(self, igT=False):\n",
    "        \"\"\"Kinda the inverse to :class:`dereference`\"\"\"\n",
    "        super().__init__(); self.igT = igT\n",
    "    def __ror__(self, it:Iterator[Any]) -> List[Any]:\n",
    "        for e in it:\n",
    "            if e is None or isinstance(e, atomic.deref): yield e\n",
    "            elif isinstance(e, settings.arrayTypes):\n",
    "                if not self.igT and len(e.shape) == 0: yield e.item()\n",
    "                else: yield e\n",
    "            else:\n",
    "                try: yield e | self\n",
    "                except: yield e\n",
    "_rosmsg_tempfile = [None]; _rosmsg_autoInc = k1lib.AutoIncrement()\n",
    "def rosmsg2BagMessage(msg): # kinda abandoned. Turns out you can't pickle a BagMessage cleanly afterall. I kinda have to do it the long way. If you want to be able to serialize a message, just do `obj | deref()`, it will wrap around using RosMsg(), which is serializable\n",
    "    if _rosmsg_tempfile[0] is None: _rosmsg_tempfile[0] = b\"\" | cli.file()\n",
    "    fn = f\"{_rosmsg_tempfile[0]}_{os.getpid()}_{_rosmsg_autoInc()}\"\n",
    "    with rosbag.Bag(fn, \"w\") as bag: bag.write(\"/default\", msg)\n",
    "    res = rosbag.Bag(fn, \"r\").read_messages() | cli.item()\n",
    "    os.remove(fn); return res\n",
    "_rosmsg_tempfile2 = [None]; _rosmsg_autoInc2 = k1lib.AutoIncrement()\n",
    "def _rosmsg_getFn2():\n",
    "    if _rosmsg_tempfile2[0] is None: _rosmsg_tempfile2[0] = b\"\" | cli.file(); os.remove(_rosmsg_tempfile2[0])\n",
    "    return f\"{_rosmsg_tempfile2[0]}_{os.getpid()}_{_rosmsg_autoInc2()}\"\n",
    "class RosMsg:\n",
    "    def __init__(self, msg): self._ab_sentinel = True; self.__msg = msg; self._ab_sentinel = False\n",
    "    def __getattr__(self, attr):\n",
    "        if attr == \"__msg\": return self.__msg\n",
    "        return getattr(self.__msg, attr)\n",
    "    def __getstate__(self):\n",
    "        fn = _rosmsg_getFn2()\n",
    "        with rosbag.Bag(fn, \"w\") as bag: bag.write(\"/default\", self.__msg)\n",
    "        with open(fn, \"rb\") as f: raw = f.read()\n",
    "        os.remove(fn); return {\"raw\": raw}\n",
    "    def __setstate__(self, d):\n",
    "        fn = _rosmsg_getFn2()\n",
    "        with open(fn, \"wb\") as f: f.write(d[\"raw\"])\n",
    "        with rosbag.Bag(fn) as bag: self.__msg = next(bag.read_messages()).message\n",
    "        os.remove(fn)\n",
    "    def __repr__(self): return self.__msg.__repr__()\n",
    "_rosMsgArrayTypes = k1lib.settings.cli.arrayTypes\n",
    "class RosMsgPlaceholder:\n",
    "    def __init__(self, idx): self.idx = idx\n",
    "def _rosmsg_complex_deref_replace(it, autoInc, msgs):\n",
    "    if isinstance(it, np.number): return it.item()\n",
    "    elif isinstance(it, k1lib.settings.cli.atomic.deref): return it\n",
    "    elif isinstance(it, _rosMsgArrayTypes): return it\n",
    "    elif isinstance(it, dict):  _d = {k:   _rosmsg_complex_deref_replace(v, autoInc, msgs) for k, v in it.items()}; return _d\n",
    "    elif isinstance(it, tuple): _t = tuple(_rosmsg_complex_deref_replace(k, autoInc, msgs) for k    in it);         return _t\n",
    "    elif isinstance(it, set):   _s = set  (_rosmsg_complex_deref_replace(k, autoInc, msgs) for k    in it);         return _s\n",
    "    elif isinstance(it, genpy.message.Message): idx = autoInc(); msgs[idx] = it; return RosMsgPlaceholder(idx)\n",
    "    elif isinstance(it, RosMsg): idx = autoInc(); msgs[idx] = it.__msg; return RosMsgPlaceholder(idx)\n",
    "    try: iter(it)\n",
    "    except: return it\n",
    "    answer = []\n",
    "    for e in it:\n",
    "        if e is cli.yieldT: return answer\n",
    "        answer.append(_rosmsg_complex_deref_replace(e, autoInc, msgs))\n",
    "    return answer\n",
    "def _rosmsg_complex_deref_reconstruct(it, msgs):\n",
    "    if isinstance(it, np.number): return it.item()\n",
    "    elif isinstance(it, k1lib.settings.cli.atomic.deref): return it\n",
    "    elif isinstance(it, _rosMsgArrayTypes): return it\n",
    "    elif isinstance(it, dict):  _d = {k:   _rosmsg_complex_deref_reconstruct(v, msgs) for k, v in it.items()}; return _d\n",
    "    elif isinstance(it, tuple): _t = tuple(_rosmsg_complex_deref_reconstruct(k, msgs) for k    in it);         return _t\n",
    "    elif isinstance(it, set):   _s = set  (_rosmsg_complex_deref_reconstruct(k, msgs) for k    in it);         return _s\n",
    "    elif isinstance(it, RosMsgPlaceholder): return msgs[it.idx]\n",
    "    try: iter(it)\n",
    "    except: return it\n",
    "    answer = []\n",
    "    for e in it:\n",
    "        if e is cli.yieldT: return answer\n",
    "        answer.append(_rosmsg_complex_deref_reconstruct(e, msgs))\n",
    "    return answer\n",
    "class RosMsgComplex:\n",
    "    def __init__(self, data):\n",
    "        \"\"\"An attempt to speed up serialization of ROS messages.\n",
    "Normally, I'd do this::\n",
    "\n",
    "    [msg1, msg2, ...] | deref() | aS(dill.dumps) | file(\"...\")\n",
    "\n",
    "But this is a little inefficient as the process of writing to and reading from a temp bag file\n",
    "is not that fast. So this kinda bunches up all messages, write them into a single bag file, and\n",
    "have clever mechanism to reconstruct the structure.\n",
    "\n",
    "Turns out lots of messages can bog down the system. This does reduce load time by 2 times and disk\n",
    "size by 3 times. So it's effective, but just not wildly effective. This is not exposed automatically\n",
    "on the docs cause I don't feel like it's fast enough to justify that, but I couldn't just delete this.\"\"\"\n",
    "        self.data = data\n",
    "    def __getstate__(self):\n",
    "        fn = _rosmsg_getFn2()\n",
    "        with rosbag.Bag(fn, \"w\") as bag:\n",
    "            msgs = {}; struct = _rosmsg_complex_deref_replace(self.data, k1lib.AutoIncrement(prefix=\"/_rosmsg_\"), msgs)\n",
    "            for k, v in msgs.items(): bag.write(k, v)\n",
    "        with open(fn, \"rb\") as f: raw = f.read()\n",
    "        res = {\"struct\": dill.dumps(struct), \"raw\": raw}; os.remove(fn); return res\n",
    "    def __setstate__(self, d):\n",
    "        fn = _rosmsg_getFn2()\n",
    "        with open(fn, \"wb\") as f: f.write(d[\"raw\"])\n",
    "        msgs = {x.topic:x for x in rosbag.Bag(fn).read_messages()}\n",
    "        self.data = _rosmsg_complex_deref_reconstruct(d[\"struct\"], msgs); os.remove(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19cd44e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class deref(BaseCli):\n",
    "    def __init__(self, maxDepth=float(\"inf\"), igT=True):\n",
    "        \"\"\"Recursively converts any iterator into a list.\n",
    "Example::\n",
    "\n",
    "    \n",
    "    iter(range(5))              # returns something like \"<range_iterator at 0x7fa8c52ca870>\"\n",
    "    iter(range(5)) | deref()    # returns [0, 1, 2, 3, 4]\n",
    "    [2, 3, yieldT, 6] | deref() # returns [2, 3], yieldT stops things early\n",
    "\n",
    "You can also specify a ``maxDepth``::\n",
    "\n",
    "    iter([range(3)]) | deref(0) # returns something like \"<list_iterator at 0x7f810cf0fdc0>\"\n",
    "    iter([range(3)]) | deref(1) # returns [range(3)]\n",
    "    iter([range(3)]) | deref(2) # returns [[0, 1, 2]]\n",
    "\n",
    "There are a few classes/types that are considered atomic, and :class:`deref`\n",
    "will never try to iterate over it. If you wish to change it, do something like::\n",
    "\n",
    "    settings.cli.atomic.deref = (int, float, ...)\n",
    "\n",
    ":param maxDepth: maximum depth to dereference. Starts at 0 for not doing anything\n",
    "    at all\n",
    ":param igT: short for \"ignore tensor\". If True, then don't loop over :class:`torch.Tensor`\n",
    "    and :class:`numpy.ndarray` internals\"\"\"\n",
    "        super().__init__(); self.igT = igT\n",
    "        self.maxDepth = maxDepth; self.depth = 0\n",
    "        if hasTorch: self.arrayType = (torch.Tensor, np.ndarray) if k1lib.settings.startup.or_patch.numpy else torch.Tensor\n",
    "        else: self.arrayType = (np.ndarray,) if k1lib.settings.startup.or_patch.numpy else ()\n",
    "    def _typehint(self, inp, depth=float(\"inf\")):\n",
    "        if depth == 0: return inp\n",
    "        if depth == float(\"inf\"): depth = self.maxDepth\n",
    "        if isinstance(inp, type) and issubclass(inp, atomic.deref): return inp\n",
    "        if isinstance(inp, tArrayTypes):\n",
    "            if self.igT: return inp\n",
    "            if inp.rank is None: return tList(tAny())\n",
    "            if inp.rank == 1:\n",
    "                if isinstance(inp, tTensor):\n",
    "                    return tList(type(torch.tensor(3, dtype=inp.child).item()))\n",
    "                if isinstance(inp, tNpArray):\n",
    "                    return tList(type(np.array(3, dtype=inp.child).item()))\n",
    "            return tList(self._typehint(inp.item(), depth-1))\n",
    "        if isinstance(inp, tListIterSet):\n",
    "            return tList(self._typehint(inp.child, depth-1))\n",
    "        if isinstance(inp, tCollection):\n",
    "            return tCollection(*(self._typehint(e, depth-1) for e in inp.children))\n",
    "        return tAny()\n",
    "    def __ror__(self, it:Iterator[Any]) -> List[Any]:\n",
    "        if self.depth >= self.maxDepth: return it\n",
    "        elif isinstance(it, np.number): return it.item()\n",
    "        elif isinstance(it, atomic.deref): return it\n",
    "        elif isinstance(it, self.arrayType):\n",
    "            if self.igT: return it\n",
    "            if len(it.shape) == 0: return it.item()\n",
    "        elif isinstance(it, dict):  self.depth += 1; _d = {k:   self.__ror__(v) for k, v in it.items()}; self.depth -= 1; return _d\n",
    "        elif isinstance(it, tuple): self.depth += 1; _t = tuple(self.__ror__(k) for k    in it);         self.depth -= 1; return _t\n",
    "        elif isinstance(it, set):   self.depth += 1; _s = set  (self.__ror__(k) for k    in it);         self.depth -= 1; return _s\n",
    "        elif hasRos1 and isinstance(it, genpy.message.Message): return RosMsg(it) # return rosmsg2BagMessage(it)\n",
    "        try: iter(it)\n",
    "        except: return it\n",
    "        self.depth += 1; answer = []\n",
    "        for e in it:\n",
    "            if e is cli.yieldT: return answer\n",
    "            answer.append(self.__ror__(e))\n",
    "        self.depth -= 1; return answer\n",
    "    def __invert__(self) -> BaseCli:\n",
    "        \"\"\"Returns a :class:`~k1lib.cli.init.BaseCli` that makes\n",
    "everything an iterator. Not entirely sure when this comes in handy, but it's\n",
    "there.\"\"\"\n",
    "        return inv_dereference(self.igT)\n",
    "    def _jsF(self, meta):\n",
    "        fIdx = init._jsFAuto(); dataIdx = init._jsDAuto()\n",
    "        return f\"{fIdx} = ({dataIdx}) => {dataIdx}\", fIdx\n",
    "    @staticmethod\n",
    "    def js():\n",
    "        \"\"\"Deref incoming object and turn them into a js object (NOT json string!).\n",
    "Example::\n",
    "\n",
    "    # returns \"[...Array(10).keys()]\"\n",
    "    range(10) | deref.json()\n",
    "\n",
    "How does it know to transpile it? Based on the dictionary at `settings.cli.kjs.jsonF`\n",
    "and the object's \"._jsonF\" function. Say you have a custom list object, you can do\n",
    "something like this::\n",
    "\n",
    "    class CustomList:\n",
    "        def __init__(self): ...\n",
    "        def _jsonF(self): return \"your js string here\"\n",
    "\n",
    "Or, you can do something like this::\n",
    "\n",
    "    class CustomList: ...\n",
    "    settings.cli.kjs.jsonF[CustomList] = lambda obj: \"your js string here\"\n",
    "\n",
    "A variety of data types are included out of the box already for common types,\n",
    "view the source code of this method to check them out.\"\"\"\n",
    "        jsonF = settings.kjs.jsonF\n",
    "        jsonF[list] = lambda x: \"[\" + \", \".join([deref_js(e) for e in x]) + \"]\"\n",
    "        jsonF[str] = lambda x: json.dumps(x)\n",
    "        jsonF[tuple] = jsonF[list]; jsonF[set] = lambda x: \"new Set(\" + jsonF[list](x) + \")\"\n",
    "        jsonF[type(None)] = lambda x: \"null\"\n",
    "        jsonF[np.ndarray] = lambda x: json.dumps(x | deref(igT=False))\n",
    "        if hasTorch: jsonF[torch.Tensor] = lambda x: json.dumps(x | deref(igT=False))\n",
    "        jsonF[type(iter(range(10)))] = lambda x: \"[\" + \", \".join([str(e) for e in x]) + \"]\"\n",
    "        jsonF[type((x for x in range(0)))] = jsonF[list]\n",
    "        jsonF[type({}.keys())] = jsonF[list]; jsonF[type({}.values())] = jsonF[list]\n",
    "        jsonF[dict] = lambda x: \"{\" + \", \".join([f\"{json.dumps(k)}: {deref_js(v)}\" for k,v in x.items()]) + \"}\"\n",
    "        jsonF[defaultdict] = jsonF[dict]\n",
    "        deref.js = lambda: cli.aS(deref_js); return deref.js() # initializes at runtime, then patches deref.json() to get a faster path!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c8db1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, numbers, torch\n",
    "a = torch.linspace(0, 10, 50) | deref(igT=False)\n",
    "b = torch.from_numpy(np.linspace(0, 10, 50)) | deref(igT=False)\n",
    "assert torch.allclose(torch.tensor(b), torch.tensor(a))\n",
    "assert iter([range(3)]) | tCheck() | deref(1) == [range(3)]\n",
    "assert iter([range(3)]) | tCheck() | deref(2) == [[0, 1, 2]]\n",
    "assert torch.randn(2, 3) | tCheck() | deref(igT=False) | ~deref() | deref() | shape() == (2, 3)\n",
    "assert [2, 3, cli.yieldT, 6] | deref() == [2, 3]\n",
    "with k1lib.settings.cli.atomic.context(deref=(int, float, ...)): assert k1lib.settings.cli.atomic.deref == (int, float, ...)\n",
    "assert np.array([[1, 2, 3], [4, 5, 6]]) | tCheck() | deref(igT=False) == [[1, 2, 3], [4, 5, 6]]\n",
    "assert {\"a\": range(3)} | tCheck() | deref() == {'a': [0, 1, 2]}\n",
    "assert deref(1, igT=False)._typehint(tTensor(float, 2)) == tList(tTensor(float, 1))\n",
    "assert deref(1, igT=False)._typehint(tTensor(float, 2)) != tList(tTensor(float, 2))\n",
    "assert deref(igT=False)._typehint(tTensor(float, 2)) == tList(tList(float))\n",
    "assert deref()._typehint(tList(tList(int))) == tList(tList(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ce4dc32-42c2-4594-b38b-9a2af1db6a90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def deref_js(obj):\n",
    "    # only 2 special cases, perf considerations, everything else is pluggable\n",
    "    if isinstance(obj, bool): return \"true\" if obj else \"false\"\n",
    "    if isinstance(obj, (numbers.Number, np.number)): return str(obj)\n",
    "    fn = settings.kjs.jsonF.get(type(obj), None)\n",
    "    if fn: return fn(obj)\n",
    "    if hasattr(obj, \"_jsonF\"): return obj._jsonF()\n",
    "    raise Exception(f\"Don't know how to transcribe object with class {type(obj)}. Either add the serialization function to `settings.cli.kjs.jsonF`, or implement the function `._jsonF()` to your custom class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "21722dea-57ee-48de-aef8-13642a5ede7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def g(): yield 4; yield 2\n",
    "assert [range(10), 4, set(range(10)), None, np.linspace(2, 10, 5), iter(range(5)), g(), \"abc\", '\"abc\"', True, {\"a\": 3, \"b\": [3, 4]}] | deref.js() == '[[...Array(10).keys()], 4, new Set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), null, [2.0, 4.0, 6.0, 8.0, 10.0], [0, 1, 2, 3, 4], [4, 2], \"abc\", \"\\\\\"abc\\\\\"\", true, {\"a\": 3, \"b\": [3, 4]}]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "154a8456",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class bindec(BaseCli):\n",
    "    def __init__(self, cats:List[Any], f=None):\n",
    "        \"\"\"Binary decodes the input.\n",
    "Example::\n",
    "\n",
    "    # returns ['a', 'c']\n",
    "    5 | bindec(\"abcdef\")\n",
    "    # returns 'a,c'\n",
    "    5 | bindec(\"abcdef\", join(\",\"))\n",
    "\n",
    ":param cats: categories\n",
    ":param f: transformation function of the selected elements. Defaulted to :class:`~k1lib.cli.conv.toList`, but others like :class:`join` is useful too\"\"\"\n",
    "        self.cats = cats; self.f = f or cli.toList()\n",
    "    def __ror__(self, it):\n",
    "        it = bin(int(it))[2:][::-1]\n",
    "        return (e for i, e in zip(it, self.cats) if i == '1') | self.f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "383375bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 5 | bindec(\"abcdef\") == ['a', 'c']\n",
    "assert 5 | bindec(\"abcdef\", join(\",\")) == \"a,c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f98ddad0-8858-4a30-8fd8-7e7788e692bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "settings.add(\"smooth\", 10, \"default smooth amount, used in utils.smooth\")\n",
    "class smooth(BaseCli):\n",
    "    def __init__(self, consecutives=None, windowing=False):\n",
    "        \"\"\"Smoothes out the input stream.\n",
    "Literally just a shortcut for::\n",
    "\n",
    "    batched(consecutives) | toMean().all()\n",
    "\n",
    "Example::\n",
    "\n",
    "    # returns [4.5, 14.5, 24.5]\n",
    "    range(30) | smooth(10) | deref()\n",
    "\n",
    "Smoothing over :class:`torch.Tensor` or :class:`numpy.ndarray` will\n",
    "be much faster::\n",
    "\n",
    "    # returns torch.Tensor with shape (2)\n",
    "    torch.randn(10, 3, 4) | smooth(4)\n",
    "\n",
    "The default consecutive value is in ``settings.cli.smooth``. This\n",
    "is useful if you are smoothing over multiple lists at the same\n",
    "time, like this::\n",
    "\n",
    "    # can change a single smooth value temporarily here, and all sequences will be smoothed in the same way\n",
    "    with settings.cli.context(smooth=5):\n",
    "        x = list(np.linspace(-2, 2, 50))\n",
    "        y = x | apply(op()**2) | deref()\n",
    "        plt.plot(x | smooth() | deref(), y | smooth() | deref())\n",
    "\n",
    ":param consecutives: if not defined, then used the value inside ``settings.cli.smooth``\"\"\"\n",
    "        n = consecutives or settings.smooth; self.b = cli.window(n) if windowing else cli.batched(n)\n",
    "        self.consecutives = consecutives; self.windowing = windowing\n",
    "    def _all_array_opt(self, it, level): return it | (self.b | cli.toMean().all()).all(level)\n",
    "    def __ror__(self, it): return init.dfGuard(it) | self.b | cli.toMean().all()\n",
    "    def _jsF(self, meta):\n",
    "        if self.windowing: raise Exception(f\"._jsF() does not support windowing in smooth() yet\")\n",
    "        fIdx = init._jsFAuto(); dataIdx = init._jsDAuto()\n",
    "        return f\"{fIdx} = ({dataIdx}) => {dataIdx}.smooth({cli.kjs.v(self.consecutives)})\", fIdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "74df162d-63b0-4aa1-91ad-abc88e72e443",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert range(30) | smooth(10) | deref() == [4.5, 14.5, 24.5]\n",
    "assert range(30) | smooth() | deref() == [4.5, 14.5, 24.5]\n",
    "with settings.context(smooth=5):\n",
    "    x = list(np.linspace(-2, 2, 50))\n",
    "    y = x | cli.apply(cli.op()**2) | deref()\n",
    "    assert x | smooth() | shape(0) == 10\n",
    "    assert y | smooth() | shape(0) == 10\n",
    "assert torch.randn(10, 3, 4) | smooth(4) | shape() | cli.op() == (2,)\n",
    "assert np.random.randn(10,4,3) | smooth(2, True).all() | cli.aS(type) == np.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6f82b7b2-c1a2-4f11-8f77-c8b08b905173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def _f(): pass\n",
    "_code = type(_f.__code__)\n",
    "def disassemble(f=None):\n",
    "    \"\"\"Disassembles anything piped into it.\n",
    "Normal usage::\n",
    "\n",
    "    def f(a, b):\n",
    "        return a**2 + b\n",
    "    # both of these print out disassembled info\n",
    "    f | disassemble()\n",
    "    disassemble(f)\n",
    "    \n",
    "    # you can pass in lambdas\n",
    "    disassemble(lambda x: x + 3)\n",
    "    \n",
    "    # or even raw code\n",
    "    \"lambda x: x + 3\" | disassemble()\"\"\"\n",
    "    c = f\n",
    "    if c is None: return cli.aS(disassemble)\n",
    "    if isinstance(c, str): c = compile(c, \"\", \"exec\")\n",
    "    try: c = c.__code__\n",
    "    except: pass\n",
    "    if not isinstance(c, _code): raise RuntimeError(f\"`{c}` is not a code object/function/class method/string code\")\n",
    "    print(f\"co_argcount: {c.co_argcount}\")\n",
    "    print(f\"co_cellvars: {c.co_cellvars}\")\n",
    "    print(f\"co_consts: {c.co_consts}\")\n",
    "    print(f\"co_filename: {c.co_filename}\")\n",
    "    print(f\"co_firstlineno: {c.co_firstlineno}\")\n",
    "    print(f\"co_flags: {c.co_flags}\")\n",
    "    print(f\"co_freevars: {c.co_freevars}\")\n",
    "    print(f\"co_kwonlyargcount: {c.co_kwonlyargcount}\")\n",
    "    print(f\"co_lnotab: {c.co_lnotab | cli.apply(str) | join(' ')}\")\n",
    "    print(f\"co_name: {c.co_name}\")\n",
    "    print(f\"co_names: {c.co_names}\")\n",
    "    print(f\"co_nlocals: {c.co_nlocals}\")\n",
    "    print(f\"co_posonlyargcount: {c.co_posonlyargcount}\")\n",
    "    print(f\"co_stacksize: {c.co_stacksize}\")\n",
    "    print(f\"co_varnames: {c.co_varnames}\")\n",
    "    print(f\"Disassembly:\"); dis.disassemble(c)\n",
    "    with k1lib.captureStdout() as out:\n",
    "        c.co_consts | cli.filt(lambda x: \"code\" in str(type(x))) | cli.tee(lambda _: \"----------------------- inner code object -----------------------\\n\") | cli.apply(disassemble) | cli.ignore()\n",
    "    out() | cli.filt(cli.op().strip() != \"\") | cli.apply(\"|\" + cli.op()) | cli.indent() | cli.stdout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da7b918e-335d-4a68-8670-a5499047747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(a, b):\n",
    "    return a**2 + b\n",
    "with k1lib.captureStdout() as out:\n",
    "    f | disassemble(); disassemble(f);\n",
    "    \"lambda x: x + 3\" | disassemble()\n",
    "    disassemble(lambda x: x + 3)\n",
    "assert out() | cli.shape(0) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7746bec9-8989-4ea0-9998-f38a6409fc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "shortName = lambda s: s.split(os.sep)[-1]\n",
    "def tree(fL=10, dL=10, depth=float(\"inf\"), ff:Callable[[str], bool]=(lambda s: True), df:Callable[[str], bool]=(lambda s: True)):\n",
    "    \"\"\"Recursively gets all files and folders. Output format might be a bit\n",
    "strange, so this is mainly for visualization. Example::\n",
    "\n",
    "    \".\" | tree() | deref()\n",
    "\n",
    "This is way less powerful and structured than clis from the module :mod:`k1lib.cli.ktree`.\n",
    "Check that out. This cli is mainly for backwards compability.\n",
    "\n",
    ":param fL: max number of file per directory included in output\n",
    ":param dL: max number of child directories per directory included in output\n",
    ":param depth: explore depth\n",
    ":param ff: optional file filter function\n",
    ":param df: optional directory filter function\"\"\"\n",
    "    processFolders = cli.apply(lambda x: [shortName(x), x]) | cli.apply(lambda x: x | tree(fL, dL, depth-1, ff, df) if depth > 0 else [], 1) | cli.toDict()\n",
    "    a = cli.filt(os.path.isfile) | cli.filt(ff) | cli.head(fL) | cli.apply(shortName) | cli.aS(set)\n",
    "    b = ~cli.filt(os.path.isfile) | cli.filt(df) | cli.head(dL) | processFolders\n",
    "    return cli.ls() | ~cli.sortF(os.path.isfile) | (a & b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "66767b93-6149-4c11-8e99-c18e22d7896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \".\" | tree() | shape() | shape(0) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cd1d7856-3115-46d4-aa96-6a95c2694008",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class lookup(BaseCli):\n",
    "    def __init__(self, d:dict, col:int=None, fill=None, mode:str=\"error\"):\n",
    "        \"\"\"Looks up items from a dictionary/object. Example::\n",
    "\n",
    "    d = {\"a\": 3, \"b\": 5, \"c\": 52}\n",
    "    \"abcca\" | lookup(d) | deref() # returns [3, 5, 52, 52, 3]\n",
    "\n",
    "    \"abccad\" | lookup(d) | deref()                     # raises Exception, as key \"d\" does not exist\n",
    "    \"abccad\" | lookup(d, fill=\"(not found)\") | deref() # returns [3, 5, 52, 52, 3, '(not found)'], mode automatically switched to \"fill\"\n",
    "    \"abccad\" | lookup(d, mode=\"fill\")  | deref()       # returns [3, 5, 52, 52, 3, None]. Do this when you really want to return None\n",
    "    \"abccad\" | lookup(d, fill=input)   | deref()       # returns [3, 5, 52, 52, 3, 'd'], mode automatically switched to \"input\"\n",
    "    \"abccad\" | lookup(d, mode=\"input\") | deref()       # returns [3, 5, 52, 52, 3, 'd'], similar to above\n",
    "    \"abccad\" | lookup(d, mode=\"rm\")    | deref()       # returns [3, 5, 52, 52, 3], removing the unknown element\n",
    "\n",
    "    [range(5), \"abcca\"] | transpose() | lookup(d, 1) | deref() # returns [[0, 3], [1, 5], [2, 52], [3, 52], [4, 3]]\n",
    "\n",
    "The ``mode`` param needs a little explaning. It specifies what should happen when an element is not found\n",
    "within the given dictionary. There are 3 modes total:\n",
    "- error: if ``.fill`` is not None, then throws an error. If ``.fill`` is specified, then this acts like mode \"fill\" instead\n",
    "- input: returns whatever the input element is\n",
    "- rm: removes (aka ignore) the element\n",
    "- fill: returns the arg ``.fill``\n",
    "\n",
    ":param d: any object that can be sliced with the inputs\n",
    ":param col: if None, lookup on each row, else lookup a specific column only\n",
    ":param fill: fill value for elements that are not in the provided dictionary. Explained more above\n",
    ":param mode: \"error\", \"input\", \"rm\", \"fill\". Explained more above\"\"\"\n",
    "        self.d = d; self.col = col; self.fill = fill\n",
    "        if mode == \"error\": # override .mode so that it's backwards compatible\n",
    "            if fill is input: mode = \"input\"; fill = None\n",
    "            elif fill is not None: mode = \"fill\"\n",
    "        self.mode = mode; self.rmSentinel = rmSentinel = object()\n",
    "        if mode == \"error\": f = lambda e: d[e]\n",
    "        elif mode == \"input\": f = lambda e: d.get(e, e)\n",
    "        elif mode == \"rm\": f = lambda e: d.get(e, rmSentinel)\n",
    "        elif mode == \"fill\": f = lambda e: d.get(e, fill)\n",
    "        else: raise Exception(\"Invalid mode. Only 'error', 'input', 'rm' and 'fill' are allowed\")\n",
    "        self.f = f\n",
    "        def fa(it, col):\n",
    "            if mode == \"rm\": return it | cli.apply(lambda e: d.get(e, rmSentinel), col) | cli.filt(lambda x: x is not rmSentinel, col)\n",
    "            return it | cli.apply(f, col)\n",
    "        self.fa = fa\n",
    "    def _typehint(self, inp):\n",
    "        t = inferType(list(self.d.values()))\n",
    "        if isinstance(t, tListIterSet): return tIter(t.child)\n",
    "        if isinstance(t, tCollection): return tIter(tLowest(*t.children))\n",
    "        return tIter(tAny())\n",
    "    def __ror__(self, it):\n",
    "        col = self.col\n",
    "        if hasPandas and isinstance(it, pd.DataFrame):\n",
    "            if col is None: it = init.dfGuard(it)\n",
    "            else:\n",
    "                f = self.f; rmSentinel = self.rmSentinel; c = [f(e) for e in it[list(it)[col]]]; it = it.replaceCol(list(it)[col], c)\n",
    "                return it.iloc[[i for i, e in enumerate(c) if e is not rmSentinel]] if self.mode == \"rm\" else it\n",
    "                # return pd.DataFrame({getattr(c, \"name\", ogName if i == col else next(genName)):c for i,c in enumerate(cols)})\n",
    "        return self.fa(it, col)\n",
    "    def _jsF(self, meta):\n",
    "        if self.mode not in (\"input\", \"rm\", \"fill\"): raise Exception(f\"lookup()._jsF() only supports modes 'input', 'rm' and 'fill'. Either specify a mode, or a default fill value\")\n",
    "        fIdx = init._jsFAuto(); dictIdx = f\"{init._jsDAuto()}_{round(time.time())}\"; dataIdx = init._jsDAuto()\n",
    "        return f\"//k1_moveOutStart\\n{dictIdx} = {json.dumps(self.d)}; //k1_moveOutEnd\\n{fIdx} = ({dataIdx}) => {dataIdx}.lookup({dictIdx}, {cli.kjs.v(self.col)}, {cli.kjs.v(self.fill)}, `{self.mode}`)\", fIdx\n",
    "    def _pyF(self, expr, **kw):\n",
    "        if self.col is not None: return None, None, NotImplemented, None\n",
    "        mode = self.mode; dN = init._pyFAuto(); xN = init._pyFAuto(); vD = {dN: self.d}\n",
    "        if mode == \"error\": return \"\", \"\", f\"({dN}[{xN}] for {xN} in {expr})\", vD\n",
    "        if mode == \"input\": return \"\", \"\", f\"({dN}.get({xN}, {xN}) for {xN} in {expr})\", vD\n",
    "        if mode == \"rm\": return \"\", \"\", f\"({dN}[{xN}] for {xN} in {expr} if {xN} in {dN})\", vD\n",
    "        if mode == \"fill\": fillN = init._pyFAuto(); vD[fillN] = self.fill; return \"\", \"\", f\"({dN}.get({xN}, {fillN}) for {xN} in {expr})\", vD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b934ae6e-c677-4a1e-b459-3e6a700cc9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"a\": 3, \"b\": 5, \"c\": 52}\n",
    "assert \"abcca\" | lookup(d) | cli.deref() == [3, 5, 52, 52, 3]\n",
    "try: \"abccad\" | lookup(d) | cli.deref(); raise Exception(\"Failed\")\n",
    "except KeyError: pass\n",
    "assert \"abccad\" | lookup(d, fill=\"(not found)\") | cli.deref() == [3, 5, 52, 52, 3, '(not found)']\n",
    "assert \"abccad\" | lookup(d, fill=input) | cli.deref() == [3, 5, 52, 52, 3, 'd']\n",
    "assert [range(5), \"abcca\"] | cli.transpose() | lookup(d, 1) | cli.deref() == [[0, 3], [1, 5], [2, 52], [3, 52], [4, 3]]\n",
    "assert lookup(d)._typehint(3) == tIter(int)\n",
    "assert \"abccad\" | lookup(d, mode=\"rm\") | cli.deref() == [3, 5, 52, 52, 3]\n",
    "\n",
    "\n",
    "assert \"abcca\" | (cli.toPyFunc() | lookup(d) | cli.deref()) == [3, 5, 52, 52, 3]\n",
    "try: \"abccad\" | (cli.toPyFunc() | lookup(d)) | cli.deref(); raise Exception(\"Failed\")\n",
    "except KeyError: pass\n",
    "assert \"abccad\" | (cli.toPyFunc() | lookup(d, fill=\"(not found)\")) | cli.deref() == [3, 5, 52, 52, 3, '(not found)']\n",
    "assert \"abccad\" | (cli.toPyFunc() | lookup(d, fill=input)) | cli.deref() == [3, 5, 52, 52, 3, 'd']\n",
    "assert [range(5), \"abcca\"] | (cli.toPyFunc() | cli.transpose() | lookup(d, 1)) | cli.deref() == [[0, 3], [1, 5], [2, 52], [3, 52], [4, 3]]\n",
    "assert \"abccad\" | (cli.toPyFunc() | lookup(d, mode=\"rm\")) | cli.deref() == [3, 5, 52, 52, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb55edbc-7445-4383-9843-85a7f037af97",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(df1 | lookup({1:2,2:3,3:4,4:5}, 0), pd.DataFrame)\n",
    "assert df1 | lookup({1:2,2:3,3:4}, 0, mode=\"rm\") | cli.shape() == (3, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f7f76401-c6df-46ec-9139-598f430ce8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_sorted = sorted\n",
    "class lookupRange(BaseCli):\n",
    "    def __init__(self, ranges, col:int=None, sorted=True, fill=None, mode=\"error\"):\n",
    "        \"\"\"Looks up values within some range.\n",
    "Example::\n",
    "\n",
    "    ranges = [[2, 3, \"a\"], [4, 5, \"b\"], [6, 7, \"c\"]]\n",
    "    vs = [1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5, 5.5]\n",
    "    vs | lookupRange(ranges, mode=\"error\") | deref() # raises an exception cause it can't find \"1\" in any ranges\n",
    "    vs | lookupRange(ranges, mode=\"fill\")  | deref() # returns [None, None, 'a', 'a', None, None, 'b', 'b', None, None]\n",
    "    vs | lookupRange(ranges, mode=\"rm\")    | deref() # returns ['a', 'a', 'b', 'b']\n",
    "    vs | lookupRange(ranges, mode=\"input\") | deref() # returns [1, 1.5, 'a', 'a', 3, 3.5, 'b', 'b', 5, 5.5]\n",
    "    \n",
    "    vs = list(zip([1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5, 5.5], \"abcdefghij\"))\n",
    "    vs | lookupRange(ranges, 0, mode=\"rm\") | deref() # returns [['a', 'c'], ['a', 'd'], ['b', 'g'], ['b', 'h']]\n",
    "\n",
    "So, ``ranges`` should be a table with 3 columns: start, stop and value. This cli will search across all ranges,\n",
    "and if the input iterator has values within a single range, it will yield that range's value. The exact\n",
    "comparison expression is \"start <= input < stop\". Internally, there're 2 implementations:\n",
    "\n",
    "First implementation assumes the ranges are not overlapping, activated by \"sorted=True\". This will\n",
    "assume the ranges are sorted based on the start values, then it searches for the value using binary\n",
    "search. Time complexity is O(n*log(m)), where n is the input size, m is the ranges's length\n",
    "\n",
    "Second implementation doesn't assume the ranges are not overlapping, activated by \"sorted=False\".\n",
    "This won't sort the ranges, and searches for the value using linear search, yielding the first\n",
    "range that contains the value. Time complexity is O(n*m)\n",
    "\n",
    "See also: :class:`lookup`\n",
    "\n",
    ":param ranges: table of size (N, 3), with each row (start, stop, value)\n",
    ":param col: column to act upon\n",
    ":param sorted: if True, use binary search, else use linear search. Explained more above\n",
    ":param fill: if specified, and if no ranges contain the value, then yield this value instead\n",
    ":param mode: explained above. See :class:`lookup` as well\"\"\"\n",
    "        try: ranges[:]; len(ranges)\n",
    "        except: ranges = ranges | deref(2)\n",
    "        if mode == \"error\" and fill is not None: mode = \"fill\"\n",
    "        if mode == \"error\" and fill == input: mode = \"input\"\n",
    "        self.ranges = ranges; self.col = col; self.sorted = sorted; self.fill = fill; self.mode = mode\n",
    "        if mode not in (\"error\", \"rm\", \"fill\", \"input\"): raise Exception(f\".mode can only be 'error', 'rm', 'fill' or 'input'\")\n",
    "    def __ror__(self, it):\n",
    "        ranges = self.ranges; col = self.col; fill = self.fill; mode = self.mode; sentinel = object(); it = init.dfGuard(it)\n",
    "        colIsNone = col is None; modeFill = mode == \"fill\"; modeRmOrError = mode == \"rm\" or mode == \"error\"; modeInput = mode == \"input\"; modeError = mode == \"error\"\n",
    "        def edit(row, value): row = list(row); row[col] = value; return row\n",
    "        if self.sorted:\n",
    "            for row in it:\n",
    "                v = row if col is None else row[col]\n",
    "                start = 0; end = len(ranges)-1; e = sentinel\n",
    "                while start <= end:\n",
    "                    mid = round((start + end)/2)\n",
    "                    r = ranges[mid]\n",
    "                    if r[0] <= v < r[1]: e = r[2]; break\n",
    "                    if v < r[0]: end = mid-1\n",
    "                    else: start = mid+1\n",
    "                if colIsNone:\n",
    "                    if modeFill: yield fill if e is sentinel else e\n",
    "                    elif modeRmOrError and e is not sentinel: yield e\n",
    "                    elif modeInput: yield v if e is sentinel else e\n",
    "                    elif modeError: raise KeyError(f\"Can't find element {v} in any ranges\")\n",
    "                else:\n",
    "                    if modeFill: row = list(row); row[col] = fill if e is sentinel else e; yield row\n",
    "                    elif modeRmOrError and e is not sentinel: row = list(row); row[col] = e; yield row\n",
    "                    elif modeInput: row = list(row); row[col] = v if e is sentinel else e; yield row\n",
    "                    elif modeError: raise KeyError(f\"Can't find element {v} in any ranges\")\n",
    "        else:\n",
    "            for row in it:\n",
    "                v = row if col is None else row[col]\n",
    "                e = next((vv for x,y,vv in ranges if x <= v < y), sentinel)\n",
    "                if colIsNone:\n",
    "                    if modeFill: yield fill if e is sentinel else e\n",
    "                    elif modeRmOrError and e is not sentinel: yield e\n",
    "                    elif modeInput: yield v if e is sentinel else e\n",
    "                    elif modeError: raise KeyError(f\"Can't find element {v} in any ranges\")\n",
    "                else:\n",
    "                    if modeFill: row = list(row); row[col] = fill if e is sentinel else e; yield row\n",
    "                    elif modeRmOrError and e is not sentinel: row = list(row); row[col] = e; yield row\n",
    "                    elif modeInput: row = list(row); row[col] = v if e is sentinel else e; yield row\n",
    "                    elif modeError: raise KeyError(f\"Can't find element {v} in any ranges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1b2e93d4-b789-47f9-8380-f443c718068e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = [[2, 3, \"a\"], [4, 5, \"b\"], [6, 7, \"c\"]]\n",
    "vs = [1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5, 5.5]\n",
    "assert vs | lookupRange(ranges, mode=\"fill\")  | cli.deref() == [None, None, 'a', 'a', None, None, 'b', 'b', None, None]\n",
    "assert vs | lookupRange(ranges, mode=\"rm\")    | cli.deref() == ['a', 'a', 'b', 'b']\n",
    "assert vs | lookupRange(ranges, mode=\"input\") | cli.deref() == [1, 1.5, 'a', 'a', 3, 3.5, 'b', 'b', 5, 5.5]\n",
    "try: vs | lookupRange(ranges, mode=\"error\")   | cli.deref(); assert False\n",
    "except KeyError: pass\n",
    "assert (vs | lookupRange(ranges, mode=\"rm\") | cli.deref()) == (vs | lookupRange(ranges, mode=\"rm\", sorted=False) | cli.deref())\n",
    "vs = list(zip([1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5, 5.5], \"abcdefghij\"))\n",
    "assert vs | lookupRange(ranges, 0, mode=\"rm\") | cli.deref() == [['a', 'c'], ['a', 'd'], ['b', 'g'], ['b', 'h']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f4f3b582-e36d-4bc4-a2e4-6d457504cdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class getitems(BaseCli):\n",
    "    def __init__(self, *fields, default=None):\n",
    "        \"\"\"Basically [input[x] for x in fields].\n",
    "Example::\n",
    "\n",
    "    # returns [3, 1, '']\n",
    "    {\"a\": 1, \"b\": 2, \"c\": 3} | getitems(\"c\", \"a\", \"d\")\n",
    "\"\"\"\n",
    "        self.fields = fields; self.default = default\n",
    "    def __ror__(self, d):\n",
    "        ans = []; default = self.default\n",
    "        for f in self.fields:\n",
    "            try: ans.append(d[f])\n",
    "            except: ans.append(default)\n",
    "        return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e3b55389-f921-4cf6-9b9d-9aecca966252",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert {\"a\": 1, \"b\": 2, \"c\": 3} | getitems(\"c\", \"a\", \"d\") == [3, 1, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b86a0124-65b5-4ed4-991b-ad5043675567",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class backup(BaseCli):\n",
    "    def __init__(self):\n",
    "        \"\"\"Backs up a file/folder.\n",
    "Example::\n",
    "\n",
    "    \"some/folderOrFile\" | backup()\n",
    "    \"some/folderOrFile\" | backup.restore()\n",
    "\n",
    "Really straightforward. Uses bash internally to copy files recursively, so\n",
    "not available on Windows.\"\"\"\n",
    "        pass\n",
    "    def __ror__(self, it):\n",
    "        it = os.path.expanduser(it)\n",
    "        None | cli.cmd(f\"rm -rf '{it}.backup'\") | cli.ignore()\n",
    "        None | cli.cmd(f\"cp -r '{it}' '{it}.backup'\") | cli.ignore()\n",
    "    @staticmethod\n",
    "    def restore():\n",
    "        def inner(it):\n",
    "            it = os.path.expanduser(it)\n",
    "            None | cli.cmd(f\"rm -rf '{it}'\") | cli.ignore()\n",
    "            None | cli.cmd(f\"cp -r '{it}.backup' '{it}'\") | cli.ignore()\n",
    "        return cli.aS(inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c85bace8-da96-43ae-9971-c137f908d085",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "sketch_interceptor = {}\n",
    "class sketch(BaseCli):\n",
    "    _jsF_ctxIdx = None\n",
    "    def __init__(self, transforms:List[Callable]=[], titles:List[str]=None, im:bool=False, ncols:int=None, n:int=None, axes:int=None):\n",
    "        \"\"\"Convenience tool to plot multiple matplotlib plots at the same\n",
    "time, while still keeping everything short and in 1 line. For this example,\n",
    "we're trying to plot x^1, x^2, ..., x^8 on 2 separate plots, one left one\n",
    "right. The left will have x^1 till x^4, the right will have x^5 to x^8.\n",
    "\n",
    "How you would do this normally::\n",
    "\n",
    "    x = np.linspace(-2, 2); exps = range(1, 9)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    # simplest solution\n",
    "    plt.sca(axes[0]); plt.plot(x, x**1); plt.plot(x, x**2); plt.plot(x, x**3); plt.plot(x, x**4); plt.legend([1, 2, 3, 4]); plt.xlabel(\"x axis\")\n",
    "    # solution using a little bit of cli\n",
    "    plt.sca(axes[1]); range(5, 9) | apply(lambda a: [x, x**a]) | ~apply(plt.plot) | ignore();     plt.legend([5, 6, 7, 8]); plt.xlabel(\"x axis\")\n",
    "\n",
    "But this is long, and I'm incredibly lazy to write it all out. So here's how\n",
    "it's going to work using this cli::\n",
    "\n",
    "    # plotting the first 4 lines only, in a single plot. Should be familiar and make sense to you before moving on\n",
    "    exps | apply(lambda a: [x, x**a]) | batched(4) | item() | ~apply(plt.plot) | ignore()\n",
    "\n",
    "    # plotting 8 lines across 2 plots. Simplest example using sketch(). It kinda captures clis after it and use it to plot each plot\n",
    "    exps | apply(lambda a: [x, x**a]) | batched(4) | (sketch() | ~apply(plt.plot))\n",
    "\n",
    "    # same as above, but adding a grid and x axis label to all plots. Transformation functions can be anything you would\n",
    "    # put inside a normal cli (`plt` will be passed as argument): string code, op()-capture, lambda functions, other cli tools\n",
    "    transforms = [\"x.grid(True)\", op().xlabel(\"x axis\"), lambda x: x.ylabel(\"y axis\")]\n",
    "    exps | apply(lambda a: [x, x**a]) | batched(4) | (sketch(transforms) | ~apply(plt.plot))\n",
    "\n",
    "    # same as above, but adding legends. [x, x**a] will eventually be directed to ~apply(plt.plot), while f\"x^{a}\" will be directed to aS(plt.legend)\n",
    "    exps | apply(lambda a: [[x, x**a], f\"x^{a}\"]) | batched(4) | (sketch() | transpose() | ~apply(plt.plot) + iden() | deref() | rItem(1) | aS(plt.legend)) | deref()\n",
    "\n",
    "Last line will generate this plot:\n",
    "\n",
    ".. image:: ../images/probScale.png\n",
    "\n",
    "Is it worth the extra confusion? Afterall, it just saves you 2-3 lines of\n",
    "code. To me, it is worth it, because you can quickly change styles (add\n",
    "a grid, make y axis log)\n",
    "\n",
    "See also: :class:`~k1lib.cli.output.plotImgs`\n",
    "\n",
    "Check out a gallery of more examples at `kapi/9-mpl <https://mlexps.com/kapi/9-mpl/>`_.\n",
    "\n",
    ":param transforms: transform functions to be run when drawing every plot. ``plt`` (aka ``matplotlib.pyplot``) will be passed in\n",
    ":param titles: if specified, use these titles for each plot. Kinda hacky I have to admit\n",
    ":param im: if True, returns a PIL image and closes the sketch, else return nothing but still have the sketch open\n",
    ":param ncols: if specified, will sketch with this number of columns\n",
    ":param n: if specified, use this number of sketch instead of figuring out automatically\n",
    ":param axes: if specified, forgo calculating #axes and initialization altogether and just use the provided axes\"\"\"\n",
    "        super().__init__(capture=True); self.titles = titles; self.im = im\n",
    "        self.transforms = [cli.fastF(t) for t in transforms]; self.ncols = ncols; self.n = n; self.axes = axes\n",
    "    def __ror__(self, it):\n",
    "        it = list(it); n = self.n or len(it); s = self.capturedSerial; transforms = self.transforms\n",
    "        ncols = self.ncols or math.ceil(n**0.5); nrows = math.ceil(n/ncols)\n",
    "        if self.axes: axes = self.axes\n",
    "        else:\n",
    "            fig, axes = plt.subplots(nrows, ncols, figsize=(ncols*5, nrows*4))\n",
    "            if nrows*ncols == 1: axes = [axes]\n",
    "        if axes | cli.shape() | cli.shape(0) > 1: axes = axes.flatten()\n",
    "        for i, [ax, e, title] in enumerate(zip(axes, it, self.titles or (\"\" | cli.repeat()))):\n",
    "            plt.sca(ax); e | s | cli.deref()\n",
    "            if title: plt.title(title)\n",
    "            for trans in transforms: trans(plt)\n",
    "        if self.n is None: axes[i+1:] | cli.op().remove().all() | cli.deref(); plt.tight_layout()\n",
    "        if self.im: return plt.gcf() | cli.toImg()\n",
    "        if self.n: return axes[i+1:]\n",
    "    def _jsF(self, meta):\n",
    "        if self.n: raise Exception(\"sketch()._jsF() doesn't support .n parameter yet\")\n",
    "        if self.axes: raise Exception(\"sketch()._jsF() doesn't support .axes parameter yet\")\n",
    "        fIdx = init._jsFAuto(); dataIdx = init._jsDAuto(); ctxIdx = init._jsDAuto()\n",
    "        # generate all child functions here\n",
    "        sketch._jsF_ctxIdx = ctxIdx\n",
    "        header, _fIdx, _async = k1lib.kast.asyncGuard(self.capturedSerial._jsF(meta))\n",
    "        # then generate all transforms here, using a tracing compiler\n",
    "        tfStmts = \"\"\n",
    "        if len(self.transforms) > 0:\n",
    "            class Interceptor:\n",
    "                def __getattr__(self, attr):\n",
    "                    if getattr(plt, attr) not in sketch_interceptor: raise Exception(f\"Transpiling function `plt.{attr}` is not supported at the moment\")\n",
    "                    return lambda *args, **kwargs: sketch_interceptor[getattr(plt, attr)](*args, **kwargs)\n",
    "            tfStmts = tfs = self.transforms | cli.apply(cli.init.fastF) | cli.op()(Interceptor()).all() | cli.join(\"; \")\n",
    "        sketch._jsF_ctxIdx = None\n",
    "        return f\"\"\"\\\n",
    "{ctxIdx} = null;\\n{header}\n",
    "{fIdx} = async ({dataIdx}) => {{ // dataIdx should have\n",
    "    const ctx = []; // this is the object that will be sent to the rendering server!\n",
    "    const titles = {json.dumps(self.titles)} ?? Array({dataIdx}.length);\n",
    "    for (const i of [...Array({dataIdx}.length).keys()]) {{\n",
    "        {ctxIdx} = [];\n",
    "        // actually executing function and plotting function downstream\n",
    "        {'await ' if _async else ''}{_fIdx}({dataIdx}[i]);\n",
    "        if (titles[i]) {ctxIdx}.push([\"title\", titles[i]]);\n",
    "        // inject all transforms here\n",
    "        {tfStmts};\n",
    "        ctx.push({ctxIdx}); {ctxIdx} = null;\n",
    "    }}\n",
    "    // console.log(ctx);\n",
    "    // console.log(JSON.stringify(ctx));\n",
    "    const res = await (await fetch(\"https://local.mlexps.com/routeServer/kapi_9-mpl\", {{\n",
    "      method: \"POST\",\n",
    "      body: JSON.stringify({{ \"ctx\": JSON.stringify(ctx) }}),\n",
    "      headers: {{ \"Content-Type\": \"application/json\" }}\n",
    "    }})).json()\n",
    "    if (res.success) {{\n",
    "        const base64 = res.data;\n",
    "        console.log(\"mpl fetched\");\n",
    "        return `<img src=\"data:image/jpg;base64, ${{base64}}\" />`\n",
    "    }} else {{ throw new Error(res.reason); }}\n",
    "    // return ctx;\n",
    "}}\"\"\", fIdx\n",
    "        return f\"{fIdx} = ({dataIdx}) => {dataIdx}.repeatFrom({cli.kjs.v(self.limit)})\", fIdx\n",
    "def _jsF_plt_ctxGuard():\n",
    "    if sketch._jsF_ctxIdx is None: raise Exception(\"Have to wrap any plotting operations around sketch(). So, transform your code from `data | (toJsFunc() | ~aS(plt.plot))` into `[data] | (toJsFunc() | (sketch() | ~aS(plt.plot)))`\")\n",
    "    return sketch._jsF_ctxIdx\n",
    "try: import matplotlib.pyplot as plt; hasMpl = True\n",
    "except: hasMpl = False\n",
    "if hasMpl:\n",
    "    def _jsF_plt_plot(meta, c=None):\n",
    "        fIdx = init._jsFAuto(); xIdx = init._jsDAuto(); yIdx = init._jsDAuto(); ctxIdx = _jsF_plt_ctxGuard()\n",
    "        return f\"\"\"\\\n",
    "    {fIdx} = ({xIdx}, {yIdx}=null) => {{\n",
    "        if (!{yIdx}) {{ // handle only xIdx is available case\n",
    "            {yIdx} = {xIdx}; {xIdx} = [...Array({yIdx}.length).keys()];\n",
    "        }}\n",
    "        {ctxIdx}.push([\"plot\", {xIdx}, {yIdx}]);\n",
    "    }}\"\"\", fIdx\n",
    "    settings.kjs.jsF[plt.plot] = _jsF_plt_plot\n",
    "    def _jsF_plt_title(meta): # version that passes args in js side\n",
    "        fIdx = init._jsFAuto(); titleIdx = init._jsDAuto(); ctxIdx = _jsF_plt_ctxGuard()\n",
    "        return f\"\"\"{fIdx} = ({titleIdx}) => {{ {ctxIdx}.push([\"title\", {titleIdx}]); }}\"\"\", fIdx\n",
    "    settings.kjs.jsF[plt.title] = _jsF_plt_title # below is version that passes args in python side, returns statement, instead of (header, fIdx) like usual\n",
    "    sketch_interceptor[plt.title] = lambda title: f\"\"\"{_jsF_plt_ctxGuard()}.push([\"title\", `{title}`])\"\"\"\n",
    "    def _jsF_plt_grid(meta):\n",
    "        fIdx = init._jsFAuto(); tfIdx = init._jsDAuto(); ctxIdx = _jsF_plt_ctxGuard()\n",
    "        return f\"\"\"{fIdx} = ({tfIdx}) => {{ {ctxIdx}.push([\"grid\", {tfIdx}]); }}\"\"\", fIdx\n",
    "    settings.kjs.jsF[plt.grid] = _jsF_plt_grid; sketch_interceptor[plt.grid] = lambda tf=True: f\"\"\"{_jsF_plt_ctxGuard()}.push([\"grid\", {cli.kjs.v(tf)}])\"\"\"\n",
    "    def _jsF_plt_legend(meta, framealpha=1):\n",
    "        fIdx = init._jsFAuto(); legendIdx = init._jsDAuto(); ctxIdx = _jsF_plt_ctxGuard()\n",
    "        return f\"\"\"{fIdx} = ({legendIdx}) => {{ {ctxIdx}.push([\"legend\", {legendIdx}, {framealpha}]); }}\"\"\", fIdx\n",
    "    settings.kjs.jsF[plt.legend] = _jsF_plt_legend; sketch_interceptor[plt.legend] = lambda legend=None, framealpha=1: f\"\"\"{_jsF_plt_ctxGuard()}.push([\"legend\", {cli.kjs.v(legend)}, {cli.kjs.v(framealpha)}])\"\"\"\n",
    "\n",
    "    sketch_interceptor[plt.xlim] = lambda left=None, right=None: f\"\"\"{_jsF_plt_ctxGuard()}.push([\"xlim\", {cli.kjs.v(left)}, {cli.kjs.v(right)}])\"\"\"\n",
    "    sketch_interceptor[plt.ylim] = lambda bottom=None, top=None: f\"\"\"{_jsF_plt_ctxGuard()}.push([\"ylim\", {cli.kjs.v(bottom)}, {cli.kjs.v(top)}])\"\"\"\n",
    "    sketch_interceptor[plt.xscale] = lambda scale: f\"\"\"{_jsF_plt_ctxGuard()}.push([\"xscale\", {cli.kjs.v(scale)}])\"\"\"\n",
    "    sketch_interceptor[plt.xlabel] = lambda label: f\"\"\"{_jsF_plt_ctxGuard()}.push([\"xlabel\", {cli.kjs.v(label)}])\"\"\"\n",
    "    sketch_interceptor[plt.ylabel] = lambda label: f\"\"\"{_jsF_plt_ctxGuard()}.push([\"ylabel\", {cli.kjs.v(label)}])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c5cfca0d-d713-473a-bbc3-a2bfbb01655b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../docs/images/utils_sketch.png'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.linspace(-2, 2); exps = range(1, 9)\n",
    "exps | cli.apply(lambda a: [[x, x**a], f\"x^{a}\"]) | cli.batched(4) | (sketch(im=True) | cli.transpose() | ~cli.apply(plt.plot) + cli.iden() | cli.deref() | cli.rItem(1) | cli.aS(plt.legend)) | cli.toBytes() | cli.file(\"../../docs/images/utils_sketch.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c4cb16e-8720-41b3-a5ad-f8454983a746",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import numbers, sys; from collections import deque\n",
    "class syncStepper(BaseCli):\n",
    "    def __init__(self, col=0, sort=False):\n",
    "        \"\"\"Steps forward all streams at a time, yielding same results from min to max.\n",
    "That's a bit vague, so let's see an example::\n",
    "\n",
    "    a = [[\"a\", 1], [\"b\", 7 ], [\"c\", 4], [\"e\", 6]]\n",
    "    b = [[\"b\", 5], [\"c\", 1 ], [\"d\", 3], [\"f\", 5]]\n",
    "    c = [[\"a\", 2], [\"c\", -4], [\"d\", 9], [\"e\", 4]]\n",
    "\n",
    "    [a, b, c] | syncStepper() | deref() # sync-step by the 1st column\n",
    "    [a, b, c] | syncStepper(1, True) | deref() # sync-step by the 2nd column. Have to sort it explicitly\n",
    "\n",
    "The first line returns this::\n",
    "\n",
    "    [[['a', 1], None, ['a', 2]],\n",
    "     [['b', 7], ['b', 5], None],\n",
    "     [['c', 4], ['c', 1], ['c', -4]],\n",
    "     [None, ['d', 3], ['d', 9]],\n",
    "     [['e', 6], None, ['e', 4]],\n",
    "     [None, ['f', 5], None]]\n",
    "\n",
    "The second line returns this::\n",
    "\n",
    "    [[None, None, ['c', -4]],\n",
    "     [['a', 1], ['c', 1], None],\n",
    "     [None, None, ['a', 2]],\n",
    "     [None, ['d', 3], None],\n",
    "     [['c', 4], None, ['e', 4]],\n",
    "     [None, ['b', 5], None],\n",
    "     [['e', 6], None, None],\n",
    "     [['b', 7], None, None],\n",
    "     [None, None, ['d', 9]]]\n",
    "\n",
    "``col`` can be None, but it's quite a strange use case::\n",
    "\n",
    "    [['a', 'b', 'c', 'e'], ['b', 'c', 'd', 'f'], ['a', 'c', 'd', 'e']] | syncStepper(None) | deref()\n",
    "\n",
    "It returns this::\n",
    "\n",
    "    [[['a'], None, ['a']],\n",
    "     [['b'], ['b'], None],\n",
    "     [['c'], ['c'], ['c']],\n",
    "     [None, ['d'], ['d']],\n",
    "     [['e'], None, ['e']],\n",
    "     [None, ['f'], None]]\n",
    "\n",
    "As you can see, for each line, it kinda yields elements with the same column. If\n",
    "that element doesn't exist, it'll just put None there. This expects the input\n",
    "streams are sorted at the column of interest. If they are not, specify ``sort=True``.\n",
    "\n",
    "It has roughly the same vibe as :class:`~k1lib.cli.structural.groupBy`, in that\n",
    "it groups everything by a specific column. The main difference here is that you\n",
    "can sync-step them line-by-line, loading very little into memory, so you can run\n",
    "this on giant datasets and not have to worry about running out of memory.\n",
    "\n",
    "With k streams each having n elements, you should expect memory complexity to be\n",
    "O(k), and the time complexity to be O(n*k^2/2). That k^2 term is kinda worrying,\n",
    "but in most use cases, k is small and so k^2 can be treated as a constant\n",
    "\n",
    "See also: :class:`~k1lib.cli.structural.latch`\n",
    "\n",
    ":param col: column where it should compare values and merge them together. Can be None, but that would be quite a weird use case\n",
    ":param sort: whether to sort the streams or not. This cli requires it, but it's\n",
    "    not turned on by default because it's an intensive operation\"\"\"\n",
    "        if col is None: self.col = 0; self.colPreprocess = cli.wrapList().all()\n",
    "        else: self.col = col; self.colPreprocess = cli.iden()\n",
    "        self.bank = deque(); self.sentinel = object(); self._sort = sort\n",
    "    def _append(self, stIdx1, val1, elem1): # append to bank in the correct position\n",
    "        i = 0; val2 = self.minObj\n",
    "        for i, [stIdx2, val2, elem2] in enumerate(self.bank):\n",
    "            if val1 <= val2: break\n",
    "        if val1 <= val2: self.bank.insert(i, [stIdx1, val1, elem1])\n",
    "        else: self.bank.append([stIdx1, val1, elem1])\n",
    "    def _yieldNext(self): # yield the next set of values\n",
    "        n = len(self.sts); res = [None]*n; last = None; hasInit = False; changed = False; bank = self.bank; sentinel = self.sentinel\n",
    "        for i, [stIdx, val, elem] in enumerate(bank):\n",
    "            if not hasInit and elem is sentinel: return res, changed\n",
    "            if last == val or not hasInit: changed = True; res[stIdx] = elem\n",
    "            elif hasInit: break\n",
    "            hasInit = True; last = val\n",
    "        while bank[0][1] == last: # popping the values off\n",
    "            stIdx, val1, elem1 = bank.popleft(); val2, elem2 = next(self.sts[stIdx])\n",
    "            if val1 > val2: raise Exception(f\"Stream {stIdx} has not been sorted yet! Please sort all streams before passing it into syncStepper\")\n",
    "            self._append(stIdx, val2, elem2)\n",
    "        return res, changed\n",
    "    def __ror__(self, sts): # sts = \"streams\"\n",
    "        col = self.col; it = init.dfGuard(it)\n",
    "        # --------------------- All of this is just to figure out the type of the column dynamically. So painful ---------------------\n",
    "        samples, sts = sts | self.colPreprocess.all() | cli.apply(cli.peek()) | cli.transpose() | cli.cut(col) + cli.iden() | cli.apply(list)\n",
    "        if len([e for e in sts if e != []]) == 0: return # no elements to yield at all!\n",
    "        n_nums = sum([1 if isinstance(e, numbers.Number) else 0 for e in samples])\n",
    "        n_strs = sum([1 if isinstance(e, str) else 0 for e in samples]); n = len(samples)\n",
    "        if n_nums*(n-n_nums) + n_strs*(n-n_strs) > 0: raise Exception(\"The requested column in some of the streams is not purely of numeric or string type, a requirement of syncStepper(). Please fix your data structure and try again.\")\n",
    "        if n_nums + n_strs == 0: raise Exception(\"The requested column in some of the streams is not of numeric or string type, so can't compare them to sync-step them\")\n",
    "        # n = 3; n_strs = 1\n",
    "        text = n_strs > 0; self.minObj = \"\" if text else float(\"-inf\"); self.maxObj = chr(sys.maxunicode) if text else float(\"inf\"); senObj = [self.maxObj, self.sentinel]\n",
    "        # --------------------- And here's the meat of the cli ---------------------\n",
    "        sts = sts | (cli.sort(col, not text).all() if self._sort else cli.iden()) | cli.apply(lambda st: [st | cli.apply(lambda elem: [elem[col], elem]), senObj | cli.repeat()] | cli.joinStreams()) | cli.aS(list)\n",
    "        sts | cli.apply(next) | cli.insertIdColumn() | ~cli.apply(lambda idx,e: self._append(idx, *e)) | cli.ignore(); self.sts = sts\n",
    "        while True:\n",
    "            res, changed = self._yieldNext()\n",
    "            if not changed: break\n",
    "            yield res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b23fbea7-498d-4fe5-9971-545db76bd0f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = [[\"a\", 1], [\"b\", 7],  [\"c\", 4], [\"e\", 6]]\n",
    "b = [[\"b\", 5], [\"c\", 1],  [\"d\", 3], [\"f\", 5]]\n",
    "c = [[\"a\", 2], [\"c\", -4], [\"d\", 9], [\"e\", 4]]\n",
    "\n",
    "# yields first element [[\"a\", 1], None, [\"a\", 2]]\n",
    "#[a, b, c] | sort(1).all() | syncStepper(1) | deref()\n",
    "assert [a, b, c] | syncStepper() | deref() == [[['a', 1], None, ['a', 2]], [['b', 7], ['b', 5], None], [['c', 4], ['c', 1], ['c', -4]], [None, ['d', 3], ['d', 9]], [['e', 6], None, ['e', 4]], [None, ['f', 5], None]]\n",
    "assert [a, b, c] | syncStepper(1, True) | deref() == [[None, None, ['c', -4]], [['a', 1], ['c', 1], None], [None, None, ['a', 2]], [None, ['d', 3], None], [['c', 4], None, ['e', 4]], [None, ['b', 5], None], [['e', 6], None, None], [['b', 7], None, None], [None, None, ['d', 9]]]\n",
    "assert [['a', 'b', 'c', 'e'], ['b', 'c', 'd', 'f'], ['a', 'c', 'd', 'e']] | syncStepper(None) | deref() == [[['a'], None, ['a']], [['b'], ['b'], None], [['c'], ['c'], ['c']], [None, ['d'], ['d']], [['e'], None, ['e']], [None, ['f'], None]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f140d15c-d618-445e-99d3-51a2e7f698d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class zeroes(BaseCli):\n",
    "    def __init__(self, col:int=None, log=False, offset:float=0):\n",
    "        \"\"\"Shift the specified column so that the first element is zero\n",
    "Example::\n",
    "\n",
    "    range(13, 20)   | zeroes()         | deref() # returns [0, 1, 2, 3, 4, 5, 6]\n",
    "    range(13, 20)   | zeroes(offset=5) | deref() # returns [5, 6, 7, 8, 9, 10, 11]\n",
    "    [2, 3, 1, 4, 7] | zeroes()         | deref() # returns [0, 1, -1, 2, 5]\n",
    "\n",
    "Assumes the first element is going to be transformed to zero, thus the last example.\n",
    "This cli also has log mode, where the natural log of the values will be shifted to zero::\n",
    "\n",
    "    # returns [1.0, 1.5, 0.5, 2.0, 3.5]\n",
    "    [2, 3, 1, 4, 7] | zeroes(log=True)           | aS(round, 2).all() | deref()\n",
    "    # returns [2.72, 4.08, 1.36, 5.44, 9.51]\n",
    "    [2, 3, 1, 4, 7] | zeroes(offset=1, log=True) | aS(round, 2).all() | deref()\n",
    "\n",
    "This is essentially the same as dividing everything by 2, so that the first element\n",
    "turns into 1. Super neat. The 2nd example is equivalent to multiplying everything by e/2.\n",
    "\n",
    "This cli can function in a table (.col != None)::\n",
    "\n",
    "    # returns [[0, 'a'], [1, 'b'], [2, 'c'], [3, 'd'], [4, 'e'], [5, 'f'], [6, 'g']]\n",
    "    [[13, 'a'], [14, 'b'], [15, 'c'], [16, 'd'], [17, 'e'], [18, 'f'], [19, 'g']] | zeroes(0) | deref()\n",
    "\n",
    "This cli can also act across multiple list of numbers::\n",
    "\n",
    "    data = [[2, 3, 1, 4, 7], [1, 4, 3, 6, 9]]\n",
    "    data2 = [[[2, 'b'], [3, 'c'], [1, 'a'], [4, 'd'], [7, 'g']], [[1, 'a'], [4, 'd'], [3, 'c'], [6, 'f'], [9, 'i']]]\n",
    "\n",
    "    # returns [[0, 1, -1, 2, 5], [5, 8, 7, 10, 13]]\n",
    "    data | ~zeroes() | deref()\n",
    "    # returns [[1, 2, 0, 3, 6], [6, 9, 8, 11, 14]]\n",
    "    data | ~zeroes(offset=1) | deref()\n",
    "    # returns [[1.0, 1.5, 0.5, 2.0, 3.5], [3.5, 14.0, 10.5, 21.0, 31.5]]\n",
    "    data | ~zeroes(log=True) | aS(round, 2).all(2) | deref()\n",
    "    \n",
    "    # returns [[[0, 'b'], [1, 'c'], [-1, 'a'], [2, 'd'], [5, 'g']], [[5, 'a'], [8, 'd'], [7, 'c'], [10, 'f'], [13, 'i']]]\n",
    "    data2 | ~zeroes(0) | deref()\n",
    "\n",
    "So as you can see, the offsets are adjusted so that the first element of each list\n",
    "starts from the last element of the previous list\n",
    "\n",
    ":param col: column to shift values\n",
    ":param offset: custom offset of the minimum value, defaulted to zero\n",
    ":param log: whether to zero it linearly or zero it logarithmically\"\"\"\n",
    "        self.col = col; self.log = log; self.offset = offset; self.inverted = False\n",
    "    def __invert__(self): res = zeroes(self.col, self.log, self.offset); res.inverted = True; return res\n",
    "    def __ror__(self, it):\n",
    "        col = self.col; log = self.log; offset = self.offset; it = init.dfGuard(it)\n",
    "        if self.inverted:\n",
    "            def gen():\n",
    "                currentOffset = offset\n",
    "                for arr in it:\n",
    "                    arr = arr | zeroes(col, log, currentOffset)\n",
    "                    if isinstance(arr, settings.arrayTypes):\n",
    "                        bm = np if isinstance(arr, np.ndarray) else (torch if hasTorch and isinstance(arr, torch.Tensor) else None)\n",
    "                        if bm:\n",
    "                            if col is None: currentOffset = bm.log(arr[-1]) if log else arr[-1]\n",
    "                            else: currentOffset = bm.log(arr[-1][col]) if log else arr[-1][col]\n",
    "                            yield arr; continue\n",
    "                    # yes, we have to deref() them, even though perf will suffer, because let's say\n",
    "                    # that the user then does rItem(3), and discards elements 0, 1 and 2. Then 0, 1, 2\n",
    "                    # won't be run, so element 3 won't know its offset!\n",
    "                    if col is None: arr = list(arr);        currentOffset = math.log(arr[-1])      if log else arr[-1]\n",
    "                    else: arr = [list(row) for row in arr]; currentOffset = math.log(arr[-1][col]) if log else arr[-1][col]\n",
    "                    yield arr\n",
    "            return gen()\n",
    "        if isinstance(it, settings.arrayTypes):\n",
    "            bm = np if isinstance(it, np.ndarray) else (torch if hasTorch and isinstance(it, torch.Tensor) else None)\n",
    "            if bm:\n",
    "                cloneF = np.copy if isinstance(it, np.ndarray) else torch.clone\n",
    "                if log:\n",
    "                    if col is None: minValue = bm.log(it[0]) - offset; return bm.exp(bm.log(it) - minValue)\n",
    "                    else: minValue = bm.log(it[0, col]) - offset; it = cloneF(it); it[:,col] = bm.exp(bm.log(it[:,col]) - minValue); return it\n",
    "                else:\n",
    "                    if col is None: minValue = it[0] - offset; return it - minValue\n",
    "                    else: minValue = it[0, col] - offset; it = cloneF(it); it[:,col] = it[:,col] - minValue; return it\n",
    "        row, it = it | cli.peek()\n",
    "        if it == []: return []\n",
    "        if log:\n",
    "            mlog = math.log; mexp = math.exp\n",
    "            if col is None: minValue = mlog(row) - offset; return (mexp(mlog(row) - minValue) for row in it)\n",
    "            else: minValue = mlog(row[col]) - offset; return ([*row[:col], mexp(mlog(row[col]) - minValue), *row[col+1:]] for row in it)\n",
    "        else:\n",
    "            if col is None: minValue = row - offset; return (row - minValue for row in it)\n",
    "            else: minValue = row[col] - offset; return ([*row[:col], row[col] - minValue, *row[col+1:]] for row in it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ce20d937-6c26-43a8-978f-bdbb01950b4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert range(13, 20) | zeroes(offset=5) | cli.deref() == [5, 6, 7, 8, 9, 10, 11]\n",
    "assert range(13, 20) | zeroes() | cli.deref() == [0, 1, 2, 3, 4, 5, 6]\n",
    "assert [2, 3, 1, 4, 7] | zeroes() | cli.deref() == [0, 1, -1, 2, 5]\n",
    "assert [2, 3, 1, 4, 7] | zeroes(log=True) | cli.aS(round, 2).all() | cli.deref() == [1.0, 1.5, 0.5, 2.0, 3.5]\n",
    "assert [2, 3, 1, 4, 7] | zeroes(offset=1, log=True) | cli.aS(round, 2).all() | cli.deref() == [2.72, 4.08, 1.36, 5.44, 9.51]\n",
    "assert [[13, 'a'], [14, 'b'], [15, 'c'], [16, 'd'], [17, 'e'], [18, 'f'], [19, 'g']] | zeroes(0) | cli.deref() == [[0, 'a'], [1, 'b'], [2, 'c'], [3, 'd'], [4, 'e'], [5, 'f'], [6, 'g']]\n",
    "data = [[2, 3, 1, 4, 7], [1, 4, 3, 6, 9]]\n",
    "data2 = data | cli.aS(lambda x: [x, chr(x+97-1)]).all(2) | cli.deref()\n",
    "data3 = data | cli.aS(lambda x: [x, x+10]).all(2) | cli.deref()\n",
    "assert data               | ~zeroes() | cli.deref()          == [[0, 1, -1, 2, 5], [5, 8, 7, 10, 13]]\n",
    "assert np.array(data)     | ~zeroes() | cli.deref(igT=False) == [[0, 1, -1, 2, 5], [5, 8, 7, 10, 13]]\n",
    "assert torch.Tensor(data) | ~zeroes() | cli.deref(igT=False) == [[0, 1, -1, 2, 5], [5, 8, 7, 10, 13]]\n",
    "assert data | ~zeroes(offset=1) | cli.deref() == [[1, 2, 0, 3, 6], [6, 9, 8, 11, 14]]\n",
    "assert data | ~zeroes(log=True) | cli.aS(round, 2).all(2) | cli.deref() == [[1.0, 1.5, 0.5, 2.0, 3.5], [3.5, 14.0, 10.5, 21.0, 31.5]]\n",
    "assert data2 | ~zeroes(0) | cli.deref() == [[[0, 'b'], [1, 'c'], [-1, 'a'], [2, 'd'], [5, 'g']], [[5, 'a'], [8, 'd'], [7, 'c'], [10, 'f'], [13, 'i']]]\n",
    "assert data3 | cli.aS(np.array) | ~zeroes(0) | cli.deref(igT=False) == [[[0, 12], [1, 13], [-1, 11], [2, 14], [5, 17]], [[5, 11], [8, 14], [7, 13], [10, 16], [13, 19]]]\n",
    "x = np.random.randn(100)+10; xT = torch.randn(100)+10\n",
    "assert x | zeroes()         | shape() == (100,)\n",
    "assert x | zeroes(log=True) | shape() == (100,)\n",
    "try: x | zeroes(1); raise Exception(\"Failed\")\n",
    "except IndexError: pass\n",
    "try: x | zeroes(1, log=True); raise Exception(\"Failed\")\n",
    "except IndexError: pass\n",
    "assert xT | zeroes()         | shape() == (100,)\n",
    "assert xT | zeroes(log=True) | shape() == (100,)\n",
    "try: xT | zeroes(1); raise Exception(\"Failed\")\n",
    "except IndexError: pass\n",
    "try: xT | zeroes(1, log=True); raise Exception(\"Failed\")\n",
    "except IndexError: pass\n",
    "x = np.random.randn(100, 30)+10; xT = torch.randn(100, 30)+10\n",
    "assert x | zeroes()  | shape() == (100, 30)\n",
    "assert x | zeroes(3) | shape() == (100, 30)\n",
    "assert x | zeroes(log=True)    | shape() == (100, 30)\n",
    "assert x | zeroes(3, log=True) | shape() == (100, 30)\n",
    "assert xT | zeroes()  | shape() == (100, 30)\n",
    "assert xT | zeroes(3) | shape() == (100, 30)\n",
    "assert xT | zeroes(log=True)    | shape() == (100, 30)\n",
    "assert xT | zeroes(3, log=True) | shape() == (100, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3eeec5f8-cde0-4bc2-9c3b-6f9d1202e42d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class normalize(BaseCli):\n",
    "    def __init__(self, col:int=None, mode:int=0):\n",
    "        \"\"\"Normalize the data going in.\n",
    "Example::\n",
    "\n",
    "    arr = np.random.randn(100)+10\n",
    "    arr | normalize()       # returns array with mean around 0\n",
    "    arr | normalize(mode=1) # returns array with mean around 0.5, min 0, max 1\n",
    "\n",
    "    arr = np.random.randn(100, 20)+10\n",
    "    arr | normalize(2)         # returns array with 2nd (0-indexing!) column have mean around 0. Other columns not touched\n",
    "    arr | normalize(2, mode=1) # returns array with 2nd (0-indexing!) column have mean around 0.5\n",
    "\n",
    "Modes:\n",
    "\n",
    "- 0: ``(x - x.mean()) / x.std()``\n",
    "- 1: ``(x - x.min()) / (x.max() - x.min())``\n",
    "- 2: ``a = log10(x); (a - a.min()) / (a.max() - a.min())``\n",
    "\n",
    ":param col: column to apply the normalization to\n",
    ":param mode: see above\"\"\"\n",
    "        self.col = col; self.mode = mode\n",
    "    def _all_array_opt(self, it, level):\n",
    "        col = self.col; n = len(it.shape); s = slice(None, None, None); mode = self.mode\n",
    "        log10 = np.log10 if isinstance(it, np.ndarray) else torch.log10\n",
    "        if col is None:\n",
    "            # (*level, N, *rest (>0)) -> (*level, N, rest) -> (*level, N*rest) -> (*level) (this is mean & std) -> (*level, N, *rest)\n",
    "            if level+1 == len(it.shape): it = it[(*[s]*len(it.shape), None)]; n += 1\n",
    "            b = it | cli.joinSt(n-level-2).all(level+1); c = b | cli.joinSt().all(level)\n",
    "            if mode == 0:\n",
    "                mean = c.mean(level)[(*[s]*level,None,None)]\n",
    "                std = c.std(level)[(*[s]*level,None,None)]\n",
    "                return ((b - mean)/std).reshape(it.shape)\n",
    "            elif mode == 1:\n",
    "                min_ = c.min(level)[(*[s]*level,None,None)]\n",
    "                max_ = c.max(level)[(*[s]*level,None,None)]\n",
    "                return ((b - min_)/(max_ - min_)).reshape(it.shape)\n",
    "            else:\n",
    "                min_ = log10(c).min(level)[(*[s]*level,None,None)]\n",
    "                max_ = log10(c).max(level)[(*[s]*level,None,None)]\n",
    "                return ((log10(b) - min_)/(max_ - min_)).reshape(it.shape)\n",
    "        else:\n",
    "            # (*level, N, F, *rest (>0)) -> (*level, N, *rest) -> (*level, N, rest) -> (*level, N*rest) -> (*level) (this is mean & std) -> (*level, N, F, *rest)\n",
    "            a = np.copy(it) if isinstance(it, np.ndarray) else torch.clone(it); unsqueezed = False; s = slice(None, None, None)\n",
    "            if level+2 == len(a.shape): a = a[(*[s]*len(a.shape), None)]; unsqueezed = True; n += 1\n",
    "            b = a[(*[slice(None,None,None)]*(level+1),col)] | cli.joinSt(n-level-3).all(level+1) # (*level, N, rest (>0, hence unsqueeze))\n",
    "            c = b | cli.joinSt(len(b.shape)-level-1).all(level) # (*level, N*rest)\n",
    "            if mode == 0:\n",
    "                mean = c.mean(level)[(*[s]*level,None,None)]\n",
    "                std = c.std(level)[(*[s]*level,None,None)]\n",
    "                b[:] = (b - mean)/std\n",
    "            elif mode == 1:\n",
    "                min_ = c.min(level)[(*[s]*level,None,None)]\n",
    "                max_ = c.max(level)[(*[s]*level,None,None)]\n",
    "                b[:] = (b - min_)/(max_ - min_)\n",
    "            else:\n",
    "                min_ = log10(c).min(level)[(*[s]*level,None,None)]\n",
    "                max_ = log10(c).max(level)[(*[s]*level,None,None)]\n",
    "                b[:] = (log10(b) - min_)/(max_ - min_)\n",
    "            return (a | cli.joinSt().all(len(a.shape)-2)) if unsqueezed else a\n",
    "        return NotImplemented\n",
    "    def __ror__(self, x):\n",
    "        col = self.col; mode = self.mode; x = init.dfGuard(x)\n",
    "        if isinstance(x, k1lib.settings.cli.arrayTypes):\n",
    "            dims = len(x.shape); log10 = np.log10 if isinstance(x, np.ndarray) else torch.log10\n",
    "            if col is None:\n",
    "                if mode == 0: return (x - x.mean())/x.std()\n",
    "                elif mode == 1: return (x - x.min())/(x.max() - x.min())\n",
    "                else: x = log10(x); return (x - x.min())/(x.max() - x.min())\n",
    "            else:\n",
    "                if mode == 0: xc = x[:,col]; x[:,col] = (xc - xc.mean())/xc.std(); return x\n",
    "                elif mode == 1: xc = x[:,col]; x[:,col] = (xc - xc.min())/(xc.max() - xc.min()); return x\n",
    "                else: xc = log10(x[:,col]); x[:,col] = (xc - xc.min())/(xc.max() - xc.min()); return x\n",
    "        if col is None: return np.array(list(x)) | self\n",
    "        else:\n",
    "            it = x; ans = []; it = it | cli.deref(2); log10 = math.log10\n",
    "            if len(it) == 0: return []\n",
    "            if mode == 0:\n",
    "                mean = [row[col] for row in it] | cli.toMean()\n",
    "                std = [row[col] for row in it] | cli.toStd()\n",
    "                for row in it: row = list(row); row[col] = (row[col]-mean)/std; ans.append(row)\n",
    "            elif mode == 1:\n",
    "                _min = min([row[col] for row in it])\n",
    "                _max = max([row[col] for row in it])\n",
    "                for row in it: row = list(row); row[col] = (row[col]-_min)/(_max-_min); ans.append(row)\n",
    "            else:\n",
    "                _min = min([log10(row[col]) for row in it])\n",
    "                _max = max([log10(row[col]) for row in it])\n",
    "                for row in it: row = list(row); row[col] = (log10(row[col])-_min)/(_max-_min); ans.append(row)\n",
    "            return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d13d011f-bfdb-4686-aca8-af483774dc47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = np.random.randn(100)+10; xT = torch.randn(100)+10\n",
    "assert abs(x  | normalize()  | cli.toMean()) < 1e-4\n",
    "assert abs(xT | normalize()  | cli.toMean()) < 1e-4\n",
    "assert abs(x  | cli.deref(igT=False) | normalize()  | cli.toMean()) < 1e-4\n",
    "assert abs(xT | cli.deref(igT=False) | normalize()  | cli.toMean()) < 1e-4\n",
    "x = np.random.randn(100, 30)+10; xT = torch.randn(100, 30)+10\n",
    "assert abs(x  | normalize()  | cli.toMean()) < 1e-4\n",
    "assert abs(xT | normalize()  | cli.toMean()) < 1e-4\n",
    "assert abs(x  | normalize(2) | cli.toMean()) > 8\n",
    "assert abs(xT | normalize(2) | cli.toMean()) > 8\n",
    "assert (x  | normalize(2) | cli.op()[:,2] | cli.toMean()) < 1e-4\n",
    "assert (xT | normalize(2) | cli.op()[:,2] | cli.toMean()) < 1e-4\n",
    "assert (x  | cli.deref(igT=False) | normalize(2) | cli.toMean().all() | cli.toMean()) > 8\n",
    "assert (xT | cli.deref(igT=False) | normalize(2) | cli.toMean().all() | cli.toMean()) > 8\n",
    "assert sum((x+10 | normalize(mode=1) != x+10 | normalize(mode=2)).flatten()) > 1500\n",
    "# _all_array_opts\n",
    "a = np.random.randn(3,4,5,6); ogA = np.copy(a); a | shape()\n",
    "assert (abs((a | normalize(1).all()) - a) < 1e-5) | cli.joinSt(3) | cli.count() | ~cli.sort() | cli.item(2) == 288 # 360/5 = 3*4*5*6/5\n",
    "assert isinstance(a | normalize(1).all(), np.ndarray)\n",
    "assert isinstance(a | normalize().all(), np.ndarray)\n",
    "assert not np.allclose(a | normalize(), a | normalize(1))\n",
    "a = np.array([[[1,2], [3,4], [5,6], [7,8.0]]])\n",
    "assert np.allclose(a | normalize(1, 0).all(), np.array([[[ 1.        , -1.34164079], [ 3.        , -0.4472136 ], [ 5.        ,  0.4472136 ], [ 7.        ,  1.34164079]]]))\n",
    "assert np.allclose(np.array([[[1,2], [3,4], [5,6], [7,8.0]]]) | normalize(1, 0).all(), np.array([[[ 1.        , -1.34164079], [ 3.        , -0.4472136 ], [ 5.        ,  0.4472136 ], [ 7.        ,  1.34164079]]]))\n",
    "assert np.allclose(np.array([[[1,2], [3,4], [5,6], [7,8.0]]]) | normalize(1, 1).all(), np.array([[[1.        , 0.        ], [3.        , 0.33333333], [5.        , 0.66666667], [7.        , 1.        ]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2c80eba4-dd10-4f76-af95-37ed9b88f3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class branch(BaseCli):\n",
    "    def __init__(self, f, f1, f2):\n",
    "        \"\"\"Works like an if statement, for when you don't want to make a separate\n",
    "function as it's too time consuming.\n",
    "\n",
    "    3 | branch(lambda x: x>2, lambda x: x+4, lambda x: x+5) # returns 7\n",
    "    3 | branch(op()>2, op()+4, op()+5)                      # returns 7\n",
    "    3 | branch(\"x>2\", \"x+4\", \"x+5\")                         # returns 7\n",
    "\n",
    "    3 | aS(lambda x: (x + 4) if (x > 2) else (x + 5))       # returns 7\n",
    "\n",
    "So all of them kinda does the same thing as the 4th line. Is it worth it? Debatable, but I've\n",
    "had so many times that I have to wrap things in parenthesis around expressions to make sure\n",
    "it's not doing anything weird and that takes long enough to disrupt my thought process\n",
    "that I kinda have to make this\n",
    "\n",
    ":param f: predicate function. If returns True, use the first function (f1), else use the second function (f2)\"\"\"\n",
    "        self.f = f; self._fC = cli.fastF(f)\n",
    "        self.f1 = f1; self._fC1 = cli.fastF(f1)\n",
    "        self.f2 = f2; self._fC2 = cli.fastF(f2)\n",
    "    def __ror__(self, it): return self._fC1(it) if self._fC(it) else self._fC2(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8baac754-afd0-4a01-b989-c6e187f8a6d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert 3 | branch(lambda x: x>2, lambda x: x+4, lambda x: x+5) == 7\n",
    "assert 3 | branch(\"x>2\", \"x+4\", \"x+5\") == 7\n",
    "assert 3 | branch(cli.op()>2, cli.op()+4, cli.op()+5) == 7\n",
    "assert 3 | cli.aS(lambda x: x+4 if x > 2 else x+5) == 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79252d65-4748-4b01-adc3-0f2fd0d21bd5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./export started up - /home/quang/miniconda3/envs/torch/bin/python3\n",
      "----- exportAll\n",
      "16076   0   61%   \n",
      "10444   1   39%   \n",
      "Found existing installation: k1lib 1.7\n",
      "Uninstalling k1lib-1.7:\n",
      "  Successfully uninstalled k1lib-1.7\n",
      "Looking in indexes: https://pypi.org/simple, http://10.104.0.3:3141/\n",
      "Processing /home/quang/k1lib\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14 in /home/quang/miniconda3/envs/torch/lib/python3.9/site-packages (from k1lib==1.7) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=2.0 in /home/quang/miniconda3/envs/torch/lib/python3.9/site-packages (from k1lib==1.7) (3.8.3)\n",
      "Requirement already satisfied: dill in /home/quang/miniconda3/envs/torch/lib/python3.9/site-packages (from k1lib==1.7) (0.3.8)\n",
      "Requirement already satisfied: forbiddenfruit in /home/quang/miniconda3/envs/torch/lib/python3.9/site-packages (from k1lib==1.7) (0.1.4)\n",
      "Requirement already satisfied: wurlitzer in /home/quang/miniconda3/envs/torch/lib/python3.9/site-packages (from k1lib==1.7) (3.0.3)\n",
      "Requirement already satisfied: validators in /home/quang/miniconda3/envs/torch/lib/python3.9/site-packages (from k1lib==1.7) (0.22.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/quang/miniconda3/envs/torch/lib/python3.9/site-packages (from matplotlib>=2.0->k1lib==1.7) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/quang/miniconda3/envs/torch/lib/python3.9/site-packages (from matplotlib>=2.0->k1lib==1.7) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/quang/miniconda3/envs/torch/lib/python3.9/site-packages (from matplotlib>=2.0->k1lib==1.7) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/quang/miniconda3/envs/torch/lib/python3.9/site-packages (from matplotlib>=2.0->k1lib==1.7) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/quang/miniconda3/envs/torch/lib/python3.9/site-packages (from matplotlib>=2.0->k1lib==1.7) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/quang/miniconda3/envs/torch/lib/python3.9/site-packages (from matplotlib>=2.0->k1lib==1.7) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/quang/miniconda3/envs/torch/lib/python3.9/site-packages (from matplotlib>=2.0->k1lib==1.7) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/quang/miniconda3/envs/torch/lib/python3.9/site-packages (from matplotlib>=2.0->k1lib==1.7) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/quang/miniconda3/envs/torch/lib/python3.9/site-packages (from matplotlib>=2.0->k1lib==1.7) (6.1.3)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/quang/miniconda3/envs/torch/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib>=2.0->k1lib==1.7) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/quang/miniconda3/envs/torch/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=2.0->k1lib==1.7) (1.16.0)\n",
      "Building wheels for collected packages: k1lib\n",
      "  Building wheel for k1lib (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for k1lib: filename=k1lib-1.7-py3-none-any.whl size=5103384 sha256=b087769196aca5501f351fbd9351a71c6c3dc05bcc151f56e61c81ec2db540e3\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-9rhfjz5a/wheels/11/94/07/711323eb4091c7ef1b180ccc3793fc75a96521821bdd2932ac\n",
      "Successfully built k1lib\n",
      "Installing collected packages: k1lib\n",
      "Successfully installed k1lib-1.7\n"
     ]
    }
   ],
   "source": [
    "!../../export.py cli/utils --upload=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7ec55fe4-2c92-48d2-8b78-8222d5c81070",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./export started up - /home/quang/miniforge3/bin/python\n",
      "----- exportAll\n",
      "16748   0   60%   \n",
      "11071   1   40%   \n",
      "installing...\n",
      "Found existing installation: k1lib 1.8\n",
      "Uninstalling k1lib-1.8:\n",
      "  Successfully uninstalled k1lib-1.8\n",
      "\u001b[33mDEPRECATION: Loading egg at /home/quang/miniforge3/lib/python3.12/site-packages/aigu-0.1-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, http://10.104.0.3:3141/\n",
      "Processing /home/quang/k1lib\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14 in /home/quang/miniforge3/lib/python3.12/site-packages (from k1lib==1.8) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=2.0 in /home/quang/miniforge3/lib/python3.12/site-packages (from k1lib==1.8) (3.9.2)\n",
      "Requirement already satisfied: dill in /home/quang/miniforge3/lib/python3.12/site-packages (from k1lib==1.8) (0.3.8)\n",
      "Requirement already satisfied: forbiddenfruit in /home/quang/miniforge3/lib/python3.12/site-packages (from k1lib==1.8) (0.1.4)\n",
      "Requirement already satisfied: wurlitzer in /home/quang/miniforge3/lib/python3.12/site-packages (from k1lib==1.8) (3.1.1)\n",
      "Requirement already satisfied: validators in /home/quang/miniforge3/lib/python3.12/site-packages (from k1lib==1.8) (0.34.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/quang/miniforge3/lib/python3.12/site-packages (from matplotlib>=2.0->k1lib==1.8) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/quang/miniforge3/lib/python3.12/site-packages (from matplotlib>=2.0->k1lib==1.8) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/quang/miniforge3/lib/python3.12/site-packages (from matplotlib>=2.0->k1lib==1.8) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/quang/miniforge3/lib/python3.12/site-packages (from matplotlib>=2.0->k1lib==1.8) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/quang/miniforge3/lib/python3.12/site-packages (from matplotlib>=2.0->k1lib==1.8) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /home/quang/miniforge3/lib/python3.12/site-packages (from matplotlib>=2.0->k1lib==1.8) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/quang/miniforge3/lib/python3.12/site-packages (from matplotlib>=2.0->k1lib==1.8) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/quang/miniforge3/lib/python3.12/site-packages (from matplotlib>=2.0->k1lib==1.8) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/quang/miniforge3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=2.0->k1lib==1.8) (1.16.0)\n",
      "Building wheels for collected packages: k1lib\n",
      "  Building wheel for k1lib (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for k1lib: filename=k1lib-1.8-py3-none-any.whl size=5134291 sha256=2c17cc8639da43d0b8d9b0cfb8e002d5c94e67346b897c5b0edfa0f992c8efdc\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-mht5c3u7/wheels/b5/32/67/e20c84dce16d707fb881c12d405f70adfaa36fe7dae9021380\n",
      "Successfully built k1lib\n",
      "Installing collected packages: k1lib\n",
      "Successfully installed k1lib-1.8\n",
      "installed\n"
     ]
    }
   ],
   "source": [
    "!../../export.py cli/utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d46fb6b0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/kelvin/repos/labs/k1lib/k1lib/cli/../../export.py\", line 10, in <module>\n",
      "    try: from k1lib.imports import *; hasK1 = True\n",
      "  File \"/home/kelvin/repos/labs/k1lib/k1lib/__init__.py\", line 9, in <module>\n",
      "    from . import cli\n",
      "  File \"/home/kelvin/repos/labs/k1lib/k1lib/cli/__init__.py\", line 17, in <module>\n",
      "    from .utils import *\n",
      "  File \"/home/kelvin/repos/labs/k1lib/k1lib/cli/utils.py\", line 339, in <module>\n",
      "    if hasPandas: a.append(pd.core.arraylike.OpsMixin)                               # clipboard\n",
      "AttributeError: module 'pandas' has no attribute 'core'\n",
      "./export started up - /home/kelvin/anaconda3/envs/ray2/bin/python3\n",
      "----- bootstrapping\n",
      "Current dir: /home/kelvin/repos/labs/k1lib, /home/kelvin/repos/labs/k1lib/k1lib/cli/../../export.py\n",
      "rm: cannot remove '__pycache__': No such file or directory\n",
      "Found existing installation: k1lib 1.6\n",
      "Uninstalling k1lib-1.6:\n",
      "  Successfully uninstalled k1lib-1.6\n",
      "running install\n",
      "/home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "/home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages/setuptools/command/easy_install.py:144: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "creating k1lib.egg-info\n",
      "writing k1lib.egg-info/PKG-INFO\n",
      "writing dependency_links to k1lib.egg-info/dependency_links.txt\n",
      "writing requirements to k1lib.egg-info/requires.txt\n",
      "writing top-level names to k1lib.egg-info/top_level.txt\n",
      "writing manifest file 'k1lib.egg-info/SOURCES.txt'\n",
      "reading manifest file 'k1lib.egg-info/SOURCES.txt'\n",
      "adding license file 'LICENSE'\n",
      "writing manifest file 'k1lib.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "creating build/lib/k1lib\n",
      "copying k1lib/_learner.py -> build/lib/k1lib\n",
      "copying k1lib/fmt.py -> build/lib/k1lib\n",
      "copying k1lib/selen.py -> build/lib/k1lib\n",
      "copying k1lib/kast.py -> build/lib/k1lib\n",
      "copying k1lib/_k1a.py -> build/lib/k1lib\n",
      "copying k1lib/_context.py -> build/lib/k1lib\n",
      "copying k1lib/selector.py -> build/lib/k1lib\n",
      "copying k1lib/imports.py -> build/lib/k1lib\n",
      "copying k1lib/_baseClasses.py -> build/lib/k1lib\n",
      "copying k1lib/_basics.py -> build/lib/k1lib\n",
      "copying k1lib/serpent.py -> build/lib/k1lib\n",
      "copying k1lib/viz.py -> build/lib/k1lib\n",
      "copying k1lib/zircon.py -> build/lib/k1lib\n",
      "copying k1lib/_higher.py -> build/lib/k1lib\n",
      "copying k1lib/__init__.py -> build/lib/k1lib\n",
      "copying k1lib/_monkey.py -> build/lib/k1lib\n",
      "copying k1lib/knn.py -> build/lib/k1lib\n",
      "copying k1lib/p5.py -> build/lib/k1lib\n",
      "copying k1lib/kcom.py -> build/lib/k1lib\n",
      "copying k1lib/graphEqn.py -> build/lib/k1lib\n",
      "copying k1lib/_advanced.py -> build/lib/k1lib\n",
      "copying k1lib/schedule.py -> build/lib/k1lib\n",
      "copying k1lib/_perlin.py -> build/lib/k1lib\n",
      "copying k1lib/kws.py -> build/lib/k1lib\n",
      "copying k1lib/trans.py -> build/lib/k1lib\n",
      "copying k1lib/eqn.py -> build/lib/k1lib\n",
      "copying k1lib/kop.py -> build/lib/k1lib\n",
      "creating build/lib/k1lib/_hidden\n",
      "copying k1lib/_hidden/hiddenFile.py -> build/lib/k1lib/_hidden\n",
      "copying k1lib/_hidden/__init__.py -> build/lib/k1lib/_hidden\n",
      "creating build/lib/k1lib/cli\n",
      "copying k1lib/cli/bio.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/cif.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/structural.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/modifier.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/gb.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/output.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/kxml.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/ktree.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/nb.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/inp.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/mol.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/mgi.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/kcv.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/_applyCl.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/grep.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/kapi.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/models.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/sam.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/trace.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/kjs.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/__init__.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/typehint.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/kgv.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/filt.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/utils.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/init.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/conv.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/optimizations.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/lsext.py -> build/lib/k1lib/cli\n",
      "creating build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/loss_accuracy.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/progress.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/limits.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/hookParam.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/profiler.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/callbacks.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/paramFinder.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/core.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/__init__.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/landscape.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/confusionMatrix.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/recorder.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/shorts.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/hookModule.py -> build/lib/k1lib/callbacks\n",
      "creating build/lib/k1lib/callbacks/profilers\n",
      "copying k1lib/callbacks/profilers/time.py -> build/lib/k1lib/callbacks/profilers\n",
      "copying k1lib/callbacks/profilers/memory.py -> build/lib/k1lib/callbacks/profilers\n",
      "copying k1lib/callbacks/profilers/__init__.py -> build/lib/k1lib/callbacks/profilers\n",
      "copying k1lib/callbacks/profilers/io.py -> build/lib/k1lib/callbacks/profilers\n",
      "copying k1lib/callbacks/profilers/computation.py -> build/lib/k1lib/callbacks/profilers\n",
      "creating build/lib/k1lib/callbacks/lossFunctions\n",
      "copying k1lib/callbacks/lossFunctions/accuracy.py -> build/lib/k1lib/callbacks/lossFunctions\n",
      "copying k1lib/callbacks/lossFunctions/__init__.py -> build/lib/k1lib/callbacks/lossFunctions\n",
      "copying k1lib/callbacks/lossFunctions/shorts.py -> build/lib/k1lib/callbacks/lossFunctions\n",
      "creating build/lib/k1lib/_mo\n",
      "copying k1lib/_mo/atom.py -> build/lib/k1lib/_mo\n",
      "copying k1lib/_mo/parseM.py -> build/lib/k1lib/_mo\n",
      "copying k1lib/_mo/substance.py -> build/lib/k1lib/_mo\n",
      "copying k1lib/_mo/system.py -> build/lib/k1lib/_mo\n",
      "copying k1lib/_mo/__init__.py -> build/lib/k1lib/_mo\n",
      "creating build/lib/k1lib/serve\n",
      "copying k1lib/serve/suffix.py -> build/lib/k1lib/serve\n",
      "copying k1lib/serve/suffix-dash.py -> build/lib/k1lib/serve\n",
      "copying k1lib/serve/__init__.py -> build/lib/k1lib/serve\n",
      "copying k1lib/serve/main.py -> build/lib/k1lib/serve\n",
      "creating build/lib/k1lib/k1ui\n",
      "copying k1lib/k1ui/__init__.py -> build/lib/k1lib/k1ui\n",
      "copying k1lib/k1ui/main.py -> build/lib/k1lib/k1ui\n",
      "copying k1lib/serve/main.html -> build/lib/k1lib/serve\n",
      "copying k1lib/k1ui/256.model.state_dict.pth -> build/lib/k1lib/k1ui\n",
      "copying k1lib/k1ui/mouseKey.pth -> build/lib/k1lib/k1ui\n",
      "creating build/bdist.linux-x86_64\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/_learner.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "creating build/bdist.linux-x86_64/egg/k1lib/serve\n",
      "copying build/lib/k1lib/serve/main.html -> build/bdist.linux-x86_64/egg/k1lib/serve\n",
      "copying build/lib/k1lib/serve/suffix.py -> build/bdist.linux-x86_64/egg/k1lib/serve\n",
      "copying build/lib/k1lib/serve/suffix-dash.py -> build/bdist.linux-x86_64/egg/k1lib/serve\n",
      "copying build/lib/k1lib/serve/__init__.py -> build/bdist.linux-x86_64/egg/k1lib/serve\n",
      "copying build/lib/k1lib/serve/main.py -> build/bdist.linux-x86_64/egg/k1lib/serve\n",
      "copying build/lib/k1lib/fmt.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/selen.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/kast.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/_k1a.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/_context.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/selector.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/imports.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "creating build/bdist.linux-x86_64/egg/k1lib/k1ui\n",
      "copying build/lib/k1lib/k1ui/mouseKey.pth -> build/bdist.linux-x86_64/egg/k1lib/k1ui\n",
      "copying build/lib/k1lib/k1ui/__init__.py -> build/bdist.linux-x86_64/egg/k1lib/k1ui\n",
      "copying build/lib/k1lib/k1ui/main.py -> build/bdist.linux-x86_64/egg/k1lib/k1ui\n",
      "copying build/lib/k1lib/k1ui/256.model.state_dict.pth -> build/bdist.linux-x86_64/egg/k1lib/k1ui\n",
      "copying build/lib/k1lib/_baseClasses.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/_basics.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/serpent.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "creating build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/bio.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/cif.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/structural.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/modifier.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/gb.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/output.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/kxml.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/ktree.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/nb.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/inp.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/mol.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/mgi.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/kcv.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/_applyCl.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/grep.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/kapi.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/models.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/sam.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/trace.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/kjs.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/__init__.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/typehint.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/kgv.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/filt.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/utils.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/init.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/conv.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/optimizations.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/lsext.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/viz.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/zircon.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/_higher.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/__init__.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/_monkey.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "creating build/bdist.linux-x86_64/egg/k1lib/_mo\n",
      "copying build/lib/k1lib/_mo/atom.py -> build/bdist.linux-x86_64/egg/k1lib/_mo\n",
      "copying build/lib/k1lib/_mo/parseM.py -> build/bdist.linux-x86_64/egg/k1lib/_mo\n",
      "copying build/lib/k1lib/_mo/substance.py -> build/bdist.linux-x86_64/egg/k1lib/_mo\n",
      "copying build/lib/k1lib/_mo/system.py -> build/bdist.linux-x86_64/egg/k1lib/_mo\n",
      "copying build/lib/k1lib/_mo/__init__.py -> build/bdist.linux-x86_64/egg/k1lib/_mo\n",
      "copying build/lib/k1lib/knn.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/p5.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/kcom.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/graphEqn.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/_advanced.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/schedule.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "creating build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/loss_accuracy.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/progress.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/limits.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/hookParam.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/profiler.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/callbacks.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/paramFinder.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/core.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "creating build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers\n",
      "copying build/lib/k1lib/callbacks/profilers/time.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers\n",
      "copying build/lib/k1lib/callbacks/profilers/memory.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers\n",
      "copying build/lib/k1lib/callbacks/profilers/__init__.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers\n",
      "copying build/lib/k1lib/callbacks/profilers/io.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers\n",
      "copying build/lib/k1lib/callbacks/profilers/computation.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers\n",
      "copying build/lib/k1lib/callbacks/__init__.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/landscape.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/confusionMatrix.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/recorder.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/shorts.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/hookModule.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "creating build/bdist.linux-x86_64/egg/k1lib/callbacks/lossFunctions\n",
      "copying build/lib/k1lib/callbacks/lossFunctions/accuracy.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks/lossFunctions\n",
      "copying build/lib/k1lib/callbacks/lossFunctions/__init__.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks/lossFunctions\n",
      "copying build/lib/k1lib/callbacks/lossFunctions/shorts.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks/lossFunctions\n",
      "copying build/lib/k1lib/_perlin.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/kws.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/trans.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "creating build/bdist.linux-x86_64/egg/k1lib/_hidden\n",
      "copying build/lib/k1lib/_hidden/hiddenFile.py -> build/bdist.linux-x86_64/egg/k1lib/_hidden\n",
      "copying build/lib/k1lib/_hidden/__init__.py -> build/bdist.linux-x86_64/egg/k1lib/_hidden\n",
      "copying build/lib/k1lib/eqn.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/kop.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_learner.py to _learner.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/serve/suffix.py to suffix.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/serve/suffix-dash.py to suffix-dash.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/serve/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/serve/main.py to main.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/fmt.py to fmt.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/selen.py to selen.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/kast.py to kast.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_k1a.py to _k1a.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_context.py to _context.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/selector.py to selector.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/imports.py to imports.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/k1ui/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/k1ui/main.py to main.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_baseClasses.py to _baseClasses.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_basics.py to _basics.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/serpent.py to serpent.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/bio.py to bio.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/cif.py to cif.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/structural.py to structural.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/modifier.py to modifier.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/gb.py to gb.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/output.py to output.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/kxml.py to kxml.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/ktree.py to ktree.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/nb.py to nb.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/inp.py to inp.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/mol.py to mol.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/mgi.py to mgi.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/kcv.py to kcv.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/_applyCl.py to _applyCl.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/grep.py to grep.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/kapi.py to kapi.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/models.py to models.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/sam.py to sam.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/trace.py to trace.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/kjs.py to kjs.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/typehint.py to typehint.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/kgv.py to kgv.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/filt.py to filt.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/utils.py to utils.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/init.py to init.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/conv.py to conv.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/optimizations.py to optimizations.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/lsext.py to lsext.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/viz.py to viz.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/zircon.py to zircon.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_higher.py to _higher.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_monkey.py to _monkey.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_mo/atom.py to atom.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_mo/parseM.py to parseM.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_mo/substance.py to substance.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_mo/system.py to system.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_mo/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/knn.py to knn.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/p5.py to p5.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/kcom.py to kcom.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/graphEqn.py to graphEqn.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_advanced.py to _advanced.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/schedule.py to schedule.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/loss_accuracy.py to loss_accuracy.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/progress.py to progress.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/limits.py to limits.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/hookParam.py to hookParam.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/profiler.py to profiler.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/callbacks.py to callbacks.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/paramFinder.py to paramFinder.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/core.py to core.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers/time.py to time.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers/memory.py to memory.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers/io.py to io.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers/computation.py to computation.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/landscape.py to landscape.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/confusionMatrix.py to confusionMatrix.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/recorder.py to recorder.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/shorts.py to shorts.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/hookModule.py to hookModule.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/lossFunctions/accuracy.py to accuracy.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/lossFunctions/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/lossFunctions/shorts.py to shorts.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_perlin.py to _perlin.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/kws.py to kws.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/trans.py to trans.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_hidden/hiddenFile.py to hiddenFile.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_hidden/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/eqn.py to eqn.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/kop.py to kop.cpython-39.pyc\n",
      "installing package data to build/bdist.linux-x86_64/egg\n",
      "running install_data\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying k1lib.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying k1lib.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying k1lib.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying k1lib.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying k1lib.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "k1lib.cli.__pycache__.init.cpython-39: module MAY be using inspect.trace\n",
      "k1lib.cli.__pycache__.modifier.cpython-39: module references __file__\n",
      "k1lib.k1ui.__pycache__.main.cpython-39: module MAY be using inspect.getabsfile\n",
      "k1lib.k1ui.__pycache__.main.cpython-39: module MAY be using inspect.stack\n",
      "k1lib.serve.__pycache__.main.cpython-39: module MAY be using inspect.getsource\n",
      "k1lib.serve.__pycache__.main.cpython-39: module MAY be using inspect.getabsfile\n",
      "creating dist\n",
      "creating 'dist/k1lib-1.6-py3.9.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing k1lib-1.6-py3.9.egg\n",
      "creating /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages/k1lib-1.6-py3.9.egg\n",
      "Extracting k1lib-1.6-py3.9.egg to /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Adding k1lib 1.6 to easy-install.pth file\n",
      "\n",
      "Installed /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages/k1lib-1.6-py3.9.egg\n",
      "Processing dependencies for k1lib==1.6\n",
      "Searching for validators==0.20.0\n",
      "Best match: validators 0.20.0\n",
      "Adding validators 0.20.0 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for wurlitzer==3.0.3\n",
      "Best match: wurlitzer 3.0.3\n",
      "Adding wurlitzer 3.0.3 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for forbiddenfruit==0.1.4\n",
      "Best match: forbiddenfruit 0.1.4\n",
      "Adding forbiddenfruit 0.1.4 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for dill==0.3.7\n",
      "Best match: dill 0.3.7\n",
      "Adding dill 0.3.7 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for matplotlib==3.7.1\n",
      "Best match: matplotlib 3.7.1\n",
      "Adding matplotlib 3.7.1 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for numpy==1.25.0\n",
      "Best match: numpy 1.25.0\n",
      "Adding numpy 1.25.0 to easy-install.pth file\n",
      "Installing f2py script to /home/kelvin/anaconda3/envs/ray2/bin\n",
      "Installing f2py3 script to /home/kelvin/anaconda3/envs/ray2/bin\n",
      "Installing f2py3.9 script to /home/kelvin/anaconda3/envs/ray2/bin\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for decorator==5.1.1\n",
      "Best match: decorator 5.1.1\n",
      "Adding decorator 5.1.1 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for importlib-resources==5.12.0\n",
      "Best match: importlib-resources 5.12.0\n",
      "Adding importlib-resources 5.12.0 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for python-dateutil==2.8.2\n",
      "Best match: python-dateutil 2.8.2\n",
      "Adding python-dateutil 2.8.2 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for pyparsing==3.1.0\n",
      "Best match: pyparsing 3.1.0\n",
      "Adding pyparsing 3.1.0 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for Pillow==9.5.0\n",
      "Best match: Pillow 9.5.0\n",
      "Adding Pillow 9.5.0 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for packaging==23.1\n",
      "Best match: packaging 23.1\n",
      "Adding packaging 23.1 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for kiwisolver==1.4.4\n",
      "Best match: kiwisolver 1.4.4\n",
      "Adding kiwisolver 1.4.4 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for fonttools==4.40.0\n",
      "Best match: fonttools 4.40.0\n",
      "Adding fonttools 4.40.0 to easy-install.pth file\n",
      "Installing fonttools script to /home/kelvin/anaconda3/envs/ray2/bin\n",
      "Installing pyftmerge script to /home/kelvin/anaconda3/envs/ray2/bin\n",
      "Installing pyftsubset script to /home/kelvin/anaconda3/envs/ray2/bin\n",
      "Installing ttx script to /home/kelvin/anaconda3/envs/ray2/bin\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for cycler==0.11.0\n",
      "Best match: cycler 0.11.0\n",
      "Adding cycler 0.11.0 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for contourpy==1.1.0\n",
      "Best match: contourpy 1.1.0\n",
      "Adding contourpy 1.1.0 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for zipp==3.15.0\n",
      "Best match: zipp 3.15.0\n",
      "Adding zipp 3.15.0 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for six==1.16.0\n",
      "Best match: six 1.16.0\n",
      "Adding six 1.16.0 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Finished processing dependencies for k1lib==1.6\n"
     ]
    }
   ],
   "source": [
    "!../../export.py cli/utils --bootstrap=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d67dc82-c17b-4142-9a9c-43319c79ff2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

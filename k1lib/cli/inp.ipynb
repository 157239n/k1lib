{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20baf7bc-0542-4e7f-aa12-e8fc61c66f6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\"\"\"This module for tools that will likely start the processing stream.\"\"\"\n",
    "from typing import Iterator, Union, Any, List\n",
    "import k1lib, urllib, subprocess, warnings, os, k1lib, threading, time, warnings, math, io, dill, urllib, validators\n",
    "from collections import deque\n",
    "from k1lib.cli import BaseCli; import k1lib.cli as cli\n",
    "from k1lib.cli.typehint import *\n",
    "from contextlib import contextmanager\n",
    "requests = k1lib.dep(\"requests\")\n",
    "try: import minio; hasMinio = True\n",
    "except: hasMinio = False\n",
    "__all__ = [\"cat\", \"splitSeek\", \"refineSeek\", \"wget\", \"ls\", \"cmd\", \"walk\", \"requireCli\", \"urlPath\", \"kzip\", \"kunzip\", \"unzip\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "083b4967-07ef-4735-992c-2689c36a4a75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "settings = k1lib.settings.cli\n",
    "class NoPartialContent(Exception): pass\n",
    "def getChunk(url:str, sB:int, eB:int, timeout:float, retries:int) -> bytes: # start inclusive, end exclusive\n",
    "    for i in range(retries):\n",
    "        try: res = requests.get(url, headers={\"Range\": f\"bytes={sB}-{eB-1}\"}, timeout=timeout)\n",
    "        except Exception as e:\n",
    "            if i >= retries-1: raise Exception(f\"Can't get file chunk\")\n",
    "            continue\n",
    "        if res.status_code != 206: raise NoPartialContent(f\"Server doesn't allow partial downloads at this particular url. Status code: {res.status_code}\")\n",
    "        return res.content\n",
    "def getChunks(url:str, sB:int, eB:int, chunkSize=None, chunkTimeout:float=10, chunkRetries:int=10) -> List[bytes]:\n",
    "    \"\"\"Grabs bytes from sB to eB in chunks\"\"\"\n",
    "    chunkSize = chunkSize or settings.cli.cat.chunkSize\n",
    "    return range(sB, eB+1) | cli.batched(chunkSize, True) | cli.apply(lambda r: getChunk(url, r.start, r.stop-1, chunkTimeout, chunkRetries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03cd7374-8ae0-49bb-9675-78b416799a1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Settings:                   \n",
       "- memoryLimit = 100000000   ​if the internal cache exceeds this limit (in bytes), and randomAccess is False, then old downloaded chunks will be deleted   \n",
       "- timeout     = 10          ​seconds before terminating the remote request and retrying                                                                   \n",
       "- retries     = 10          ​how many times to retry sending the request before giving up                                                                 \n",
       "                            "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export\n",
    "catSettings = k1lib.Settings().add(\"chunkSize\", 100000, \"file reading chunk size for binary+chunk mode. Decrease it to avoid wasting memory and increase it to avoid disk latency\")\n",
    "catSettings.add(\"every\", k1lib.Settings().add(\"text\", 1000, \"for text mode, will print every n lines\").add(\"binary\", 10, \"for binary mode, will print every n 100000-byte blocks\"), \"profiler print frequency\")\n",
    "settings.add(\"cat\", catSettings, \"inp.cat() settings\")\n",
    "\n",
    "rfS = k1lib.Settings()\n",
    "settings.add(\"RemoteFile\", rfS, \"inp.RemoteFile() settings, used in cat(), splitSeek() and the like\")\n",
    "rfS.add(\"memoryLimit\", 100_000_000, \"if the internal cache exceeds this limit (in bytes), and randomAccess is False, then old downloaded chunks will be deleted\")\n",
    "rfS.add(\"timeout\", 10, \"seconds before terminating the remote request and retrying\")\n",
    "rfS.add(\"retries\", 10, \"how many times to retry sending the request before giving up\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6015e0c-8232-468b-8ae3-c08552c16ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def noPartial(url, *args):\n",
    "    try: return len(getChunk(url, 0, 10, *args)) != 10\n",
    "    except NoPartialContent: return True\n",
    "class RemoteFile:\n",
    "    def __init__(self, url, randomAccess=True, blockSize=None, noPartialConfirm=False, timeout:float=None, retries:int=None):\n",
    "        \"\"\"\n",
    ":param url: url of the remote file\n",
    ":param randomAccess: is random accessing parts of the file expected? If\n",
    "    True, then keeps all of the reads in ram internally, else free them\n",
    "    as soon as possible\n",
    ":param blockSize: all reads will fetch roughly this amount of bytes\"\"\"\n",
    "        self.url = url; self.randomAccess = randomAccess; self.blockSize = blockSize or settings.cat.chunkSize\n",
    "        self.noPartialConfirm = noPartialConfirm; self.size = None; self.domain = k1lib.Domain()\n",
    "        self.seekPos = 0; self.reads = deque() # List[sB, eB, content]\n",
    "        self._confirmMsgShown = False; self.timeout = timeout or rfS.timeout; self.retries = retries or rfS.retries\n",
    "        self._totalReadSize = 0; self.noPartial = noPartial(url, self.timeout, self.retries)\n",
    "    def _fetch(self, sB:int, eB:int): # fetches from start to end byte and dumps to internal memory. Inclusive start and end byte\n",
    "        if not self.noPartial:\n",
    "            eB = max(eB, min(sB+self.blockSize, len(self)))\n",
    "            chunk = getChunk(self.url, sB, eB, self.timeout, self.retries)\n",
    "        else:\n",
    "            if self.noPartialConfirm and not self._confirmMsgShown:\n",
    "                ans = input(f\"\"\"Remote file '{self.url}' don't support partial downloads.\n",
    "Therefore the entire file will be loaded into RAM, which\n",
    "could be undesireable. Do you want to continue? Y/n: \"\"\")\n",
    "                self._confirmMsgShown = True\n",
    "                if ans.lower()[0] != \"y\": self.reads.append([0, 0, b\"\"]); return\n",
    "            sB = 0; chunk = requests.get(self.url).content; eB = len(chunk)\n",
    "        self.reads.append([sB, eB, chunk])\n",
    "        self._totalReadSize += len(chunk); self.domain = self.domain + k1lib.Domain([sB, eB])\n",
    "        if not self.randomAccess and self._totalReadSize > rfS.memoryLimit: # deletes old reads\n",
    "            sB, eB, chunk = self.reads.popleft()\n",
    "            self._totalReadSize -= len(chunk)\n",
    "    def _ensureRange(self, sB, eB): # makes sure that all ranges between sB and eB are available\n",
    "        missingDomain = k1lib.Domain([max(sB-30, 0), min(eB+30, len(self))]) & -self.domain\n",
    "        for sB, eB in missingDomain.ranges: self._fetch(sB, eB)\n",
    "    def _readChunks(self, sB, eB): # read from sB to eB, but in chunks, to be optimized. inclusive sB, exclusive eB\n",
    "        sB = max(min(sB, len(self)), 0); eB = max(min(eB, len(self)), 0); self._ensureRange(sB, eB)\n",
    "        return self.reads | cli.filt(~cli.aS(lambda s,e,chunk: e>=sB and s<=eB)) | cli.sort() | ~cli.apply(lambda s,e,chunk: chunk[max(sB-s, 0):len(chunk)+min(eB-e, 0)]) | cli.filt(len)\n",
    "    def seek(self, cookie, whence=0):\n",
    "        if whence == 0: self.seekPos = cookie\n",
    "        elif whence == 1: self.seekPos += cookie\n",
    "        elif whence == 2: self.seekPos = len(self) + cookie\n",
    "        else: raise Exception(\"Invalid whence\")\n",
    "        return self.seekPos\n",
    "    def read(self, size, join=True):\n",
    "        chunks = self._readChunks(self.seekPos, self.seekPos + size)\n",
    "        self.seekPos += size; return b\"\".join(chunks) if join else chunks\n",
    "    def readline(self, newLine=True):\n",
    "        ans = []; seekPos = self.seekPos\n",
    "        try:\n",
    "            while self.seekPos < len(self):\n",
    "                for chunk in self.read(self.blockSize, False):\n",
    "                    if len(chunk) == 0: raise SyntaxError()\n",
    "                    ans.append(chunk)\n",
    "                    if b\"\\n\" in chunk: raise SyntaxError()\n",
    "        except SyntaxError: pass\n",
    "        ans = b\"\".join(ans)\n",
    "        try: n = ans.index(b\"\\n\")\n",
    "        except ValueError: n = len(ans) # only happens at end of file\n",
    "        self.seekPos = seekPos + n+1; return (ans[:n+1] if newLine else ans[:n]).decode()\n",
    "    def readlines(self, newLine=True):\n",
    "        while True:\n",
    "            yield self.readline(newLine)\n",
    "            if self.seekPos >= len(self): break\n",
    "    def tell(self): return self.seekPos\n",
    "    def _getSize(self):\n",
    "        if self.noPartial: self._fetch(0, 10); return self.reads[0][1]\n",
    "        for i in range(self.retries):\n",
    "            try: return requests.head(self.url, timeout=self.timeout).headers.items() | cli.apply(cli.op().lower(), 0) | cli.toDict() | cli.op()[\"content-length\"].ab_int()\n",
    "            except Exception as e:\n",
    "                if i >= self.retries: raise Exception(f\"Can't get size of remote file: {e}\")\n",
    "    def __len__(self):\n",
    "        if self.size is None: self.size = self._getSize()\n",
    "        return self.size\n",
    "    def __repr__(self): return f\"<RemoteFile url={self.url} size={k1lib.fmt.size(len(self))}>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "835a5a69-cad7-4ba3-b66a-0ee1447c2272",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = \"http://vim.kelvinho.org/.vimrc\"; rf = RemoteFile(url, True, 30, True)\n",
    "a = rf.readlines(False) | cli.deref(); b = requests.get(url).text.split(\"\\n\")[:-1]; assert a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12161194",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import zipfile, inspect\n",
    "class ZipWrapper:\n",
    "    def __init__(self, a, zfn): self.a = a; self.zfn = zfn\n",
    "    def __repr__(self):\n",
    "        a = self.a; s = f\" ({round(a.compress_size/a.file_size*100)}%)\" if a.file_size > 0 else \"\"\n",
    "        return f\"<Zip subfile name='{a.filename}' {k1lib.fmt.size(a.file_size)} -> {k1lib.fmt.size(a.compress_size)}{s}>\"\n",
    "    @property\n",
    "    def size(self): return a.file_size\n",
    "    @property\n",
    "    def compressedSize(self): return a.compress_size\n",
    "    def _catHandle(self):\n",
    "        with zipfile.ZipFile(self.zfn) as zipf:\n",
    "            with zipf.open(self.a.filename) as subfile:\n",
    "                yield subfile\n",
    "@contextmanager\n",
    "def openFile(fn, text, noPartialConfirm=False): # can be actual file or url\n",
    "    if not isinstance(fn, str):\n",
    "        if hasattr(fn, \"_catHandle\"): yield from fn._catHandle(); return # custom datatype case\n",
    "        else: yield fn; return # file handle case, just return itself\n",
    "    if os.path.exists(fn):\n",
    "        if text:\n",
    "            with open(fn, \"r\", settings.cat.chunkSize) as f: yield f\n",
    "        else:\n",
    "            with open(fn, \"rb\", settings.cat.chunkSize) as f: yield f\n",
    "    elif validators.url(fn) is True:\n",
    "        yield RemoteFile(fn, False, noPartialConfirm=noPartialConfirm)\n",
    "    else: raise FileNotFoundError(f\"The file {fn} doesn't seem to exist and/or it's not a valid url\")\n",
    "def _catGenText(fn, sB, eB): # fn for \"file name\"\n",
    "    try:\n",
    "        if sB == 0 and eB == -1: # fast path without bounds (90-160 MB/s expected)\n",
    "            with openFile(fn, True) as f:\n",
    "                line = f.readline()\n",
    "                if isinstance(line, str): # why put the if outside the loop? Speed reasons. Also, isn't .readline() supposed to return a string? Well, cause we're supporting random file handles from custom datatypes, some asshole file handles might return bytes instead\n",
    "                    while True:\n",
    "                        if line == \"\": return\n",
    "                        yield line[:-1] if line[-1] == \"\\n\" else line\n",
    "                        line = f.readline()\n",
    "                else:\n",
    "                    while True:\n",
    "                        line = line.decode()\n",
    "                        if line == \"\": return\n",
    "                        yield line[:-1] if line[-1] == \"\\n\" else line\n",
    "                        line = f.readline()\n",
    "        else: # slow path with bounds (15 MB/s expected). Update: much faster now, expect only 40% slower than the path above\n",
    "            sB = wrap(fn, sB); eB = wrap(fn, eB)\n",
    "            with openFile(fn, True) as f:\n",
    "                f.seek(sB); b = sB # current byte\n",
    "                line = f.readline()\n",
    "                if isinstance(line, str):\n",
    "                    while True:\n",
    "                        b += len(line)\n",
    "                        if len(line) == 0: return\n",
    "                        if b > eB: yield line[:len(line)-(b-eB)]; return\n",
    "                        yield line[:-1] if line[-1] == \"\\n\" else line\n",
    "                        line = f.readline()\n",
    "                else:\n",
    "                    while True:\n",
    "                        line = line.decode()\n",
    "                        b += len(line)\n",
    "                        if len(line) == 0: return\n",
    "                        if b > eB: yield line[:len(line)-(b-eB)]; return\n",
    "                        yield line[:-1] if line[-1] == \"\\n\" else line\n",
    "                        line = f.readline()\n",
    "    except FileNotFoundError: pass\n",
    "def _catGenBin(fn, sB, eB):\n",
    "    chunkSize = settings.cat.chunkSize; sB = wrap(fn, sB); eB = wrap(fn, eB); nB = eB - sB # number of bytes to read total\n",
    "    with openFile(fn, False) as f:\n",
    "        f.seek(sB); nChunks = math.ceil(nB / chunkSize); lastChunkSize = nB - chunkSize*(nChunks-1)\n",
    "        # had to do this because RemoteFile is actually not thread-safe\n",
    "        # applyF = (lambda f_: cli.apply(f_)) if isinstance(f, RemoteFile) else (lambda f_: cli.applyTh(f_, prefetch=10))\n",
    "        applyF = (lambda f_: cli.apply(f_)) # actually, normal reads are not thread-safe either. Stupid me\n",
    "        yield from range(nChunks) | applyF(lambda i: f.read(chunkSize) if i < nChunks-1 else f.read(chunkSize)[:lastChunkSize])\n",
    "def fileLength(fn):\n",
    "    with openFile(fn, False) as f: return f.seek(0, os.SEEK_END)\n",
    "def wrap(fn, b): return b if b >= 0 else b + fileLength(fn) + 1\n",
    "class _cat(BaseCli):\n",
    "    def __init__(self, text, chunks, sB, eB):\n",
    "        super().__init__(capture=True)\n",
    "        self.text = text; self.chunks = chunks; self.sB = sB; self.eB = eB\n",
    "    def _typehint(self, ignored=None):\n",
    "        if self.text: return tIter(str) if self.chunks else tList(str)\n",
    "        else: return tIter(bytes) if self.chunks else bytes\n",
    "    def __ror__(self, fn:Union[str, \"fileHandle\"]) -> Union[Iterator[str], bytes]:\n",
    "        ser = self.capturedSerial; text = self.text; chunks = self.chunks; sB = self.sB; eB = self.eB\n",
    "        if not isinstance(fn, str) and hasattr(fn, \"_cat\"): # custom datatype, _cat method defined, so it will take control of things\n",
    "            kwargs = {\"text\": text, \"chunks\": chunks, \"sB\": sB, \"eB\": eB}\n",
    "            kwdiff = [a for a, b in [[\"text\",text!=True], [\"chunks\",chunks!=True if text else chunks!=False], [\"sB\",sB!=0], [\"eB\",eB!=-1]] if b]\n",
    "            args = inspect.getfullargspec(fn._cat).args[1:]; n = len(args)\n",
    "            s = set([\"ser\", \"kwargs\"]); weirdArgs = [a for a in args if a not in s]\n",
    "            if len(weirdArgs) > 0: raise Exception(f\"Custom datatype `{type(fn)}` has ._cat() method, which expects only `ser` and `kwargs` arguments, but detected these arguments instead: {weirdArgs}. Please fix `{type(fn)}`\")\n",
    "            def guard():\n",
    "                if kwdiff: raise Exception(f\"Custom datatype `{type(fn)}` does not support custom cat() arguments like {kwdiff}\")\n",
    "            if n == 0: guard(); return fn._cat() | ser\n",
    "            elif n == 1:\n",
    "                if args[0] == \"ser\": guard(); return fn._cat(ser)\n",
    "                if args[0] == \"kwargs\": return fn._cat(kwargs) | ser\n",
    "            elif n == 2:\n",
    "                if args[0] == \"ser\": return fn._cat(ser, kwargs)\n",
    "                else: return fn._cat(kwargs, ser)\n",
    "            else: raise Exception(\"Unreachable\")\n",
    "        fn = os.path.expanduser(fn) if isinstance(fn, str) else fn\n",
    "        if text and chunks and k1lib._settings.packages.k1a and isinstance(fn, str) and os.path.exists(fn):\n",
    "            return k1lib._k1a.k1a.StrIterCat(fn, sB, eB) | ser # accelerated C version\n",
    "        if chunks: return _catGenText(fn, sB, eB) if text else _catGenBin(fn, sB, eB) | ser\n",
    "        sB = wrap(fn, sB); eB = wrap(fn, eB)\n",
    "        if text:\n",
    "            with openFile(fn, True) as f: f.seek(sB); return f.read(eB-sB).splitlines() | ser\n",
    "        else:\n",
    "            with openFile(fn, False) as f: f.seek(sB); return f.read(eB-sB) | ser\n",
    "class Profile(BaseCli):\n",
    "    def __init__(self, text): self.data = []; self.text = text\n",
    "    def __ror__(self, it):\n",
    "        fmt = k1lib.fmt; chars = 0; beginTime = time.time()\n",
    "        if self.text:\n",
    "            a, b, c, d, f = k1lib.ConstantPad.multi(5); every = settings.cat.every.text\n",
    "            for lines, e in enumerate(it):\n",
    "                chars += len(e)\n",
    "                if lines % every == 0: # every 1000 lines, print stuff out\n",
    "                    elapsed = time.time() - beginTime#; self.data.append([lines, chars, elapsed])\n",
    "                    print(f\"Current line: {fmt.item(lines) | a} ({fmt.item(lines/elapsed) | b} lines/s), current byte/chars: {fmt.size(chars) | c} ({fmt.size(chars/elapsed) | d}/s), elapsed: {fmt.time(elapsed) | f}                                 \", end=\"\\r\")\n",
    "                yield e\n",
    "        else:\n",
    "            a, b, c = k1lib.ConstantPad.multi(3); every = settings.cat.every.binary\n",
    "            for i, e in enumerate(it):\n",
    "                chars += len(e)\n",
    "                if i % every == 0: # every 10 100000-byte chunks, print stuff out\n",
    "                    elapsed = time.time() - beginTime#; self.data.append([chars, elapsed])\n",
    "                    print(f\"Current size/chars: {fmt.size(chars) | a} ({fmt.size(chars/elapsed) | b}/s), elapsed: {fmt.time(elapsed) | c}                                 \", end=\"\\r\")\n",
    "                yield e\n",
    "def cat(fileName:str=None, text:bool=True, chunks:bool=None, profile:bool=False, sB=0, eB=-1):\n",
    "    \"\"\"Reads a file line by line.\n",
    "Example::\n",
    "\n",
    "    # display first 10 lines of file\n",
    "    cat(\"file.txt\") | headOut()\n",
    "    # piping in also works\n",
    "    \"file.txt\" | cat() | headOut()\n",
    "    \n",
    "    # read bytes from an image file and dumps it to another file\n",
    "    cat(\"img.png\", False) | file(\"img2.png\")\n",
    "\n",
    "If you want to read only specific sections of the file, you can specify the\n",
    "start (``sB``) and end byte (``eB``) like this::\n",
    "\n",
    "    \"123456\\\\n89\" | file(\"test/catTest.pth\")\n",
    "    # returns ['3456', '8']\n",
    "    cat(\"test/catTest.pth\", sB=2, eB=8) | deref()\n",
    "    \n",
    "    settings.cat.context.chunkSize=3 # just for demonstration, don't do it normally\n",
    "    # returns [b'123', b'456', b'\\\\n8']\n",
    "    cat(\"test/catTest.pth\", text=False, chunks=True, eB=8) | deref()\n",
    "\n",
    ".. admonition:: Remote files\n",
    "\n",
    "    You can also read from urls directly, like this::\n",
    "\n",
    "        cat(\"https://k1lib.com/latest/\") | deref()\n",
    "\n",
    "    For remote files like this, there are extra settings at :data:`~k1lib.settings`.cli.RemoteFile.\n",
    "    This will also read the file chunk by chunk if required. If the website doesn't support\n",
    "    partial downloads, then all of it will be downloaded and stored into ram, which may not be\n",
    "    desireable. The available settings are:\n",
    "    \n",
    "    - timeout: seconds before killing the existing request\n",
    "    - retries: try to resend the request for this much before giving up\n",
    "\n",
    "If you are working with large files and would like to read 1 file from multiple\n",
    "threads/processes, then you can use this cli in conjunction with :class:`splitSeek`.\n",
    "\n",
    "If you are dumping multiple pickled objects into a single file, you can read all\n",
    "of them using :meth:`cat.pickle`.\n",
    "\n",
    "This cli has lots of settings at :data:`~k1lib.settings`.cli.cat\n",
    "\n",
    "See also: :meth:`ls`\n",
    "\n",
    ".. admonition:: Custom datatype\n",
    "\n",
    "    It is possible to build objects that can interoperate with this cli,\n",
    "    like this::\n",
    "\n",
    "        class custom1:\n",
    "            def __init__(self, config=None): ...\n",
    "            def _cat(self): return [\"abc\", \"def\"]\n",
    "\n",
    "        custom1() |  cat()           # returns [\"abc\", \"def\"]\n",
    "        custom1() |  cat() | item()  # returns \"abc\"\n",
    "        custom1() | (cat() | item()) # returns \"abc\"\n",
    "\n",
    "    When called upon, :meth:`cat` will see that the input is not a simple string, which\n",
    "    will prompt it to look for ``_cat()`` method of the complex object and execute it.\n",
    "    By default, if the user specifies any non-default arguments like ``text=False``,\n",
    "    it will errors out because :meth:`cat` does not know how to handle it. Here's how\n",
    "    to do it right::\n",
    "\n",
    "        class custom2:\n",
    "            def __init__(self, config=None): ...\n",
    "            def _cat(self, kwargs): # default kwargs if user doesn't specify anything else is `{\"text\": True, \"chunks\": None, \"sB\": 0, \"eB\": -1}`\n",
    "                if kwargs[\"text\"]: return [\"abc\", \"def\"]\n",
    "                else: return [b\"abc\", b\"def\"]\n",
    "        \n",
    "        custom2() |  cat()                     # returns [\"abc\", \"def\"]\n",
    "        custom2() |  cat()           | item()  # returns \"abc\"\n",
    "        custom2() | (cat()           | item()) # returns \"abc\"\n",
    "        custom2() |  cat(text=False)           # returns [b\"abc\", b\"def\"]\n",
    "        custom2() |  cat(text=False) | item()  # returns b\"abc\"\n",
    "\n",
    "    Here, you're saying that your function can handle non-standard arguments, so\n",
    "    :meth:`cat` will give you all the args. You may support only some arguments\n",
    "    and completely ignore others, it's all up to you. Might still be worth it to\n",
    "    throw some errors warning users of arguments your custom datatype does not support.\n",
    "    \n",
    "    You can also capture future clis like this::\n",
    "\n",
    "        class custom3:\n",
    "            def __init__(self, config=None): ...\n",
    "            def _cat(self, ser):            # \"ser\" stands for \"serial\"\n",
    "                if len(ser.clis) == 1 and isinstance(ser.clis[0], item):\n",
    "                    return \"123\"            # fancy optimization\n",
    "                return [\"abc\", \"def\"] | ser # default \"slow\" base case\n",
    "\n",
    "        custom3() |  cat()           # returns [\"abc\", \"def\"]\n",
    "        custom3() |  cat() | item()  # returns \"abc\", because cat() did not capture any clis\n",
    "        custom3() | (cat() | item()) # returns \"123\", which might be desireable, up to you\n",
    "\n",
    "    This feature is pretty advanced actually, in that you can actually do different\n",
    "    things based on future processing tasks. Let's say that the captured cli looks like\n",
    "    ``cut(3) | batched(10) | rItem(3)``. This essentially means \"give me elements 30\n",
    "    through 39 from the 4th column\". With this information, you can query your custom\n",
    "    database for exactly those elements only, while fetching nothing else, which would be\n",
    "    great for performance.\n",
    "    \n",
    "    You can also outright lie to the user like in the example, where if :class:`~k1lib.cli.utils.item`\n",
    "    is detected, it will return a completely different version (\"123\") while it should return\n",
    "    \"abc\" instead. The possibilities are endless. As you can probably feel, it's super hard to\n",
    "    actually utilize this in the right way without breaking something, as you are completely\n",
    "    responsible for the captured clis. Let's see another example::\n",
    "\n",
    "        class custom4:\n",
    "            def __init__(self, config=None): ...\n",
    "            def _cat(self, ser):\n",
    "                return [\"abc\", \"def\"]\n",
    "        \n",
    "        custom4() |  cat()           # returns [\"abc\", \"def\"]\n",
    "        custom4() |  cat() | item()  # returns \"abc\"\n",
    "        custom4() | (cat() | item()) # returns [\"abc\", \"def\"]\n",
    "\n",
    "    Same story as ``custom3``, demonstrating that if you declare that you want to see and\n",
    "    manipulate ``ser``, you'll be completely responsible for it, and if you don't handle it\n",
    "    correctly, it will create horrible bugs. You can, of course, have access to ``ser`` and\n",
    "    ``kwargs`` at the same time::\n",
    "\n",
    "        class custom5:\n",
    "            def __init__(self, config=None): ...\n",
    "            def _cat(self, ser, kwargs): return [\"abc\", \"def\"] | ser\n",
    "    \n",
    "    If your custom datatype feels like a block device, and you don't want to rewrite all\n",
    "    the functionalities in :meth:`cat`, you can implement the method ``_catHandle`` that\n",
    "    yields the custom file handle instead::\n",
    "    \n",
    "        class custom6:\n",
    "            def __init__(self, config=None): ...\n",
    "            def _catHandle(self): yield io.BytesIO(b\"abc\\\\ndef\\\\n123\")\n",
    "        class custom7:\n",
    "            def __init__(self, config=None): ...\n",
    "            def _catHandle(self): yield io.StringIO(\"abc\\\\ndef\\\\n123\")\n",
    "\n",
    "        custom6() | cat(text=False) # returns b'abc\\\\ndef\\\\n123'\n",
    "        custom7() | cat() | deref() # returns ['abc', 'def', '123']\n",
    "\n",
    "    Remember that you have to yield instead of returning the file handle. This is so that\n",
    "    you can use ``with`` statements, and if you return the file handle, the file might be\n",
    "    closed by the time :meth:`cat` decides to use it.\n",
    "\n",
    ":param fileName: if None, then return a :class:`~k1lib.cli.init.BaseCli`\n",
    "    that accepts a file name and outputs Iterator[str]\n",
    ":param text: if True, read text file, else read binary file\n",
    ":param chunks: if True then reads the file chunk by chunk, else reads the\n",
    "    entire file. Defaults to True in text mode and False in binary mode\n",
    ":param profile: whether to profile the file reading rate or not. Can adjust\n",
    "    printing frequency using `settings.cli.cat.every`\n",
    ":param sB: \"start byte\". Specify this if you want to start reading from this byte\n",
    ":param eB: \"end byte\", exclusive. Default -1 means end of file\"\"\"\n",
    "    if chunks is None: chunks = True if text else False # dev note: if default arguments are changed, please also change _cat()'s implementation for custom datatypes\n",
    "    if profile and not chunks: warnings.warn(f\"Can't profile reading rate when you're trying to read everything at once\"); profile = False\n",
    "    f = _cat(text, chunks, sB, eB)\n",
    "    if profile: f = f | Profile(text)\n",
    "    return f if fileName is None else fileName | f\n",
    "def _catPickle(fileName=None, pickleModule=dill):\n",
    "    \"\"\"Reads a file as a series of pickled objects.\n",
    "Example::\n",
    "\n",
    "    \"ab\" | aS(dill.dumps) | file(\"test/catTest.pth\")\n",
    "    \"cd\" | aS(dill.dumps) >> file(\"test/catTest.pth\") # append to the file\n",
    "    # returns [\"ab\", \"cd\"]\n",
    "    cat.pickle(\"test/catTest.pth\") | deref()\n",
    "    # also returns [\"ab\", \"cd\"], same style as :class:`cat`\n",
    "    \"test/catTest.pth\" | cat.pickle() | deref()\n",
    "\n",
    ":param fileName: name of the pickled file\n",
    ":param pickleModule: pickle module to use. Python's default is \"pickle\", but\n",
    "    I usually use :mod:`dill` because it's more robust\"\"\"\n",
    "    def gen(fn):\n",
    "        with open(os.path.expanduser(fn), \"rb\") as f:\n",
    "            try:\n",
    "                while True: yield dill.load(f)\n",
    "            except: pass\n",
    "    return cli.aS(gen) if fileName is None else fileName | cli.aS(gen)\n",
    "cat.pickle = _catPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45ee1a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current size/chars: 999.1 MB (  3.83 GB/s), elapsed: 261.02 ms                                 \r"
     ]
    }
   ],
   "source": [
    "k1lib._settings.packages.k1a = True\n",
    "assert len(\"inp.py\" | cat() | cli.head() | cli.toList()) == 10\n",
    "assert len(cat(\"inp.py\") | cli.head() | cli.toList()) == 10\n",
    "k1lib._settings.packages.k1a = False\n",
    "assert len(\"inp.py\" | cat() | cli.head() | cli.toList()) == 10\n",
    "assert len(cat(\"inp.py\") | cli.head() | cli.toList()) == 10\n",
    "assert cat(\"~/ssd/data/pubchem/Compound/CID-SMILES\", profile=True) | cli.head(int(1e6)) | cli.shape(0) == 1000000\n",
    "assert cat(\"~/ssd/data/pubchem/Compound/CID-SMILES\", False, True, True) | cli.head(10000) | cli.shape(0) == 10000\n",
    "\"123456\\n89\" | cli.file(\"test/catTest.pth\")\n",
    "assert fileLength(\"test/catTest.pth\") == 10\n",
    "assert cat(\"test/catTest.pth\", eB=9) | cli.deref() == ['123456', '89']\n",
    "assert cat(\"test/catTest.pth\", eB=8) | cli.deref() == ['123456', '8']\n",
    "assert cat(\"test/catTest.pth\", eB=7) | cli.deref() == ['123456', '']\n",
    "assert cat(\"test/catTest.pth\", eB=6) | cli.deref() == ['123456']\n",
    "assert cat(\"test/catTest.pth\", sB=2, eB=8) | cli.deref() == ['3456', '8']\n",
    "assert cat(\"test/catTest.pth\", False) == b'123456\\n89\\n'\n",
    "assert cat(\"test/catTest.pth\", False, eB=9) == b'123456\\n89'\n",
    "assert cat(\"test/catTest.pth\", False, eB=8) == b'123456\\n8'\n",
    "assert cat(\"test/catTest.pth\", False, True, eB=9) | cli.deref() == [b'123456\\n89']\n",
    "assert cat(\"test/catTest.pth\", False, True, eB=8) | cli.deref() == [b'123456\\n8']\n",
    "assert cat(\"test/catTest.pth\", False, True, eB=6) | cli.deref() == [b'123456']\n",
    "assert cat(\"test/catTest.pth\", False, True, sB=7, eB=6) | cli.deref() == []\n",
    "with settings.cat.context(chunkSize=3):\n",
    "    assert (cat(\"test/catTest.pth\", False, True, eB=9) | cli.deref() == [b'123', b'456', b'\\n89'])\n",
    "    assert (cat(\"test/catTest.pth\", False, True, eB=8) | cli.deref() == [b'123', b'456', b'\\n8'])\n",
    "    assert (cat(\"test/catTest.pth\", False, True, eB=6) | cli.deref() == [b'123', b'456'])\n",
    "    assert (cat(\"test/catTest.pth\", False, True, sB=7, eB=6) | cli.deref() == [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32024b65-7d1d-4917-bc66-4cd3a0f92e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"ab\" | cli.aS(dill.dumps) | cli.file(\"test/catTest.pth\")\n",
    "\"cd\" | cli.aS(dill.dumps) >> cli.file(\"test/catTest.pth\")\n",
    "assert cat.pickle(\"test/catTest.pth\") | cli.deref() == [\"ab\", \"cd\"]\n",
    "assert \"test/catTest.pth\" | cat.pickle() | cli.deref() == [\"ab\", \"cd\"]\n",
    "url = \"https://vim.kelvinho.org/.vimrc\"\n",
    "assert cat(url, sB=2, eB=20) | cli.item() == \"ntax on\"\n",
    "assert cat(\"https://k1lib.com/latest/\", profile=True) | cli.deref() | cli.shape(0) > 0\n",
    "assert \"test/nucleo-free-sample.zip\" | cli.ls() | ~cli.grep(\" 0.0 B\") | cli.shape(0) == 2344\n",
    "assert \"test/nucleo-free-sample.zip\" | cli.ls() | ~cli.grep(\" 0.0 B\") | cli.item() | cat(text=False) | cli.shape(0) == 312\n",
    "try: \"test/nucleo-free-sample.zip\" | cli.ls() | ~cli.grep(\" 0.0 B\") | cli.item() | cat() | cli.deref(); assert False\n",
    "except UnicodeDecodeError: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b87b19ce-59e0-4833-87ce-2cd463c3716c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class custom1:\n",
    "    def __init__(self, config=None): ...\n",
    "    def _cat(self): return [\"abc\", \"def\"]\n",
    "assert custom1() |  cat()           == [\"abc\", \"def\"]\n",
    "assert custom1() |  cat() | cli.item()  == \"abc\"\n",
    "assert custom1() | (cat() | cli.item()) == \"abc\"\n",
    "class custom2:\n",
    "    def __init__(self, config=None): ...\n",
    "    def _cat(self, kwargs): # default kwargs if user doesn't specify anything else is `{\"text\": True, \"chunks\": None, \"sB\": 0, \"eB\": -1}`\n",
    "        if kwargs[\"text\"]: return [\"abc\", \"def\"]\n",
    "        else: return [b\"abc\", b\"def\"]\n",
    "assert custom2() |  cat()                         == [\"abc\", \"def\"]\n",
    "assert custom2() |  cat()           | cli.item()  == \"abc\"\n",
    "assert custom2() | (cat()           | cli.item()) == \"abc\"\n",
    "assert custom2() |  cat(text=False)               == [b\"abc\", b\"def\"]\n",
    "assert custom2() |  cat(text=False) | cli.item()  == b\"abc\"\n",
    "class custom3:\n",
    "    def __init__(self, config=None): ...\n",
    "    def _cat(self, ser):\n",
    "        if len(ser.clis) == 1 and isinstance(ser.clis[0], cli.item): return \"123\"\n",
    "        else: return [\"abc\", \"def\"] | ser\n",
    "assert custom3() |  cat()               == [\"abc\", \"def\"]\n",
    "assert custom3() |  cat() | cli.item()  == \"abc\"\n",
    "assert custom3() | (cat() | cli.item()) == \"123\"\n",
    "class custom4:\n",
    "    def __init__(self, config=None): ...\n",
    "    def _cat(self, ser): return [\"abc\", \"def\"]\n",
    "assert custom4() |  cat()               == [\"abc\", \"def\"]\n",
    "assert custom4() |  cat() | cli.item()  == \"abc\"\n",
    "assert custom4() | (cat() | cli.item()) == [\"abc\", \"def\"]\n",
    "class custom5:\n",
    "    def __init__(self, config=None): ...\n",
    "    def _cat(self, ser, kwargs): return [\"abc\", \"def\"] | ser\n",
    "class custom6:\n",
    "    def __init__(self, config=None): ...\n",
    "    def _catHandle(self): yield io.BytesIO(b\"abc\\ndef\\n123\")\n",
    "assert custom6() | cat(text=False) == b'abc\\ndef\\n123'\n",
    "class custom7:\n",
    "    def __init__(self, config=None): ...\n",
    "    def _catHandle(self): yield io.StringIO(\"abc\\ndef\\n123\")\n",
    "assert custom7() | cat() | cli.deref() == ['abc', 'def', '123']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bc0b68d-5203-42a9-a369-1906a058bf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class splitSeek(BaseCli):\n",
    "    def __init__(self, n=None, c=b'\\n', ws=None):\n",
    "        \"\"\"Splits a file up into n fragments aligned to the closest character and return the seek points.\n",
    "Example::\n",
    "\n",
    "    # preparing the large file\n",
    "    range(120) | apply(lambda x: f\"{x:3}_56789\") | file(\"test/largeFile.txt\")\n",
    "    # returns [0, 30, 70, 110, 150, 190, 230, 270, 300, 340]\n",
    "    \"test/largeFile.txt\" | splitSeek(31) | head()\n",
    "    # returns 32\n",
    "    \"test/largeFile.txt\" | splitSeek(31) | shape(0)\n",
    "    # returns 32, demonstrating you can also pipe file objects in, if that's what you want\n",
    "    open(\"test/largeFile.txt\") | splitSeek(31) | shape(0)\n",
    "    # returns [0, 0, 10, 10, 20, 30, 30, 40, 40, 50], notice some segments have zero length\n",
    "    \"test/largeFile.txt\" | splitSeek(200) | head()\n",
    "    # returns [0, 400, 1200], demonstrating that you can split a file up unevenly by weights\n",
    "    \"test/largeFile.txt\" | splitSeek(ws=[1, 2]) | deref()\n",
    "\n",
    "So, the generated file has 120 lines in total. Each line is 10 bytes (9 for\n",
    "the string, and 1 for the new line character). Splitting the file into 31\n",
    "fragments will result in 32 seek points (:math:`p_i\\quad i\\in[1, n+1]`). You\n",
    "can then use these seek points to read the file in multiple threads/processes\n",
    "using :meth:`cat`, like this::\n",
    "\n",
    "    # returns [['  0_56789', '  1_56789', '  2_56789'], ['  3_56789', '  4_56789', '  5_56789', '  6_56789']]\n",
    "    \"test/largeFile.txt\" | splitSeek(31) | window(2) | ~apply(lambda sB, eB: cat(\"test/largeFile.txt\", sB=sB, eB=eB-1)) | head(2) | deref()\n",
    "\n",
    "Because :math:`120/31\\\\approx4`, most of cat's reads contain 4 lines, but some\n",
    "has 3 lines. Also notice that the lines smoothly transitions between cat's\n",
    "reads (``2_56789`` to ``3_56789``), so that's pretty nice. Just like with :meth:`cat`,\n",
    "this also works with urls::\n",
    "\n",
    "    \"https://example.com\" | splitSeek(10)\n",
    "\n",
    ".. warning::\n",
    "\n",
    "    You have to really test whether reading the same file from multiple processes is\n",
    "    going to be really faster or not. If your data is stored in a HDD (aka hard drive,\n",
    "    with spinning disks), then it will actually slow you down (10x-100x), because the\n",
    "    disk will have to context switch all the time, and each switch has a 10ms cost.\n",
    "    \n",
    "    You also have to take into account collecting together the results of all processes,\n",
    "    which can bottleneck the cpu. Read more about concurrency pitfalls at :class:`~k1lib.cli.modifier.applyMp`.\n",
    "\n",
    "In some scenarios where you want to adjust the seek points even more, like when\n",
    "you want to parse FASTA genome files, which has blocks of 2/4 lines each like this:\n",
    "\n",
    ".. code-block:: text\n",
    "\n",
    "    @FP200005993L1C001R00100000061/2\n",
    "    TTTTAAACTTGCATTCTTTGGAGATTTGCTGAGTGTTGCTAGAGCTGGGAAACTTTTTTAATGAGATACGTGCATATTTTTCAAATTTACAGATCTTTTTTCACAAAAATAGAAAGTCATAAATGTGAAATGGAAACCTAAACAAGGCAA\n",
    "    +\n",
    "    GFEEEDEFGFFFFEFFFFFIFCEEEFFFGFFDFEGEDGFFFGDGFFGDGCE@GGGEEFDFGFGCFDFGGHCHFFFGFFFFFGEFDFFGHGFGEEHGFGEGFGFHFFEGFFFE;GEGEFGGHFFEI=GDAEDIFDDFGHFGEFGFEGGGGF\n",
    "    @FP200005993L1C001R00100000167/2\n",
    "    CTGGAATTTGGTATCTTATTGCCAAAGAATCTGTTTTGTGAAACTTGGGATCTCTATTTTAATGTTAATTCTGGTCAGTTGTGCCTAAACTCCATAAAGCAGGGACTATACTGAGGCGTATTCAATCTTCCTTCTTACCAAGGCCAGGAA\n",
    "    +\n",
    "    EEFECEDEFFCGFFFFFEEEGEGFEDECCEFEFDFEEFDFEDDFEFEEFDDFFEEFFEEFEFFHEEFEEFEFFDEFFFECF>FFFEFEDFCFFFEGFEDEEGDDFEEFEFGEEBD@EG>EEFFECEEGFEEEFFEDGEEEDE5EBDG:CC\n",
    "\n",
    "Here, each 4 lines are (title, read, blank, quality). Because by default, this will\n",
    "only split neatly along new lines, you will have to write extra functions to detect\n",
    "if a particular seek point is desirable, and if not, either jump forward or backward\n",
    "using :meth:`splitSeek.forward` and :meth:`splitSeek.backward`. To help with this,\n",
    ":class:`refineSeek` has some useful methods that you might want to check out.\n",
    "\n",
    ":param n: how many splits do you want?\n",
    ":param c: block-boundary character, usually just the new line character\n",
    ":param ws: weights. If given, the splits length ratios will roughly correspond to this\"\"\"\n",
    "        self.n = n; self.c = c; self.ws = ws; self.fn = None; self.res = None # file name, result\n",
    "        if ws is None and n is None: raise Exception(\"Specify at least n or ws for splitSeek to work\")\n",
    "    @staticmethod\n",
    "    def forward(f, i:int, c=b'\\n') -> int:\n",
    "        \"\"\"Returns char location after the search char, going forward.\n",
    "Example::\n",
    "\n",
    "    f = io.BytesIO(b\"123\\\\n456\\\\n789\\\\nabc\")\n",
    "    f | splitSeek(2) # returns [0, 4, 15]\n",
    "    splitSeek.forward(f, 2) # returns 4\n",
    "    splitSeek.forward(f, 3) # returns 4\n",
    "    splitSeek.forward(f, 4) # returns 8\n",
    "\n",
    ":param f: file handle\n",
    ":param i: current seek point\n",
    ":param c: block-boundary character\"\"\"\n",
    "        def inner(f):\n",
    "            f.seek(i)\n",
    "            while True:\n",
    "                b = f.tell(); s = f.read(1000); di = s.find(c)\n",
    "                if di > -1: return b + di + 1\n",
    "                if s == \"\": return -1\n",
    "        if isinstance(f, str):\n",
    "            with openFile(os.path.expanduser(f), False) as _f: return inner(_f)\n",
    "        else: return inner(f)\n",
    "    @staticmethod\n",
    "    def backward(f, i:int, c=b'\\n') -> int:\n",
    "        \"\"\"Returns char location after the search char, going backward.\n",
    "Example::\n",
    "\n",
    "    f = io.BytesIO(b\"123\\\\n456\\\\n789\\\\nabc\")\n",
    "    f | splitSeek(2) # returns [0, 4, 15]\n",
    "    splitSeek.backward(f, 5) # returns 4\n",
    "    splitSeek.backward(f, 4) # returns 4\n",
    "    splitSeek.backward(f, 3) # returns 0\n",
    "\n",
    ":param f: file handle\n",
    ":param i: current seek point\n",
    ":param c: block-boundary character\"\"\"\n",
    "        def inner(f):\n",
    "            mul = 1\n",
    "            while True:\n",
    "                begin = max(i-1000*mul, 0); end = max(i-1000*(mul-1), 0); mul += 1 # search range\n",
    "                f.seek(begin); b = f.tell(); s = f.read(end-begin); di = s.rfind(c)\n",
    "                if di > -1: return b + di + 1\n",
    "                if b == 0: return 0\n",
    "        if isinstance(f, str):\n",
    "            with openFile(os.path.expanduser(f), False) as _f: return inner(_f)\n",
    "        else: return inner(f)\n",
    "    def __ror__(self, fn): # why return self instead of the seek positions directly? Because we want to pass along dependencies like file name to downstream processes like refineSeek\n",
    "        if isinstance(fn, str): fn = os.path.expanduser(fn)\n",
    "        n = self.n; c = self.c; ws = self.ws; self.fn = fn\n",
    "        def func(f):\n",
    "            f.seek(0, os.SEEK_END); end = f.tell()\n",
    "            if ws is None: begins = range(n) | cli.apply(lambda x: int(x*end/n))\n",
    "            else: begins = range(end) | cli.splitW(*ws) | cli.apply(lambda x: x.start)\n",
    "            return [*begins | cli.apply(lambda x: splitSeek.backward(f, x, c)), end]\n",
    "        if isinstance(fn, str):\n",
    "            with openFile(os.path.expanduser(fn), False, True) as f: self.res = func(f); return self\n",
    "        else: self.res = func(fn); return self\n",
    "    def __or__(self, aft):\n",
    "        if self.res is None: return super().__or__(aft)\n",
    "        return aft.__ror__(self)\n",
    "    def __getitem__(self, idx): return self.res[idx]\n",
    "    def __len__(self): return len(self.res)\n",
    "    def __iter__(self): return iter(self.res)\n",
    "    def __repr__(self): return self.res.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8175580-0902-4356-b7a6-01d188bb8bd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "range(120) | cli.apply(lambda x: f\"{x:3}_56789\") | cli.file(\"test/largeFile.txt\")\n",
    "assert \"test/largeFile.txt\" | splitSeek(31) | cli.head() == [0, 30, 70, 110, 150, 190, 230, 270, 300, 340]\n",
    "assert \"test/largeFile.txt\" | splitSeek(31) | cli.shape(0) == 32\n",
    "assert \"test/largeFile.txt\" | splitSeek(200) | cli.head() == [0, 0, 10, 10, 20, 30, 30, 40, 40, 50]\n",
    "assert \"test/largeFile.txt\" | splitSeek(31) | cli.window(2) | ~cli.apply(lambda sB, eB: cat(\"test/largeFile.txt\", sB=sB, eB=eB-1)) | cli.head(2) | cli.deref() == [['  0_56789', '  1_56789', '  2_56789'], ['  3_56789', '  4_56789', '  5_56789', '  6_56789']]\n",
    "assert \"test/largeFile.txt\" | splitSeek(ws=[1, 2]) | cli.deref() == [0, 400, 1200]\n",
    "f = io.BytesIO(b\"123\\n456\\n789\\nabc\"); assert f | splitSeek(2) | cli.deref() == [0, 4, 15]\n",
    "assert splitSeek.forward(f,  2) == 4; assert splitSeek.forward(f,  3) == 4; assert splitSeek.forward(f,  4) == 8\n",
    "assert splitSeek.backward(f, 5) == 4; assert splitSeek.backward(f, 4) == 4; assert splitSeek.backward(f, 3) == 0\n",
    "assert splitSeek.forward(\"test/largeFile.txt\", 30) == 40\n",
    "assert splitSeek.backward(\"test/largeFile.txt\", 29) == 20\n",
    "url = \"https://vim.kelvinho.org/.vimrc\"\n",
    "b = url | splitSeek(10) | cli.window(2) | cli.deref() | ~cli.apply(lambda sB, eB: cat(url, sB=sB, eB=eB-1)) | cli.joinStreams() | cli.deref()\n",
    "a = cat(url) | cli.deref(); assert a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79a39e07-51d6-4a25-ba0d-4e4cbe2a9e88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class refineSeek(BaseCli):\n",
    "    def __init__(self, f=None, window=1):\n",
    "        \"\"\"Refines seek positions.\n",
    "Example::\n",
    "\n",
    "    # returns list of integers for seek positions\n",
    "    \"abc.txt\" | splitSeek(30)\n",
    "    # returns refined seek positions, such that the line starting at the seek positions starts with \"@\"\n",
    "    \"abc.txt\" | splitSeek(30) | refineSeek(lambda x: x.startswith(b\"@\"))\n",
    "    # same thing as above\n",
    "    \"abc.txt\" | splitSeek(30) | refineSeek(lambda x: x[0] == b\"@\"[0])\n",
    "    # returns refined seek positions, such that 0th line starts with \"@\" and 2nd line starts with \"+\". This demonstrates `window` parameter\n",
    "    \"abc.txt\" | splitSeek(30) | refineSeek(lambda x: x[0][0] == b\"@\"[0] and x[2][0] == b\"+\"[0], 3)\n",
    "    # same thing as above, demonstrating some builtin refine seek functions\n",
    "    \"abc.txt\" | splitSeek(30) | refineSeek.fastq()\n",
    "\n",
    ":param f: function that returns True if the current line/lines is a valid block boundary\n",
    ":param window: by default (1), will fetch 1 line and check boundary using ``f(line)``.\n",
    "    If a value greater than 1 is passed (for example, 3), will fetch 3 lines and check\n",
    "    boundary using ``f([line1, line2, line3])``\n",
    "\"\"\"\n",
    "        if f is None: f = lambda x: True\n",
    "        self.f = cli.fastF(f); self.window = window; self.fn = None\n",
    "    def __ror__(self, seeks):\n",
    "        f = self.f; window = self.window\n",
    "        def read(fio, sB:int):\n",
    "            fio.seek(sB)\n",
    "            if window == 1: return fio.readline()\n",
    "            return list(cli.repeatF(lambda: fio.readline(), window))\n",
    "        if len(seeks) <= 2: return seeks\n",
    "        fn = self.fn or seeks.fn; newSeeks = [seeks[0]]\n",
    "        def process(fio):\n",
    "            with openFile(fn, False) as fio:\n",
    "                for seek in seeks[1:-1]:\n",
    "                    line = read(fio, seek)\n",
    "                    while not f(line): seek = splitSeek.forward(fio, seek); line = read(fio, seek)\n",
    "                    newSeeks.append(seek)\n",
    "            newSeeks.append(seeks[-1]); return newSeeks\n",
    "        if isinstance(fn, str):\n",
    "            with openFile(fn, False) as fio: return process(fio)\n",
    "        else: return process(fn)\n",
    "    def injectFn(self, fn):\n",
    "        \"\"\"Injects file name dependency, if this is not used right after :class:`splitSeek`\"\"\"\n",
    "        self.fn = fn; return self\n",
    "    @classmethod\n",
    "    def fastq(cls):\n",
    "        \"\"\"Refine fastq file's seek points\"\"\"\n",
    "        return cls(lambda x: x[0][0] == b\"@\"[0] and x[2][0] == b\"+\"[0], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68da3fd3-9b85-4803-9697-5438f946f46a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def readline(fn:str, sB:int):\n",
    "    with open(os.path.expanduser(fn), \"rb\") as f: f.seek(sB); return f.readline()\n",
    "fn = \"~/hdd/genome/NG156Q3CQM_2.fq\"\n",
    "assert fn | splitSeek(31) | refineSeek.fastq() | cli.apply(lambda sB: readline(fn, sB)) | cli.head(-1) | cli.apply(lambda x: x.startswith(b\"@\")) | cli.aS(all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c22c763",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def wget(url:str, fileName:str=None, mkdir=True):\n",
    "    \"\"\"Downloads a file. Also returns the file name, in case you want to pipe it\n",
    "to something else.\n",
    "\n",
    ":param url: The url of the file\n",
    ":param fileName: if None, then tries to infer it from the url\n",
    ":param mkdir: whether to make the directory leading up to the file or not\"\"\"\n",
    "    if fileName is None: fileName = url.split(\"/\")[-1]\n",
    "    fileName = os.path.expanduser(fileName); dirname = os.path.dirname(fileName)\n",
    "    if mkdir: os.makedirs(dirname, exist_ok=True)\n",
    "    try: urllib.request.urlretrieve(url, fileName); return fileName\n",
    "    except: return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5ea17d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ls(folder:str=None):\n",
    "    \"\"\"List every file and folder inside the specified folder.\n",
    "Example::\n",
    "\n",
    "    # returns List[str]\n",
    "    ls(\"/home\")\n",
    "    # same as above\n",
    "    \"/home\" | ls()\n",
    "    # only outputs files, not folders\n",
    "    ls(\"/home\") | filt(os.path.isfile)\n",
    "\n",
    "This can handle things that are not plain folders. For example,\n",
    "it can handle zip file whereby it will list out all the files contained\n",
    "within a particular .zip::\n",
    "\n",
    "    ls(\"abc.zip\")\n",
    "\n",
    "Then, you can use :meth:`cat` as usual, like this::\n",
    "\n",
    "    ls(\"abc.zip\") | item() | cat()\n",
    "\n",
    "Pretty nice!\n",
    "\n",
    ".. admonition:: Custom datatype\n",
    "\n",
    "    It is possible to build objects that can interoperate with this cli,\n",
    "    like this::\n",
    "    \n",
    "        class sql:\n",
    "            def __init__(self): ...\n",
    "            def _ls(self): return [\"something\", \"here\"]\n",
    "\n",
    "    ls() will identify that what's inputted is not a string, and will try\n",
    "    to execute the object's \"_ls()\" method, so you can just simply implement\n",
    "    it in your classes\n",
    "\"\"\"\n",
    "    if folder is None: return _ls()\n",
    "    else: return folder | _ls()\n",
    "class _ls(BaseCli):\n",
    "    def _typehint(self, ignored=None): return tList(str)\n",
    "    def __ror__(self, path:str):\n",
    "        if isinstance(path, str):\n",
    "            path = os.path.expanduser(path.rstrip(os.sep))\n",
    "            if os.path.exists(path):\n",
    "                if os.path.isfile(path):\n",
    "                    if cat(path, False, eB=2) == b\"PK\": # list subfiles in a zip file\n",
    "                        return [ZipWrapper(e, path) for e in zipfile.ZipFile(path).infolist()]\n",
    "                    else: raise Exception(f\"{path} is a file, not a folder, so can't list child directories\")\n",
    "                else: return [f\"{path}{os.sep}{e}\" for e in os.listdir(path)]\n",
    "            else: return []\n",
    "        else: return path._ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb49c206",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(ls(\"/home\")) == len(\"/home\" | ls())\n",
    "assert len(ls(\"/home\")) > 0\n",
    "assert len(\"/home/kelvin\" | ls() | cli.filt(os.path.isfile) | cli.deref()) > 0\n",
    "assert len(\"~\" | ls() | cli.filt(os.path.isfile) | cli.deref()) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bddde15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "k1lib.settings.cli.add(\"quiet\", False, \"whether to mute extra outputs from clis or not\")\n",
    "newline = b'\\n'[0]\n",
    "class lazySt:\n",
    "    def __init__(self, st, text:bool):\n",
    "        \"\"\"Converts byte stream into lazy text/byte stream, with nice __repr__.\"\"\"\n",
    "        self.st = st; self.text = text;\n",
    "    def __iter__(self):\n",
    "        if self.text:\n",
    "            while True:\n",
    "                line = self.st.readline()\n",
    "                if len(line) == 0: break\n",
    "                yield line.decode().rstrip(\"\\n\")\n",
    "        else:\n",
    "            while True:\n",
    "                line = self.st.readline()\n",
    "                if len(line) == 0: break\n",
    "                yield line\n",
    "    def __repr__(self): self | cli.stdout(); return \"\"\n",
    "def executeCmd(cmd:str, inp:bytes, text):\n",
    "    \"\"\"Runs a command, and returns stdout and stderr streams\"\"\"\n",
    "    p = subprocess.Popen(cmd, shell=True, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, cwd=k1lib.settings.wd)\n",
    "    if inp is not None:\n",
    "        if isinstance(inp, (str, bytes)): p.stdin.write(inp if isinstance(inp, bytes) else inp.encode())\n",
    "        else:\n",
    "            for e in inp:\n",
    "                if not isinstance(e, (str, bytes)): e = str(e)\n",
    "                if not isinstance(e, bytes): e = e.encode()\n",
    "                p.stdin.write(e); p.stdin.write(b\"\\n\")\n",
    "    p.stdin.close(); return p, lazySt(p.stdout, text), lazySt(p.stderr, text)\n",
    "def printStderr(err):\n",
    "    if not k1lib.settings.cli.quiet:\n",
    "        e, it = err | cli.peek()\n",
    "        if it != []: it | cli.insert(\"\\nError encountered:\\n\") | cli.apply(k1lib.fmt.txt.red) | cli.stdout()\n",
    "def requireCli(cliTool:str):\n",
    "    \"\"\"Searches for a particular cli tool (eg. \"ls\"), throws ImportError if not\n",
    "found, else do nothing\"\"\"\n",
    "    a = cmd(cliTool); None | a;\n",
    "    if len(a.err) > 0: raise ImportError(f\"\"\"Can't find cli tool {cliTool}. Please install it first.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "673b76a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class cmd(BaseCli):\n",
    "    def __init__(self, cmd:str, mode:int=1, text=True, block=False): # 0: return (stdout, stderr). 1: return stdout, 2: return stderr\n",
    "        \"\"\"Runs a command, and returns the output line by line. Can pipe in some\n",
    "inputs. If no inputs then have to pipe in :data:`None`. Example::\n",
    "\n",
    "    # return detailed list of files\n",
    "    None | cmd(\"ls -la\")\n",
    "    # return list of files that ends with \"ipynb\"\n",
    "    None | cmd(\"ls -la\") | cmd('grep ipynb$')\n",
    "\n",
    "It might be tiresome to pipe in :data:`None` all the time. So, you can use \">\"\n",
    "operator to yield values right away::\n",
    "\n",
    "    # prints out first 10 lines of list of files\n",
    "    cmd(\"ls -la\") > headOut()\n",
    "\n",
    "If you're using Jupyter notebook/lab, then if you were to display a :class:`cmd`\n",
    "object, it will print out the outputs. So, a single command ``cmd(\"mkdir\")``\n",
    "displayed at the end of a cell is enough to trigger creating the directory.\n",
    "\n",
    "Reminder that \">\" operator in here sort of has a different meaning to that of\n",
    ":class:`~k1lib.cli.init.BaseCli`. So you kinda have to becareful about this::\n",
    "\n",
    "    # returns a serial cli, cmd not executed\n",
    "    cmd(\"ls -la\") | deref()\n",
    "    # executes cmd with no input stream and pipes output to deref\n",
    "    cmd(\"ls -la\") > deref()\n",
    "    # returns a serial cli\n",
    "    cmd(\"ls -la\") > grep(\"txt\") > headOut()\n",
    "    # executes pipeline\n",
    "    cmd(\"ls -la\") > grep(\"txt\") | headOut()\n",
    "\n",
    "General advice is, right ater a :class:`cmd`, use \">\", and use \"|\" everywhere else.\n",
    "\n",
    "Let's see a few more exotic examples. File ``a.sh``:\n",
    "\n",
    ".. code-block:: bash\n",
    "\n",
    "    #!/bin/bash\n",
    "\n",
    "    echo 1; sleep 0.5\n",
    "    echo This message goes to stderr >&2\n",
    "    echo 2; sleep 0.5\n",
    "    echo $(</dev/stdin)\n",
    "    sleep 0.5; echo 3\n",
    "\n",
    "Examples::\n",
    "\n",
    "    # returns [b'1\\\\n', b'2\\\\n', b'45\\\\n', b'3\\\\n'] and prints out the error message\n",
    "    \"45\" | cmd(\"./a.sh\", text=False) | deref()\n",
    "    # returns [b'This message goes to stderr\\\\n']\n",
    "    \"45\" | cmd(\"./a.sh\", mode=2, text=False) | deref()\n",
    "    # returns [[b'1\\\\n', b'2\\\\n', b'45\\\\n', b'3\\\\n'], [b'This message goes to stderr\\\\n']]\n",
    "    \"45\" | cmd(\"./a.sh\", mode=0, text=False) | deref()\n",
    "\n",
    "Performance-wise, stdout and stderr will yield values right away as soon\n",
    "as the process outputs it, so you get real time feedback. However, this will\n",
    "convert the entire input into a :class:`bytes` object, and not feed it bit by\n",
    "bit lazily, so if you have a humongous input, it might slow you down a little.\n",
    "\n",
    "Also, because stdout and stderr yield values right away, it means that if you\n",
    "want the operation to be blocking until finished, you have to consume the output::\n",
    "\n",
    "    None | cmd(\"mkdir abc\")\n",
    "    # might fail, because this might get executed before the previous line\n",
    "    None | cmd(\"echo a>abc/rg.txt\")\n",
    "    \n",
    "    None | cmd(\"mkdir abc\") | ignore()\n",
    "    # will succeed, because this will be guaranteed to execute after the previous line\n",
    "    None | cmd(\"echo a>abc/rg.txt\")\n",
    "\n",
    "Settings:\n",
    "- cli.quiet: if True, won't display errors in mode 1\n",
    "\n",
    ":param mode: if 0, returns ``(stdout, stderr)``. If 1, returns ``stdout`` and prints\n",
    "    ``stderr`` if there are any errors. If 2, returns ``stderr``\n",
    ":param text: whether to decode the outputs into :class:`str` or return raw :class:`bytes`\n",
    ":param block: whether to wait for the task to finish before returning to Python or not\"\"\"\n",
    "        super().__init__(); self.cmd = cmd; self.mode = mode\n",
    "        self.text = text; self.block = block; self.ro = k1lib.RunOnce()\n",
    "    def _typehint(self, ignored=None):\n",
    "        t = tIter(str) if self.text else tIter(bytes)\n",
    "        if self.mode == 0: return tCollection(t, t)\n",
    "        return t\n",
    "    def __ror__(self, it:Union[None, str, bytes, Iterator[Any]]) -> Iterator[Union[str, bytes]]:\n",
    "        \"\"\"Pipes in lines of input, or if there's nothing to\n",
    "pass, then pass None\"\"\"\n",
    "        if not self.ro.done(): self.p, self.out, self.err = executeCmd(self.cmd, it, self.text); mode = self.mode\n",
    "        if self.block:\n",
    "            self.out = self.out | cli.deref()\n",
    "            self.err = self.err | cli.deref()\n",
    "        if mode == 0: return (self.out, self.err)\n",
    "        elif mode == 1:\n",
    "            threading.Thread(target=lambda: printStderr(self.err)).start()\n",
    "            return self.out\n",
    "        elif mode == 2: return self.err\n",
    "    def __gt__(self, it): return None | self | it\n",
    "    def __repr__(self):\n",
    "        return (None | self).__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "426599ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert None | tCheck() | cmd(\"ls -la\") | cli.shape(0) | (cli.op() > 0)\n",
    "assert None | tCheck() | cmd(\"ls -la\", block=True) | cli.shape(0) | (cli.op() > 0)\n",
    "assert None | tCheck() | cmd(\"ls -la\") | cmd('grep ipynb$') | cli.shape(0) | (cli.op() > 0)\n",
    "with k1lib.captureStdout() as out: cmd(\"ls -la\") > cli.headOut()\n",
    "assert len(out()) > 3\n",
    "assert type(cmd(\"ls -la\") | cli.deref()).__name__ == \"serial\"\n",
    "assert len(cmd(\"ls -la\") > cli.deref()) > 0\n",
    "assert None | cmd(\"ls -la\") | cmd(\"grep ipynb\") | cli.deref() | cli.shape(0) > 0\n",
    "with k1lib.captureStdout() as out: assert \"45\" | tCheck() | cmd(\"test/a.sh\", text=False) | cli.deref() == [b'1\\n', b'2\\n', b'45\\n', b'3\\n']\n",
    "assert len(out()) > 2\n",
    "assert \"45\" | tCheck() | cmd(\"test/a.sh\", mode=2, text=False) | cli.deref() == [b'This message goes to stderr\\n']\n",
    "assert \"45\" | tCheck() | cmd(\"test/a.sh\", mode=0, text=False) | cli.deref() == ([b'1\\n', b'2\\n', b'45\\n', b'3\\n'], [b'This message goes to stderr\\n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2005330-1580-41fd-8c8e-835e1762403f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class walk(BaseCli):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"Recursively get all files inside a dictionary.\n",
    "Example::\n",
    "\n",
    "    # prints out first 10 files\n",
    "    \".\" | walk() | headOut()\"\"\"\n",
    "        self.kwargs = kwargs\n",
    "    def __ror__(self, path):\n",
    "        return os.walk(path, **self.kwargs) | ~cli.apply(lambda x, y, z: z | cli.apply(lambda e: x + os.sep + e)) | cli.joinStreams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3bbdce3-5294-40a9-a174-9eb03a42827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \".\" | walk() | cli.shape(0) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94fc49ce-833b-44bc-8aa8-e7c22fb0ab29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def urlPath(base:str, host:bool=True):\n",
    "    \"\"\"Translates from a url to a file path.\n",
    "Example::\n",
    "\n",
    "    base = \"~/ssd/some/other/path\"\n",
    "    url = \"http://example.com/some/path/to/file.txt\"\n",
    "    url | urlPath(base) # returns \"~/ssd/some/other/path/example_com/some/path/to/file.txt\"\n",
    "    url | urlPath(base, False) # returns \"~/ssd/some/other/path/some/path/to/file.txt\"\n",
    "\n",
    ":param base: base directory you want the files to be in\"\"\"\n",
    "    base = base.rstrip(\"/\\\\\")\n",
    "    def inner(url):\n",
    "        p = urllib.parse.urlparse(url)\n",
    "        a = (p.netloc.replace(\".\", \"_\") + os.sep) if host else \"\"\n",
    "        return f\"{base}{os.sep}{a}{p.path.strip('/')}\".replace(\"//\", \"/\")\n",
    "    return cli.aS(inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e931482-2e5f-4ef5-bdd0-263662b24579",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base = \"~/ssd/some/other/path\"; url = \"http://example.com/some/path/to/file.txt\"\n",
    "assert url | urlPath(base, False) == \"~/ssd/some/other/path/some/path/to/file.txt\"\n",
    "assert url | urlPath(base) == \"~/ssd/some/other/path/example_com/some/path/to/file.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e883e11a-0210-4afa-88e5-869530e12893",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import bz2, gzip, zlib\n",
    "class kzip(BaseCli):\n",
    "    def __init__(self, fmt=\"gz\"):\n",
    "        \"\"\"Incrementally compresses a stream of data using gzip or bzip2.\n",
    "Example::\n",
    "\n",
    "    data = range(100) | apply(lambda x: str(x).encode()) | deref() # list of bytes\n",
    "    data | kzip() | deref() # returns list of bytes\n",
    "    range(100) | apply(str) | kzip() | deref() # returns list of bytes, demonstrating piping iterator of string works\n",
    "\n",
    "Quick reminder that if you pass in bytes iterator then it will be compressed as-is.\n",
    "But if you pass in string iterator then it will append a new line character to each\n",
    "string and then compress it. This is more intuitive, and it makes the style consistent\n",
    "with :class:`~k1lib.cli.output.file`.\n",
    "\n",
    "Passing in single string or byte is ok too::\n",
    "\n",
    "    \"0123456789\" | kzip()  # returns gz bytes\n",
    "    b\"0123456789\" | kzip() # returns gz bytes, exact same pattern as above\n",
    "\n",
    "Why \"kzip\" and not just \"zip\"? Because \"zip\" is a builtin python keyword.\n",
    "\n",
    "See also: :class:`kunzip`\n",
    "\n",
    ":param fmt: desired compressed format. Currently only supports \"gz\" or \"bz2\"\n",
    "\"\"\"\n",
    "        fmt = fmt.strip(\".\")\n",
    "        if fmt == \"gzip\" or fmt == \"gz\":\n",
    "            self.o = zlib.compressobj(wbits=31)\n",
    "        elif fmt == \"bzip2\" or fmt == \"bz2\":\n",
    "            self.o = bz2.BZ2Compressor()\n",
    "        else: raise Exception(f\"File type {fmt} not supported. Specify either 'gz' or 'bz2'\")\n",
    "    def __ror__(self, it):\n",
    "        o = self.o\n",
    "        def gen():\n",
    "            for e in it:\n",
    "                if isinstance(e, str): e = f\"{e}\\n\".encode()\n",
    "                res = o.compress(e)\n",
    "                if res: yield res\n",
    "            try:\n",
    "                res = o.flush()\n",
    "                if res: yield res\n",
    "            except: pass\n",
    "        if isinstance(it, str): it = it.encode()\n",
    "        if isinstance(it, bytes): return [o.compress(it), o.flush()] | cli.filt(\"x\") | cli.aS(b\"\".join)\n",
    "        else: return gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c2920ac-d44f-43fc-bb38-71333973046a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class decompressobj: # .gz or .bz2 file\n",
    "    \"\"\"\n",
    "Why not just use zlib.decompressobj() directly? I encountered a strange bug when trying\n",
    "to decompress CommonCrawl's gzip files, posted on Stack Overflow and got help from none\n",
    "other than Mark Adler, creator of gzip and zlib. That guy's super active on Stack Overflow.\n",
    "Anyway, this code here is a modified version of his code. Here's the discussion:\n",
    "https://stackoverflow.com/questions/76452480/pythons-zlib-doesnt-work-on-commoncrawl-file\n",
    "\"\"\"\n",
    "    def __init__(self, gz=True): self.gz = gz\n",
    "    def __ror__(self, it):\n",
    "        gz = self.gz; data = left = b''; o = zlib.decompressobj(zlib.MAX_WBITS|32) if gz else bz2.BZ2Decompressor()\n",
    "        for got in it:\n",
    "            yield o.decompress(left + got); left = b''\n",
    "            if o.eof: left = o.unused_data; o = zlib.decompressobj(zlib.MAX_WBITS|32) if gz else bz2.BZ2Decompressor()\n",
    "            if len(got) == 0 and len(left) == 0: break\n",
    "stream_unzip = k1lib.dep(\"stream_unzip\")\n",
    "class decompressobjZip: # .zip files\n",
    "    def __ror__(self, it):\n",
    "        for a, b, c in stream_unzip.stream_unzip(it): yield from c; return\n",
    "class kunzip(BaseCli):\n",
    "    def __init__(self, text=False):\n",
    "        \"\"\"Incrementally decompress a stream of data using gzip or bzip2.\n",
    "Example::\n",
    "\n",
    "    # returns an iterator of bytes. cat() command can shorten to cat(\"someFile.gz\", False, True)\n",
    "    cat(\"someFile.gz\", text=False, chunks=True) | unzip()\n",
    "    # incrementally fetches remote file, then incrementally unzips it\n",
    "    cat(\"https://example.com/someFile.gz\", False, True) | unzip()\n",
    "\n",
    "    data = range(100) | apply(lambda x: str(x).encode()) | deref() # list of bytes\n",
    "    data | kzip() | unzip() | deref() # returns original data in list of bytes. May split the bytes at different positions though\n",
    "\n",
    "How does it know which algorithm to pick to decompress? It looks at the\n",
    "first few bytes of the file for its magic number. Also, if you're expecting\n",
    "a text file after decompression, you can do this to get the lines directly::\n",
    "\n",
    "    # returns iterator of strings\n",
    "    cat(\"https://example.com/someFile.gz\", False, True) | unzip(True)\n",
    "\n",
    "One more thing. If you're planning to use this to download whole files, you might\n",
    "want to tune the chunk size in :data:`~k1lib.settings`.cli.cat.chunkSize as\n",
    "it might speed things up considerably to raise it. Or may be you should just\n",
    "use wget instead =))\n",
    "\n",
    "More examples of the different styles to use this cli::\n",
    "\n",
    "    [\"abc\"] | kzip() | unzip(True) | deref() # returns [\"abc\"]\n",
    "     \"abc\"  | kzip() | unzip(True)           # returns  \"abc\"\n",
    "     \"abc\"  | kzip() | unzip()               # returns b\"abc\"\n",
    "\n",
    "See also: :class:`kzip`.\n",
    "\n",
    ".. admonition:: Reading files directly\n",
    "\n",
    "    The original purpose of this cli is to incrementally decompress a byte stream.\n",
    "    But a lot of time, that byte stream is coming from a file, and typing out\n",
    "    ``cat(fn, False, True)`` to generate a byte stream to feed into this cli is\n",
    "    tedious, so instead, you can pipe in the file name and this will just unzips\n",
    "    it and return the string/byte stream to you::\n",
    "    \n",
    "        \"abc.gz\"  | unzip() # returns string iterator\n",
    "        \"abc.bz2\" | unzip() # same\n",
    "        \"abc.zip\" | unzip() # returns string iterator from the first subfile only. All subsequent subfiles are ignored\n",
    "\n",
    ".. admonition:: .zip files\n",
    "\n",
    "    This can also work with subfiles within .zip files, like this::\n",
    "\n",
    "        \"abc.zip\" | unzip()                   # unzips the first subfile\n",
    "        \"abc.zip\" | ls()                      # lists out all subfiles\n",
    "        \"abc.zip\" | ls() | rItem(2) | unzip() # unzips the 3rd subfile\n",
    "\n",
    ":param text: whether to yield string lines or bytes\"\"\"\n",
    "        self.text = text\n",
    "    def __ror__(self, it):\n",
    "        def gen(it): # generates a stream of bytes\n",
    "            it = iter(it); e = next(it)\n",
    "            if e[:2] == b\"\\x1f\\x8b\": o = decompressobj(True) # .gz\n",
    "            elif e[:3] == b\"BZh\": o = decompressobj(False)    # .bz2\n",
    "            elif e[:2] == b\"PK\": o = decompressobjZip()      # .zip\n",
    "            else: raise Exception(\"Can't infer the file type (whether gz or bz2) of this file\")\n",
    "            yield from [[e], it] | cli.joinStreams() | o\n",
    "        single = False\n",
    "        if isinstance(it, str): return cat(it, False, True) | kunzip(self.text) # special case for reading file names directly\n",
    "        if isinstance(it, ZipWrapper): return it | cat(text=self.text, chunks=True) # special case for .zip subfile\n",
    "        if isinstance(it, bytes): single = True; it = [it]\n",
    "        if self.text:\n",
    "            def gen2(it): # generates a stream of strings\n",
    "                last = b\"\" # last split is probably not the right line boundary, so gotta do this\n",
    "                for e in gen(it):\n",
    "                    e = last + e; splits = e.split(b\"\\n\")\n",
    "                    for line in splits[:-1]: yield line.decode()\n",
    "                    last = splits[-1]\n",
    "                yield last.decode()\n",
    "            res = gen2(it)\n",
    "        else: res = gen(it)\n",
    "        if not single: return res\n",
    "        else: return \"\\n\".join(res) if self.text else b\"\".join(res)\n",
    "unzip = kunzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e28c8c7-4ae5-44b9-bf32-e2eb84fc10fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = range(100) | cli.apply(str) | cli.deref() # list of bytes\n",
    "assert data | kzip() | kunzip() | cli.deref() | cli.aS(b\"\".join) == (data | cli.apply(\"x+'\\\\n'\") | cli.join(\"\")).encode() # returns original data\n",
    "assert data | kzip(\"bz2\") | kunzip() | cli.deref() | cli.aS(b\"\".join) == (data | cli.apply(\"x+'\\\\n'\") | cli.join(\"\")).encode()\n",
    "assert data | kzip() | cli.aS(b\"\".join) == data | cli.apply(\"x+'\\\\n'\") | cli.aS(\"\".join) | kzip() | cli.deref()\n",
    "assert b\"0123456789\" | kzip() == \"0123456789\" | kzip()\n",
    "assert [\"abc\"] | kzip() | kunzip(True) | cli.deref() == [\"abc\", \"\"]\n",
    "assert \"abc\" | kzip() | kunzip(True) == \"abc\"\n",
    "assert \"abc\" | kzip() | kunzip() == b\"abc\"\n",
    "assert type(\"test/GSE13277_family.soft.gz\" | unzip(True) | cli.item()) == str\n",
    "assert type(\"test/GSE13277_family.soft.gz\" | unzip() | cli.item()) == bytes\n",
    "assert type(\"test/ch04.zip\" | unzip() | cli.item()) == bytes\n",
    "assert type(\"test/ch04.zip\" | ls() | cli.item() | cat(text=False, chunks=True) | cli.item()) == bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15b43d7c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-15 13:03:43,436\tINFO worker.py:1364 -- Connecting to existing Ray cluster at address: 192.168.1.133:6379...\n",
      "2023-07-15 13:03:43,440\tINFO worker.py:1544 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "7131    1   40%   \n",
      "10664   0   60%   \n",
      "rm: cannot remove '__pycache__': No such file or directory\n",
      "Found existing installation: k1lib 1.4.2\n",
      "Uninstalling k1lib-1.4.2:\n",
      "  Successfully uninstalled k1lib-1.4.2\n",
      "running install\n",
      "/home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "/home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages/setuptools/command/easy_install.py:144: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "creating k1lib.egg-info\n",
      "writing k1lib.egg-info/PKG-INFO\n",
      "writing dependency_links to k1lib.egg-info/dependency_links.txt\n",
      "writing requirements to k1lib.egg-info/requires.txt\n",
      "writing top-level names to k1lib.egg-info/top_level.txt\n",
      "writing manifest file 'k1lib.egg-info/SOURCES.txt'\n",
      "reading manifest file 'k1lib.egg-info/SOURCES.txt'\n",
      "adding license file 'LICENSE'\n",
      "writing manifest file 'k1lib.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "creating build/lib/k1lib\n",
      "copying k1lib/_learner.py -> build/lib/k1lib\n",
      "copying k1lib/fmt.py -> build/lib/k1lib\n",
      "copying k1lib/_k1a.py -> build/lib/k1lib\n",
      "copying k1lib/_context.py -> build/lib/k1lib\n",
      "copying k1lib/selector.py -> build/lib/k1lib\n",
      "copying k1lib/imports.py -> build/lib/k1lib\n",
      "copying k1lib/_baseClasses.py -> build/lib/k1lib\n",
      "copying k1lib/_basics.py -> build/lib/k1lib\n",
      "copying k1lib/viz.py -> build/lib/k1lib\n",
      "copying k1lib/_higher.py -> build/lib/k1lib\n",
      "copying k1lib/__init__.py -> build/lib/k1lib\n",
      "copying k1lib/_monkey.py -> build/lib/k1lib\n",
      "copying k1lib/knn.py -> build/lib/k1lib\n",
      "copying k1lib/p5.py -> build/lib/k1lib\n",
      "copying k1lib/graphEqn.py -> build/lib/k1lib\n",
      "copying k1lib/schedule.py -> build/lib/k1lib\n",
      "copying k1lib/_perlin.py -> build/lib/k1lib\n",
      "copying k1lib/eqn.py -> build/lib/k1lib\n",
      "creating build/lib/k1lib/_hidden\n",
      "copying k1lib/_hidden/hiddenFile.py -> build/lib/k1lib/_hidden\n",
      "copying k1lib/_hidden/__init__.py -> build/lib/k1lib/_hidden\n",
      "creating build/lib/k1lib/cli\n",
      "copying k1lib/cli/bio.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/cif.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/structural.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/modifier.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/gb.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/output.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/kxml.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/ktree.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/nb.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/inp.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/mol.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/mgi.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/_applyCl.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/grep.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/models.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/sam.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/trace.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/__init__.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/typehint.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/filt.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/utils.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/init.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/conv.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/optimizations.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/lsext.py -> build/lib/k1lib/cli\n",
      "creating build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/loss_accuracy.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/progress.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/limits.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/hookParam.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/profiler.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/callbacks.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/paramFinder.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/core.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/__init__.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/landscape.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/confusionMatrix.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/recorder.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/shorts.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/hookModule.py -> build/lib/k1lib/callbacks\n",
      "creating build/lib/k1lib/callbacks/profilers\n",
      "copying k1lib/callbacks/profilers/time.py -> build/lib/k1lib/callbacks/profilers\n",
      "copying k1lib/callbacks/profilers/memory.py -> build/lib/k1lib/callbacks/profilers\n",
      "copying k1lib/callbacks/profilers/__init__.py -> build/lib/k1lib/callbacks/profilers\n",
      "copying k1lib/callbacks/profilers/io.py -> build/lib/k1lib/callbacks/profilers\n",
      "copying k1lib/callbacks/profilers/computation.py -> build/lib/k1lib/callbacks/profilers\n",
      "creating build/lib/k1lib/callbacks/lossFunctions\n",
      "copying k1lib/callbacks/lossFunctions/accuracy.py -> build/lib/k1lib/callbacks/lossFunctions\n",
      "copying k1lib/callbacks/lossFunctions/__init__.py -> build/lib/k1lib/callbacks/lossFunctions\n",
      "copying k1lib/callbacks/lossFunctions/shorts.py -> build/lib/k1lib/callbacks/lossFunctions\n",
      "creating build/lib/k1lib/_mo\n",
      "copying k1lib/_mo/atom.py -> build/lib/k1lib/_mo\n",
      "copying k1lib/_mo/parseM.py -> build/lib/k1lib/_mo\n",
      "copying k1lib/_mo/substance.py -> build/lib/k1lib/_mo\n",
      "copying k1lib/_mo/system.py -> build/lib/k1lib/_mo\n",
      "copying k1lib/_mo/__init__.py -> build/lib/k1lib/_mo\n",
      "creating build/lib/k1lib/serve\n",
      "copying k1lib/serve/suffix.py -> build/lib/k1lib/serve\n",
      "copying k1lib/serve/suffix-dash.py -> build/lib/k1lib/serve\n",
      "copying k1lib/serve/__init__.py -> build/lib/k1lib/serve\n",
      "copying k1lib/serve/main.py -> build/lib/k1lib/serve\n",
      "creating build/lib/k1lib/k1ui\n",
      "copying k1lib/k1ui/__init__.py -> build/lib/k1lib/k1ui\n",
      "copying k1lib/k1ui/main.py -> build/lib/k1lib/k1ui\n",
      "creating build/bdist.linux-x86_64\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/_learner.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "creating build/bdist.linux-x86_64/egg/k1lib/serve\n",
      "copying build/lib/k1lib/serve/suffix.py -> build/bdist.linux-x86_64/egg/k1lib/serve\n",
      "copying build/lib/k1lib/serve/suffix-dash.py -> build/bdist.linux-x86_64/egg/k1lib/serve\n",
      "copying build/lib/k1lib/serve/__init__.py -> build/bdist.linux-x86_64/egg/k1lib/serve\n",
      "copying build/lib/k1lib/serve/main.py -> build/bdist.linux-x86_64/egg/k1lib/serve\n",
      "copying build/lib/k1lib/fmt.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/_k1a.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/_context.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/selector.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/imports.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "creating build/bdist.linux-x86_64/egg/k1lib/k1ui\n",
      "copying build/lib/k1lib/k1ui/__init__.py -> build/bdist.linux-x86_64/egg/k1lib/k1ui\n",
      "copying build/lib/k1lib/k1ui/main.py -> build/bdist.linux-x86_64/egg/k1lib/k1ui\n",
      "copying build/lib/k1lib/_baseClasses.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/_basics.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "creating build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/bio.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/cif.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/structural.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/modifier.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/gb.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/output.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/kxml.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/ktree.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/nb.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/inp.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/mol.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/mgi.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/_applyCl.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/grep.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/models.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/sam.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/trace.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/__init__.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/typehint.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/filt.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/utils.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/init.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/conv.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/optimizations.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/lsext.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/viz.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/_higher.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/__init__.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/_monkey.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "creating build/bdist.linux-x86_64/egg/k1lib/_mo\n",
      "copying build/lib/k1lib/_mo/atom.py -> build/bdist.linux-x86_64/egg/k1lib/_mo\n",
      "copying build/lib/k1lib/_mo/parseM.py -> build/bdist.linux-x86_64/egg/k1lib/_mo\n",
      "copying build/lib/k1lib/_mo/substance.py -> build/bdist.linux-x86_64/egg/k1lib/_mo\n",
      "copying build/lib/k1lib/_mo/system.py -> build/bdist.linux-x86_64/egg/k1lib/_mo\n",
      "copying build/lib/k1lib/_mo/__init__.py -> build/bdist.linux-x86_64/egg/k1lib/_mo\n",
      "copying build/lib/k1lib/knn.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/p5.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/graphEqn.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/schedule.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "creating build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/loss_accuracy.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/progress.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/limits.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/hookParam.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/profiler.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/callbacks.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/paramFinder.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/core.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "creating build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers\n",
      "copying build/lib/k1lib/callbacks/profilers/time.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers\n",
      "copying build/lib/k1lib/callbacks/profilers/memory.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers\n",
      "copying build/lib/k1lib/callbacks/profilers/__init__.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers\n",
      "copying build/lib/k1lib/callbacks/profilers/io.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers\n",
      "copying build/lib/k1lib/callbacks/profilers/computation.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers\n",
      "copying build/lib/k1lib/callbacks/__init__.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/landscape.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/confusionMatrix.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/recorder.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/shorts.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/hookModule.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "creating build/bdist.linux-x86_64/egg/k1lib/callbacks/lossFunctions\n",
      "copying build/lib/k1lib/callbacks/lossFunctions/accuracy.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks/lossFunctions\n",
      "copying build/lib/k1lib/callbacks/lossFunctions/__init__.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks/lossFunctions\n",
      "copying build/lib/k1lib/callbacks/lossFunctions/shorts.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks/lossFunctions\n",
      "copying build/lib/k1lib/_perlin.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "creating build/bdist.linux-x86_64/egg/k1lib/_hidden\n",
      "copying build/lib/k1lib/_hidden/hiddenFile.py -> build/bdist.linux-x86_64/egg/k1lib/_hidden\n",
      "copying build/lib/k1lib/_hidden/__init__.py -> build/bdist.linux-x86_64/egg/k1lib/_hidden\n",
      "copying build/lib/k1lib/eqn.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_learner.py to _learner.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/serve/suffix.py to suffix.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/serve/suffix-dash.py to suffix-dash.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/serve/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/serve/main.py to main.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/fmt.py to fmt.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_k1a.py to _k1a.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_context.py to _context.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/selector.py to selector.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/imports.py to imports.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/k1ui/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/k1ui/main.py to main.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_baseClasses.py to _baseClasses.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_basics.py to _basics.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/bio.py to bio.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/cif.py to cif.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/structural.py to structural.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/modifier.py to modifier.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/gb.py to gb.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/output.py to output.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/kxml.py to kxml.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/ktree.py to ktree.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/nb.py to nb.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/inp.py to inp.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/mol.py to mol.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/mgi.py to mgi.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/_applyCl.py to _applyCl.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/grep.py to grep.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/models.py to models.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/sam.py to sam.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/trace.py to trace.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/typehint.py to typehint.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/filt.py to filt.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/utils.py to utils.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/init.py to init.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/conv.py to conv.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/optimizations.py to optimizations.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/lsext.py to lsext.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/viz.py to viz.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_higher.py to _higher.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_monkey.py to _monkey.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_mo/atom.py to atom.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_mo/parseM.py to parseM.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_mo/substance.py to substance.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_mo/system.py to system.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_mo/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/knn.py to knn.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/p5.py to p5.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/graphEqn.py to graphEqn.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/schedule.py to schedule.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/loss_accuracy.py to loss_accuracy.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/progress.py to progress.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/limits.py to limits.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/hookParam.py to hookParam.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/profiler.py to profiler.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/callbacks.py to callbacks.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/paramFinder.py to paramFinder.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/core.py to core.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers/time.py to time.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers/memory.py to memory.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers/io.py to io.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers/computation.py to computation.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/landscape.py to landscape.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/confusionMatrix.py to confusionMatrix.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/recorder.py to recorder.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/shorts.py to shorts.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/hookModule.py to hookModule.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/lossFunctions/accuracy.py to accuracy.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/lossFunctions/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/lossFunctions/shorts.py to shorts.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_perlin.py to _perlin.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_hidden/hiddenFile.py to hiddenFile.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_hidden/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/eqn.py to eqn.cpython-39.pyc\n",
      "installing package data to build/bdist.linux-x86_64/egg\n",
      "running install_data\n",
      "copying k1lib/serve/main.html -> build/bdist.linux-x86_64/egg/k1lib/serve\n",
      "copying k1lib/k1ui/mouseKey.pth -> build/bdist.linux-x86_64/egg/k1lib/k1ui\n",
      "copying k1lib/k1ui/256.model.state_dict.pth -> build/bdist.linux-x86_64/egg/k1lib/k1ui\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying k1lib.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying k1lib.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying k1lib.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying k1lib.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying k1lib.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "k1lib.cli.__pycache__.init.cpython-39: module MAY be using inspect.trace\n",
      "k1lib.cli.__pycache__.modifier.cpython-39: module references __file__\n",
      "k1lib.k1ui.__pycache__.main.cpython-39: module MAY be using inspect.getabsfile\n",
      "k1lib.k1ui.__pycache__.main.cpython-39: module MAY be using inspect.stack\n",
      "k1lib.serve.__pycache__.main.cpython-39: module MAY be using inspect.getsource\n",
      "k1lib.serve.__pycache__.main.cpython-39: module MAY be using inspect.getabsfile\n",
      "creating dist\n",
      "creating 'dist/k1lib-1.4.2-py3.9.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing k1lib-1.4.2-py3.9.egg\n",
      "creating /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages/k1lib-1.4.2-py3.9.egg\n",
      "Extracting k1lib-1.4.2-py3.9.egg to /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Adding k1lib 1.4.2 to easy-install.pth file\n",
      "\n",
      "Installed /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages/k1lib-1.4.2-py3.9.egg\n",
      "Processing dependencies for k1lib==1.4.2\n",
      "Searching for validators==0.20.0\n",
      "Best match: validators 0.20.0\n",
      "Adding validators 0.20.0 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for wurlitzer==3.0.3\n",
      "Best match: wurlitzer 3.0.3\n",
      "Adding wurlitzer 3.0.3 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for forbiddenfruit==0.1.4\n",
      "Best match: forbiddenfruit 0.1.4\n",
      "Adding forbiddenfruit 0.1.4 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for dill==0.3.6\n",
      "Best match: dill 0.3.6\n",
      "Adding dill 0.3.6 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for matplotlib==3.7.1\n",
      "Best match: matplotlib 3.7.1\n",
      "Adding matplotlib 3.7.1 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for numpy==1.25.0\n",
      "Best match: numpy 1.25.0\n",
      "Adding numpy 1.25.0 to easy-install.pth file\n",
      "Installing f2py script to /home/kelvin/anaconda3/envs/ray2/bin\n",
      "Installing f2py3 script to /home/kelvin/anaconda3/envs/ray2/bin\n",
      "Installing f2py3.9 script to /home/kelvin/anaconda3/envs/ray2/bin\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for decorator==5.1.1\n",
      "Best match: decorator 5.1.1\n",
      "Adding decorator 5.1.1 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for importlib-resources==5.12.0\n",
      "Best match: importlib-resources 5.12.0\n",
      "Adding importlib-resources 5.12.0 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for python-dateutil==2.8.2\n",
      "Best match: python-dateutil 2.8.2\n",
      "Adding python-dateutil 2.8.2 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for pyparsing==3.1.0\n",
      "Best match: pyparsing 3.1.0\n",
      "Adding pyparsing 3.1.0 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for Pillow==9.5.0\n",
      "Best match: Pillow 9.5.0\n",
      "Adding Pillow 9.5.0 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for packaging==23.1\n",
      "Best match: packaging 23.1\n",
      "Adding packaging 23.1 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for kiwisolver==1.4.4\n",
      "Best match: kiwisolver 1.4.4\n",
      "Adding kiwisolver 1.4.4 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for fonttools==4.40.0\n",
      "Best match: fonttools 4.40.0\n",
      "Adding fonttools 4.40.0 to easy-install.pth file\n",
      "Installing fonttools script to /home/kelvin/anaconda3/envs/ray2/bin\n",
      "Installing pyftmerge script to /home/kelvin/anaconda3/envs/ray2/bin\n",
      "Installing pyftsubset script to /home/kelvin/anaconda3/envs/ray2/bin\n",
      "Installing ttx script to /home/kelvin/anaconda3/envs/ray2/bin\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for cycler==0.11.0\n",
      "Best match: cycler 0.11.0\n",
      "Adding cycler 0.11.0 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for contourpy==1.1.0\n",
      "Best match: contourpy 1.1.0\n",
      "Adding contourpy 1.1.0 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for zipp==3.15.0\n",
      "Best match: zipp 3.15.0\n",
      "Adding zipp 3.15.0 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for six==1.16.0\n",
      "Best match: six 1.16.0\n",
      "Adding six 1.16.0 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Finished processing dependencies for k1lib==1.4.2\n",
      "Starting distributedInstall()...\n",
      "Finished distributedInstall()\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!../../export.py cli/inp --dist=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a0e719",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

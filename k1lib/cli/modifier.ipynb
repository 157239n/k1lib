{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8b5cdc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\"\"\"\n",
    "This is for quick modifiers, think of them as changing formats\n",
    "\"\"\"\n",
    "__all__ = [\"applyS\", \"aS\", \"apply\", \"map_\", \"applyMp\", \"parallel\", \"applyCl\",\n",
    "           \"applyTh\", \"applySerial\",\n",
    "           \"sort\", \"sortF\", \"consume\", \"randomize\", \"stagger\", \"op\",\n",
    "           \"integrate\"]\n",
    "from typing import Callable, Iterator, Any, Union, List\n",
    "from k1lib.cli.init import patchDefaultDelim, BaseCli, T, fastF\n",
    "import k1lib.cli as cli, numpy as np, threading, gc; import k1lib\n",
    "from collections import deque\n",
    "from functools import partial, update_wrapper, lru_cache\n",
    "from k1lib.cli.typehint import *\n",
    "import dill, pickle, k1lib, warnings, atexit, signal, time, os, random\n",
    "try: import torch; import torch.multiprocessing as mp; hasTorch = True\n",
    "except: import multiprocessing as mp; hasTorch = False\n",
    "ray = k1lib.dep(\"ray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e425bb19-fc89-446a-96de-a0464c760f19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "settings = k1lib.settings.cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7646c3f-63b8-49f4-8192-5c550dd07703",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cli.init.patchNumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1b8e0dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class applyS(BaseCli):\n",
    "    def __init__(self, f:Callable[[T], T], *args, **kwargs):\n",
    "        \"\"\"Like :class:`apply`, but much simpler, just operating on the entire input\n",
    "object, essentially. The \"S\" stands for \"single\". There's\n",
    "also an alias shorthand for this called :class:`aS`. Example::\n",
    "\n",
    "    # returns 5\n",
    "    3 | aS(lambda x: x+2)\n",
    "\n",
    "Like :class:`apply`, you can also use this as a decorator like this::\n",
    "\n",
    "    @aS\n",
    "    def f(x):\n",
    "        return x+2\n",
    "    # returns 5\n",
    "    3 | f\n",
    "\n",
    "This also decorates the returned object so that it has same qualname, docstring\n",
    "and whatnot.\n",
    "\n",
    "(Advanced) Writing out \"lambda x:\" all the time is annoying, and there are ways\n",
    "to quickly say ``lambda x: x+2`` like so::\n",
    "\n",
    "    3 | op()+2 # returns 5\n",
    "    3 | aS(\"x+2\") # returns 5. Behind the scenes, it compiles and execute `lambda x: x+2`\n",
    "\n",
    "The first way is to use :class:`op`, that will absorb all operations done on it,\n",
    "like \"+\", and returns a function that essentially replays all the operations.\n",
    "\n",
    "In the second way, you only have to pass in the string containing code that you want\n",
    "done on the variable \"x\". Then internally, it will compile to regular Python code.\n",
    "\n",
    "In fact, you can pass in ``op()`` or just a string to any cli that accepts any kind\n",
    "of function, like :class:`~k1lib.cli.filt.filt` or :class:`apply`::\n",
    "\n",
    "    range(4) | apply(\"x-2\") | deref()\n",
    "    range(4) | apply(op()-2) | deref()\n",
    "    range(4) | filt(\"x%2\") | deref()\n",
    "    range(4) | filt(op()%2) | deref()\n",
    "\n",
    ":param f: the function to be executed\n",
    ":param kwargs: other keyword arguments to pass to the function, together with ``args``\"\"\"\n",
    "        super().__init__(fs=[f]); self.args = args; self.kwargs = kwargs\n",
    "        self.f = f; self._fC = fastF(f); update_wrapper(self, f, updated=())\n",
    "    def _typehint(self, inp):\n",
    "        if self.hasHint: return self._hint\n",
    "        try: return self.f._typehint(inp)\n",
    "        except: return tAny()\n",
    "    def __ror__(self, it:T) -> T:\n",
    "        return self._fC(it, *self.args, **self.kwargs)\n",
    "    def __invert__(self):\n",
    "        \"\"\"Configures it so that it expand the arguments out.\n",
    "Example::\n",
    "\n",
    "    # returns 5\n",
    "    [2, 3] | ~aS(lambda x, y: x + y)\n",
    "\n",
    "    def f(x, y, a=4):\n",
    "        return x*y + a\n",
    "    # returns 10\n",
    "    [2, 3] | ~aS(f)\n",
    "    # returns 11\n",
    "    [2, 3] | ~aS(f, a=5)\"\"\"\n",
    "        f = self.f; a = self.args; kw = self.kwargs; return applyS(lambda x: f(*x, *a, **kw));\n",
    "aS = applyS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa6590fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert 3 | aS(lambda x: x+2) == 5\n",
    "@aS\n",
    "def f(x): return x+2\n",
    "assert 3 | f == 5\n",
    "assert [2, 3] | ~aS(lambda x, y: x + y) == 5\n",
    "def f(x, y, a=4): return x*y + a\n",
    "assert [2, 3] | ~aS(f) == 10\n",
    "assert [2, 3] | ~aS(f, a=5) == 11\n",
    "assert aS(cli.iden())._typehint(tList(int)) == tList(int)\n",
    "assert aS(lambda x: x.split(\"3\"))._typehint(tList(int)) == tAny()\n",
    "assert aS(lambda x: x.split(\"3\")).hint(str)._typehint(tList(int)) == str\n",
    "assert range(4) | cli.apply(\"x-2\") | cli.deref() == [-2, -1, 0, 1]\n",
    "assert range(4) | cli.apply(cli.op()-2) | cli.deref() == [-2, -1, 0, 1]\n",
    "assert range(4) | cli.filt(\"x%2\") | cli.deref() == [1, 3]\n",
    "assert range(4) | cli.filt(cli.op()%2) | cli.deref() == [1, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "473a6379",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class apply(BaseCli):\n",
    "    def __init__(self, f:Callable[[T], T], column:int=None, cache:int=0, **kwargs):\n",
    "        \"\"\"Applies a function f to every element in the incoming list/iterator.\n",
    "Example::\n",
    "\n",
    "    # returns [0, 1, 4, 9, 16]\n",
    "    range(5) | apply(lambda x: x**2) | deref()\n",
    "    # returns [[3.0, 1.0, 1.0], [3.0, 1.0, 1.0]]\n",
    "    torch.ones(2, 3) | apply(lambda x: x+2, 0) | deref()\n",
    "\n",
    "You can also use this as a decorator, like this::\n",
    "\n",
    "    @apply\n",
    "    def f(x):\n",
    "        return x**2\n",
    "    # returns [0, 1, 4, 9, 16]\n",
    "    range(5) | f | deref()\n",
    "\n",
    "You can also add a cache, like this::\n",
    "\n",
    "    def calc(i): time.sleep(0.5); return i**2\n",
    "    # takes 2.5s\n",
    "    range(5) | repeatFrom(2) | apply(calc, cache=10) | deref()\n",
    "    # takes 5s\n",
    "    range(5) | repeatFrom(2) | apply(calc) | deref()\n",
    "\n",
    "You can add custom keyword arguments into the function::\n",
    "\n",
    "    def f(x, y, z=3):\n",
    "        return x + y + z\n",
    "    # returns [15, 17, 19, 21, 23]\n",
    "    [range(5), range(10, 15)] | transpose() | ~apply(f, z=5) | deref()\n",
    "\n",
    "If \"apply\" is too hard to remember, this cli also has an alias :class:`map_`\n",
    "that kinda mimics Python's ``map()``.\n",
    "\n",
    ":param column: if not None, then applies the function to that column only\n",
    ":param cache: if specified, then caches this much number of values\n",
    ":param kwargs: extra keyword arguments to pass in the function\"\"\"\n",
    "        super().__init__(fs=[f]); self.f = f; self.kwargs = kwargs\n",
    "        if column and column < 0: raise Exception(f\"Applying a function on a negative-indexed column ({column}) is not supported\")\n",
    "        self.column = column; self.cache = cache; self._fC = fastF(f)\n",
    "        if cache > 0: self._fC = lru_cache(cache)(self._fC)\n",
    "        self.normal = self.column is None and self.cache == 0 # cached value to say that this apply is just being used as a wrapper, nothing out of the ordinary\n",
    "    def _typehint(self, inp):\n",
    "        if self.column is None:\n",
    "            if isinstance(inp, tListIterSet):\n",
    "                try: return tIter(self.f._typehint(inp.child))\n",
    "                except: return tIter(tAny())\n",
    "        return super()._typehint(inp)\n",
    "    def __ror__(self, it:Iterator[str]):\n",
    "        c = self.column; f = self._fC; kwargs = self.kwargs\n",
    "        if c is None: return (f(line, **kwargs) for line in it)\n",
    "        else: return ([(e if i != c else f(e, **kwargs)) \n",
    "                       for i, e in enumerate(row)] for row in it)\n",
    "    def __invert__(self):\n",
    "        \"\"\"Same mechanism as in :class:`applyS`, it expands the\n",
    "arguments out. Just for convenience really. Example::\n",
    "\n",
    "    # returns [10, 12, 14, 16, 18]\n",
    "    [range(5), range(10, 15)] | transpose() | ~apply(lambda x, y: x+y) | deref()\"\"\"\n",
    "        return apply(lambda x: self.f(*x, **self.kwargs), self.column, self.cache)\n",
    "map_ = apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6bf1c01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert range(5) | apply(lambda x: x**2) | cli.deref() == [0, 1, 4, 9, 16]\n",
    "assert torch.ones(2, 3) | apply(lambda x: x+2, 0) | cli.deref() == [[3.0, 1.0, 1.0], [3.0, 1.0, 1.0]]\n",
    "@apply\n",
    "def f(x): return x**2\n",
    "assert range(5) | f | cli.deref() == [0, 1, 4, 9, 16]\n",
    "def calc(i): time.sleep(0.1); return i**2\n",
    "with k1lib.timer() as t1:\n",
    "    range(5) | cli.repeatFrom(2) | apply(calc, cache=10) | cli.deref()\n",
    "with k1lib.timer() as t2:\n",
    "    range(5) | cli.repeatFrom(2) | apply(calc) | cli.deref()\n",
    "assert t1() < t2()*0.7\n",
    "assert [range(5), range(10, 15)] | cli.transpose() | ~apply(lambda x, y: x+y) | cli.deref() == [10, 12, 14, 16, 18]\n",
    "assert apply(aS(lambda x: x + 3).hint(int))._typehint(tIter(float)) == tIter(int)\n",
    "assert apply(aS(lambda x: x + 3))._typehint(tIter(float)) == tIter(tAny())\n",
    "def f(x, y, z=3): return x + y + z\n",
    "assert [range(5), range(10, 15)] | cli.transpose() | ~apply(f, z=5) | cli.deref() == [15, 17, 19, 21, 23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4500b057",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def executeFunc(common, line):\n",
    "    import dill, time\n",
    "    f, kwargs = dill.loads(common)\n",
    "    res = f(dill.loads(line), **kwargs)\n",
    "    time.sleep(0.1); return res # suggestion by https://stackoverflow.com/questions/36359528/broken-pipe-error-with-multiprocessing-queue\n",
    "def terminateGraceful(): signal.signal(signal.SIGINT, signal.SIG_IGN)\n",
    "class applyMp(BaseCli):\n",
    "    _pools = set()\n",
    "    _torchNumThreads = None\n",
    "    def __init__(self, f:Callable[[T], T], prefetch:int=None, timeout:float=8, utilization:float=0.8, bs:int=1, newPoolEvery:int=0, **kwargs):\n",
    "        \"\"\"Like :class:`apply`, but execute a function over the input iterator\n",
    "in multiple processes. Example::\n",
    "\n",
    "    # returns [3, 2]\n",
    "    [\"abc\", \"de\"] | applyMp(len) | deref()\n",
    "    # returns [5, 6, 9]\n",
    "    range(3) | applyMp(lambda x, bias: x**2+bias, bias=5) | deref()\n",
    "    \n",
    "    # returns [[1, 2, 3], [1, 2, 3]], demonstrating outside vars work\n",
    "    someList = [1, 2, 3]\n",
    "    [\"abc\", \"de\"] | applyMp(lambda s: someList) | deref()\n",
    "\n",
    "Internally, this will continuously spawn new jobs up until 80% of all CPU\n",
    "cores are utilized. On posix systems, the default multiprocessing start method is\n",
    "``fork()``. This sort of means that all the variables in memory will be copied\n",
    "over. On windows and macos, the default start method is ``spawn``, meaning each\n",
    "child process is a completely new interpreter, so you have to pass in all required\n",
    "variables and reimport every dependencies. Read more at https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods\n",
    "\n",
    "If you don't wish to schedule all jobs at once, you can specify a ``prefetch``\n",
    "amount, and it will only schedule that much jobs ahead of time. Example::\n",
    "\n",
    "    range(10000) | applyMp(lambda x: x**2)    | head() | deref() # 700ms\n",
    "    range(10000) | applyMp(lambda x: x**2, 5) | head() | deref() # 300ms\n",
    "\n",
    "    # demonstrating there're no huge penalties even if we want all results at the same time\n",
    "    range(10000) | applyMp(lambda x: x**2)    | deref() # 900ms\n",
    "    range(10000) | applyMp(lambda x: x**2, 5) | deref() # 1000ms\n",
    "\n",
    "The first line will schedule all jobs at once, and thus will require more RAM and\n",
    "compute power, even though we discard most of the results anyway (the\n",
    ":class:`~k1lib.cli.filt.head` cli). The second line only schedules 5 jobs ahead of\n",
    "time, and thus will be extremely more efficient if you don't need all results right\n",
    "away.\n",
    "\n",
    ".. note::\n",
    "\n",
    "    Remember that every :class:`~k1lib.cli.init.BaseCli` is also a\n",
    "    function, meaning that you can do stuff like::\n",
    "\n",
    "        # returns [['ab', 'ac']]\n",
    "        [[\"ab\", \"cd\", \"ac\"]] | applyMp(filt(op().startswith(\"a\")) | deref()) | deref()\n",
    "\n",
    "    Also remember that the return result of ``f`` should be serializable, meaning it\n",
    "    should not be a generator. That's why in the example above, there's a ``deref()``\n",
    "    inside f. You should also convert PyTorch tensors into Numpy arrays\n",
    "\n",
    "Most of the time, you would probably want to specify ``bs`` to something bigger than 1\n",
    "(may be 32 or sth like that). This will executes ``f`` multiple times in a single job,\n",
    "instead of executing ``f`` only once per job. Should reduce overhead of process\n",
    "creation dramatically.\n",
    "\n",
    "If you encounter strange errors not seen on :class:`apply`, you can try to clear all\n",
    "pools (using :meth:`clearPools`), to terminate all child processes and thus free\n",
    "resources. On earlier versions, you have to do this manually before exiting, but now\n",
    ":class:`applyMp` is much more robust.\n",
    "\n",
    "Also, you should not immediately assume that :class:`applyMp` will always be faster\n",
    "than :class:`apply`. Remember that :class:`applyMp` will create new processes,\n",
    "serialize and transfer data to them, execute it, then transfer data back. If your code\n",
    "transfers a lot of data back and forth (compared to the amount of computation done), or\n",
    "the child processes don't have a lot of stuff to do before returning, it may very well\n",
    "be a lot slower than :class:`apply`.\n",
    "\n",
    "There's a potential loophole here that can make your code faster. Because the main\n",
    "process is forked (at least on linux), every variable is still there, even the big\n",
    "ones. So, you can potentially do something like this::\n",
    "\n",
    "    bigData = [] # 1B items in the list\n",
    "    # summing up all items together. No input data transfers (because it's forked instead)\n",
    "    range(1_000_000_000) | batched(100) | applyMp(lambda r: r | apply(lambda i: bigData[i]) | toSum()) | toSum()\n",
    "\n",
    ":param prefetch: if not specified, schedules all jobs at the same time. If\n",
    "    specified, schedules jobs so that there'll only be a specified amount of\n",
    "    jobs, and will only schedule more if results are actually being used.\n",
    ":param timeout: seconds to wait for job before raising an error\n",
    ":param utilization: how many percent cores are we running? 0 for no cores, 1 for\n",
    "    all the cores. Defaulted to 0.8\n",
    ":param bs: if specified, groups ``bs`` number of transforms into 1 job to be more\n",
    "    efficient.\n",
    ":param kwargs: extra arguments to be passed to the function. ``args`` not\n",
    "    included as there're a couple of options you can pass for this cli.\n",
    ":param newPoolEvery: creates a new processing pool for every specific amount of input\n",
    "    fed. 0 for not refreshing any pools at all. Turn this on in case your process consumes\n",
    "    lots of memory and you have to kill them eventually to free up some memory\"\"\"\n",
    "        super().__init__(fs=[f]); self.f = fastF(f)\n",
    "        self.prefetch = prefetch or int(1e9)\n",
    "        self.timeout = timeout; self.utilization = utilization\n",
    "        self.bs = bs; self.kwargs = kwargs; self.p = None\n",
    "        self.newPoolEvery = newPoolEvery; self.ps = []\n",
    "    def __ror__(self, it:Iterator[T]) -> Iterator[T]:\n",
    "        timeout = self.timeout; it = iter(it) # really make sure it's an iterator, for prefetch\n",
    "        if self.bs > 1: return it | cli.batched(self.bs, True) | applyMp(apply(self.f) | cli.toList(), self.prefetch, timeout, **self.kwargs) | cli.joinStreams()\n",
    "        def newPool():\n",
    "            if hasTorch:\n",
    "                try: applyMp._torchNumThreads = applyMp._torchNumThreads or torch.get_num_threads(); torch.set_num_threads(1)\n",
    "                except: pass # why do all of this? Because some strange interaction between PyTorch and multiprocessing, outlined here: https://github.com/pytorch/pytorch/issues/82843\n",
    "            os.environ[\"py_k1lib_in_applyMp\"] = \"True\"\n",
    "            self.p = mp.Pool(int(mp.cpu_count()*self.utilization), terminateGraceful); self.ps.append(self.p)\n",
    "            if hasTorch and applyMp._torchNumThreads is not None: torch.set_num_threads(applyMp._torchNumThreads)\n",
    "        def intercept(it, n):\n",
    "            for i, e in enumerate(it):\n",
    "                if i % n == 0:\n",
    "                    if self.p is not None: self.p.close(); self.ps.remove(self.p)\n",
    "                    gc.collect(); newPool()\n",
    "                yield e\n",
    "        common = dill.dumps([self.f, self.kwargs])\n",
    "        def gen(it):\n",
    "            with k1lib.captureStdout(False, True) as out:\n",
    "                try:\n",
    "                    if self.newPoolEvery > 0: it = intercept(it, self.newPoolEvery)\n",
    "                    else: newPool()\n",
    "                    fs = deque()\n",
    "                    for i, line in zip(range(self.prefetch), it):\n",
    "                        fs.append(self.p.apply_async(executeFunc, [common, dill.dumps(line)]))\n",
    "                    for line in it:\n",
    "                        yield fs.popleft().get(timeout)\n",
    "                        fs.append(self.p.apply_async(executeFunc, [common, dill.dumps(line)]))\n",
    "                    for f in fs: yield f.get(timeout)\n",
    "                except KeyboardInterrupt as e:\n",
    "                    print(\"applyMp interrupted. Terminating pool now\")\n",
    "                    for p in self.ps: p.terminate();\n",
    "                    raise e\n",
    "                except Exception as e:\n",
    "                    print(\"applyMp encounter errors. Terminating pool now\")\n",
    "                    for p in self.ps: p.terminate();\n",
    "                    raise e\n",
    "                else:\n",
    "                    for p in self.ps: p.terminate();\n",
    "        return gen(it)\n",
    "    def _copy(self): return applyMp(self.f, self.prefetch, self.timeout, self.utilization, self.bs, self.newPoolEvery, **self.kwargs)\n",
    "    def __invert__(self):\n",
    "        \"\"\"Expands the arguments out, just like :class:`apply`.\n",
    "Example::\n",
    "\n",
    "    # returns [20, 20, 18, 14, 8, 0, -10, -22, -36, -52]\n",
    "    [range(10), range(20, 30)] | transpose() | ~applyMp(lambda x, y: y-x**2) | deref()\"\"\"\n",
    "        res = self._copy(); f = res.f; res.f = lambda x: f(*x); return res\n",
    "    @staticmethod\n",
    "    def clearPools():\n",
    "        \"\"\"Terminate all existing pools. Do this before restarting/quitting the\n",
    "script/notebook to make sure all resources (like GPU) are freed. **Update**:\n",
    "you probably won't have to call this manually anymore since version 0.9, but\n",
    "if you run into problems, try doing this.\"\"\"\n",
    "        for p in applyMp._pools:\n",
    "            try: p.terminate()\n",
    "            except: pass\n",
    "        applyMp._pools = set()\n",
    "    @staticmethod\n",
    "    def pools():\n",
    "        \"\"\"Get set of all pools. Meant for debugging purposes only.\"\"\"\n",
    "        return applyMp._pools\n",
    "    def __del__(self):\n",
    "        return\n",
    "        if hasattr(self, \"p\"):\n",
    "            self.p.terminate();\n",
    "            if self.p in applyMp._pools: applyMp._pools.remove(self.p)\n",
    "# apparently, this doesn't do anything, at least in jupyter environment\n",
    "atexit.register(lambda: applyMp.clearPools())\n",
    "parallel = applyMp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0af69270",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert [\"abc\", \"de\"] | applyMp(len) | cli.deref() == [3, 2]\n",
    "assert range(3) | applyMp(lambda x, bias: x**2+bias, bias=5) | cli.deref() == [5, 6, 9]\n",
    "someList = [1, 2, 3]\n",
    "assert [\"abc\", \"de\"] | applyMp(lambda s: someList) | cli.deref() == [[1, 2, 3], [1, 2, 3]]\n",
    "assert [[\"ab\", \"cd\", \"ac\"]] | applyMp(cli.filt(cli.op().startswith(\"a\")) | cli.deref()) | cli.deref() == [['ab', 'ac']]\n",
    "beginTime = time.time(); range(10000) | applyMp(lambda x: x**2) | cli.head() | cli.deref(); time1 = time.time() - beginTime\n",
    "beginTime = time.time(); range(10000) | applyMp(lambda x: x**2, 5) | cli.head() | cli.deref(); time2 = time.time() - beginTime\n",
    "assert time1 > time2\n",
    "# 1 and 3 are essentially identical, to make sure no dubious copy-on-write is happening\n",
    "with k1lib.timer() as t1:\n",
    "    res1 = range(10000) | applyMp(lambda x: x**2) | cli.deref() | cli.head() | cli.deref()\n",
    "with k1lib.timer() as t2:\n",
    "    res2 = range(10000) | applyMp(lambda x: x**2, prefetch=10, bs=32) | cli.deref() | cli.head() | cli.deref()\n",
    "with k1lib.timer() as t3:\n",
    "    res3 = range(10000) | applyMp(lambda x: x**2) | cli.deref() | cli.head() | cli.deref()\n",
    "assert t1() > t2(); assert t3() > t2(); assert res1 == res2 == res3\n",
    "assert range(100) | applyMp(lambda x: x**2, newPoolEvery=10) | cli.deref() == range(100) | apply(lambda x: x**2) | cli.deref()\n",
    "assert [range(10), range(20, 30)] | cli.transpose() | ~applyMp(lambda x, y: y-x**2) | cli.deref() == [20, 20, 18, 14, 8, 0, -10, -22, -36, -52]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91ee17aa-38fe-4b0e-9107-fba75d5b7e7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def specificNode(obj, nodeId:str):\n",
    "    return obj.options(scheduling_strategy=ray.util.scheduling_strategies.NodeAffinitySchedulingStrategy(node_id=nodeId, soft=False))\n",
    "class applyCl(BaseCli):\n",
    "    def __init__(self, f, prefetch=None, timeout=8, bs=1, rss:Union[dict, str]={}, pre:bool=False, orPatch=True, num_cpus=1, **kwargs):\n",
    "        \"\"\"Like :class:`apply`, but execute a function over the input iterator\n",
    "in multiple processes on multiple nodes inside of a cluster (hence \"cl\"). So, just a more\n",
    "powerful version of :class:`applyMp`, assuming you have a cluster to run it on.\n",
    "Example::\n",
    "\n",
    "    # returns [3, 2]\n",
    "    [\"abc\", \"de\"] | applyCl(len) | deref()\n",
    "    # returns [5, 6, 9]\n",
    "    range(3) | applyCl(lambda x, bias: x**2+bias, bias=5) | deref()\n",
    "    \n",
    "    # returns [[1, 2, 3], [1, 2, 3]], demonstrating outside vars work\n",
    "    someList = [1, 2, 3]\n",
    "    [\"abc\", \"de\"] | applyCl(lambda s: someList) | deref()\n",
    "\n",
    "Internally, this uses the library Ray (https://www.ray.io) to do the heavy\n",
    "lifting. So, :class:`applyCl` can be thought of as a thin wrapper around that\n",
    "library, but still has the same consistent interface as :class:`apply` and\n",
    ":class:`applyMp`. From all of my tests so far, it seems that :class:`applyCl`\n",
    "works quite well and is quite robust, so if you have access to a cluster, use\n",
    "it over :class:`applyMp`.\n",
    "\n",
    "The library will connect to a Ray cluster automatically when you import\n",
    "everything using ``from k1lib.imports import *``. It will execute\n",
    "``import ray; ray.init()``, which is quite simple. If you have ray installed,\n",
    "but does not want this default behavior, you can do this::\n",
    "\n",
    "    import k1lib\n",
    "    k1lib.settings.startup.init_ray = False\n",
    "    from k1lib.imports import *\n",
    "\n",
    "As with :class:`applyMp`, there are pitfalls and weird quirks to multiprocessing,\n",
    "on 1 or multiple nodes, so check out the docs over there to be aware of them,\n",
    "as those translates well to here.\n",
    "\n",
    ".. admonition:: Advanced use case\n",
    "\n",
    "    Not really advanced, but just a bit difficult to understand/follow. Let's say\n",
    "    that you want to scan through the home directory of all nodes, grab all files,\n",
    "    read them, and get the number of bytes they have. You can do something like this::\n",
    "    \n",
    "        a = None | applyCl.aS(lambda: None | cmd(\"ls ~\") | filt(os.path.isfile) | deref()) | deref()\n",
    "        b = a | ungroup(single=True, begin=True) | deref()\n",
    "        c = b | applyCl(cat(text=False) | shape(0), pre=True) | deref()\n",
    "        d = c | groupBy(0, True) | apply(item().all() | toSum(), 1) | deref()\n",
    "    \n",
    "    Noted, this is relatively complex. Let's see what A, B, C and D looks like::\n",
    "    \n",
    "        # A\n",
    "        [['7bb387b2920694abe9f7d2a2ed939b6d31843faf91d174d0221e871d', ['Miniconda3-latest-Linux-x86_64.sh', 'mintupgrade-2023-04-01T232950.log']],\n",
    "         ['1051dafd2b0dac13561c46fe052f561400592f0723df2cd746a41068', ['5a', 'abc.jpg', 'a.txt']]]\n",
    "        # B\n",
    "        [['7bb387b2920694abe9f7d2a2ed939b6d31843faf91d174d0221e871d', 'Miniconda3-latest-Linux-x86_64.sh'],\n",
    "         ['7bb387b2920694abe9f7d2a2ed939b6d31843faf91d174d0221e871d', 'mintupgrade-2023-04-01T232950.log'],\n",
    "         ['1051dafd2b0dac13561c46fe052f561400592f0723df2cd746a41068', '5a'],\n",
    "         ['1051dafd2b0dac13561c46fe052f561400592f0723df2cd746a41068', 'abc.jpg'],\n",
    "         ['1051dafd2b0dac13561c46fe052f561400592f0723df2cd746a41068', 'a.txt']]\n",
    "        # C\n",
    "        [['7bb387b2920694abe9f7d2a2ed939b6d31843faf91d174d0221e871d', 74403966],\n",
    "         ['7bb387b2920694abe9f7d2a2ed939b6d31843faf91d174d0221e871d', 1065252],\n",
    "         ['1051dafd2b0dac13561c46fe052f561400592f0723df2cd746a41068', 2601],\n",
    "         ['1051dafd2b0dac13561c46fe052f561400592f0723df2cd746a41068', 16341],\n",
    "         ['1051dafd2b0dac13561c46fe052f561400592f0723df2cd746a41068', 10177]]\n",
    "        # D\n",
    "        [['1051dafd2b0dac13561c46fe052f561400592f0723df2cd746a41068', 92185432],\n",
    "         ['7bb387b2920694abe9f7d2a2ed939b6d31843faf91d174d0221e871d', 75469218]]\n",
    "\n",
    "    The steps we're concerned with is A and C. In step A, we're running 2 processes, 1 for each\n",
    "    node, to get all the file names in the home directory. In step C, we're running 5 processes\n",
    "    total, 2 on the first node and 3 on the second node. For each process, it's going to read as\n",
    "    bytes and count up those bytes. Finally in step D, the results are grouped together and the\n",
    "    sizes summed.\n",
    "\n",
    "    So yeah, it's pretty nice that we did all of that in a relatively short amount of code.\n",
    "    The data is distributed too (reading multiple files from multiple nodes), so we're truly\n",
    "    not bottlenecked by anything.\n",
    "\n",
    ":param prefetch: if not specified, schedules all jobs at the same time. If\n",
    "    specified, schedules jobs so that there'll only be a specified amount of\n",
    "    jobs, and will only schedule more if results are actually being used.\n",
    ":param timeout: seconds to wait for job before raising an error\n",
    ":param bs: if specified, groups ``bs`` number of transforms into 1 job to be more\n",
    "    efficient.\n",
    ":param rss: resources required for the task. Can be {\"CPU\": 2} or \"CPU\" as a shortcut\n",
    ":param pre: \"preserve\", same convention as :meth:`applyCl.aS`. If True, then allow passing\n",
    "    through node ids as the first column to shedule jobs on those specific nodes only\n",
    ":param orPatch: whether to automatically patch __or__ function so that cli tools can\n",
    "    work with numpy arrays on that remote worker\n",
    ":param num_cpus: how many cpu does each task take?\n",
    ":param kwargs: extra arguments to be passed to the function. ``args`` not\n",
    "    included as there're a couple of options you can pass for this cli.\"\"\"\n",
    "        super().__init__(fs=[f]); _fC = fastF(f); self.pre = pre\n",
    "        if isinstance(rss, str): rss = {rss: 1}\n",
    "        def ogF(e):\n",
    "            if orPatch:\n",
    "                import k1lib; k1lib.cli.init.patchNumpy()\n",
    "                k1lib.cli.init.patchDict(); k1lib.cli.init.patchPandas()\n",
    "            return _fC(e, **kwargs)\n",
    "        self.ogF = ogF; self.f = ray.remote(resources=rss, num_cpus=num_cpus)(ogF)\n",
    "        self.prefetch = prefetch or int(1e9)\n",
    "        self.timeout = timeout; self.bs = bs\n",
    "        def preprocessF(f, e): # return future (if pre=False), or [nodeId, future] (if pre=True)\n",
    "            if pre: nodeId, e = e; return [nodeId, specificNode(f, nodeId).remote(e)]\n",
    "            else: return f.remote(e)\n",
    "        def resolveF(e):\n",
    "            if pre: return [e[0], ray.get(e[1], timeout=timeout)]\n",
    "            else: return ray.get(e, timeout=timeout)\n",
    "        self.preprocessF = preprocessF; self.resolveF = resolveF\n",
    "    def __ror__(self, it):\n",
    "        f = self.f; timeout = self.timeout; bs = self.bs; ogF = self.ogF; preprocessF = self.preprocessF; resolveF = self.resolveF\n",
    "        if bs > 1: return it | cli.batched(bs, True) | applyCl(lambda x: x | apply(ogF) | cli.aS(list), self.prefetch, timeout) | cli.joinStreams()\n",
    "        def gen(it):\n",
    "            futures = deque(); it = iter(it)\n",
    "            for i, e in zip(range(self.prefetch), it): futures.append(preprocessF(f, e))\n",
    "            for e in it: yield resolveF(futures.popleft()); futures.append(preprocessF(f, e))\n",
    "            for e in futures: yield resolveF(e)\n",
    "        return gen(it)\n",
    "    @staticmethod\n",
    "    def nodeIds(includeSelf=True) -> List[str]:\n",
    "        \"\"\"Returns a list of all node ids in the current cluster.\n",
    "Example::\n",
    "\n",
    "    applyCl.nodeIds() # returns something like ['7bb387b2920694abe9f7d2a2ed939b6d31843faf91d174d0221e871d', '1051dafd2b0dac13561c46fe052f561400592f0723df2cd746a41068']\n",
    "\n",
    "If you want to get nodes' metadata, then just use ray's builtin function ``ray.nodes()``\n",
    "\n",
    ":param includeSelf: whether to include node id of the current process or not\"\"\"\n",
    "        res = ray.nodes() | cli.filt(lambda x: x[\"Alive\"]) | apply(lambda x: x[\"NodeID\"]) | aS(list)\n",
    "        if includeSelf: return res\n",
    "        res.remove(applyCl.nodeId()); return res\n",
    "    @staticmethod\n",
    "    def nodeId() -> str:\n",
    "        \"\"\"Returns current node id\"\"\"\n",
    "        return ray.runtime_context.get_runtime_context().get_node_id()\n",
    "    @staticmethod\n",
    "    def meta() -> object:\n",
    "        \"\"\"Grabs the metadata object for the current node\"\"\"\n",
    "        return ray.nodes() | cli.filt(lambda x: x[\"NodeID\"] == applyCl.nodeId()) | cli.item()\n",
    "    @staticmethod\n",
    "    def cpu() -> int:\n",
    "        \"\"\"Grabs the number of cpus available on this node\"\"\"\n",
    "        return int(applyCl.meta()[\"Resources\"][\"CPU\"])\n",
    "    @staticmethod\n",
    "    def aS(f, timeout:float=8):\n",
    "        \"\"\"Executes function f once for all node ids that are piped in.\n",
    "Example::\n",
    "\n",
    "    # returns [['1051da...', ['Desktop', 'Downloads']], ['7bb387...', ['Pictures', 'Music']]]\n",
    "    applyCl.nodeIds() | applyCl.aS(lambda: None | cmd(\"ls ~\") | deref()) | deref()\n",
    "    # also returns [['1051da...', ['Desktop', 'Downloads']], ['7bb387...', ['Pictures', 'Music']]]\n",
    "    None | applyCl.aS(lambda: None | cmd(\"ls ~\") | deref()) | deref()\n",
    "\n",
    "If you want to execute f for all nodes, you can pass in None instead.\n",
    "\n",
    "As a reminder, this kinda follows the same logic as the popular cli :class:`aS`, where\n",
    "f is executed once, hence the name \"apply Single\". Here, the meaning of \"single\" is\n",
    "different. It just means execute once for each node ids.\n",
    "\n",
    ":param f: main function to execute in each node. Not supposed to accept any arguments\n",
    ":param timeout: seconds to wait for job before raising an error\"\"\"\n",
    "        f = fastF(f); g = lambda nodeId: specificNode(ray.remote(f), nodeId).remote()\n",
    "        final = cli.iden() & (apply(g) | aS(list) | apply(ray.get, timeout=timeout)) | cli.transpose()\n",
    "        return aS(lambda it: (applyCl.nodeIds() if it is None else it) | final)\n",
    "    @staticmethod\n",
    "    def replicateFile(fn:str, nodeIds=None):\n",
    "        \"\"\"Replicates a specific file in the current node to all the other nodes.\n",
    "Example::\n",
    "\n",
    "    applyCl.replicate(\"~/cron.log\")\n",
    "\n",
    "Internally, this will read chunks of 100kB of the specified file and dump it\n",
    "incrementally to all other nodes, which has implications on performance. To\n",
    "increase or decrease it, check out :class:`~k1lib.cli.inp.cat`. This also means\n",
    "you can replicate arbitrarily large files around as long as you have the disk\n",
    "space for it, while ram size doesn't really matter\n",
    "\n",
    ":param fn: file name\"\"\"\n",
    "        fn = os.path.expanduser(fn); dirname = os.path.dirname(fn)\n",
    "        if nodeIds is None: nodeIds = applyCl.nodeIds(False)\n",
    "        nodeIds = nodeIds | cli.wrapList().all() | cli.deref()\n",
    "        nodeIds | cli.insert(None, False).all() | applyCl(lambda _: None | cli.cmd(f\"mkdir -p {dirname}; rm {fn}\") | cli.deref(), pre=True) | cli.deref()\n",
    "        for chunk in cli.cat(fn, text=False, chunks=True):\n",
    "            nodeIds | cli.insert(chunk, False).all() | applyCl(lambda chunk: chunk >> cli.file(fn) | cli.deref(), pre=True) | cli.deref()\n",
    "    @staticmethod\n",
    "    def splitFile(fn:str, nodeIds=None):\n",
    "        \"\"\"Splits a specified file in the current node and dumps other parts\n",
    "to other nodes. Example::\n",
    "\n",
    "    applyCl.splitFile(\"~/cron.log\")\n",
    "\n",
    "This will split the big file up into multiple segments (1 for each node). Then\n",
    "for each segment, it will read through it chunk by chunk into memory, and then\n",
    "deposits it into the respective nodes. Finally, it truncates the original file\n",
    "down to its segment boundary.\n",
    "\n",
    "The exact split rule depends on the number of CPUs of each node. Say there're\n",
    "2 nodes: A and B. A has 16 cpus and B has 8 cpus. Then, a 48MB file will be split\n",
    "into 2 parts. A will have the first 32MB, and B will have the last 16MB. This is\n",
    "to optimize for distributed reading and processing using :meth:`applyCl.cat`.\n",
    "This makes sense right? If you don't have as many cores, you should process less\n",
    "data, so you should have less data to work with from the beginning.\n",
    "\n",
    "Again, this means that you can split arbitrarily large files as long as you have\n",
    "the disk space for it, ram size is not a concern. How does this perform? Not\n",
    "the best in the world if you don't have a lot of nodes. With sata 3 ssds, 750MB/s\n",
    "ethernet, I got transfer speeds of roughly 100MB/s. This should increase as you\n",
    "have more nodes based on the code structure, but I haven't tested it yet. Can\n",
    "it be faster? Definitely. Am I willing to spend time optimizing it? No.\"\"\"\n",
    "        fn = os.path.expanduser(fn); dirname = os.path.dirname(fn)\n",
    "        if nodeIds is None: nodeIds = applyCl.nodeIds(False)\n",
    "        nodeIds | cli.wrapList().all() | cli.insert(None, False).all() | applyCl(lambda _: None | cli.cmd(f\"mkdir -p {dirname}; rm {fn}\") | cli.deref(), pre=True) | cli.deref()\n",
    "        nodeId2Cpu = ray.nodes() | cli.filt(lambda x: x[\"Alive\"]) | cli.apply(lambda x: [x[\"NodeID\"], int(x[\"Resources\"][\"CPU\"])]) | cli.toDict()\n",
    "        n = len(nodeIds)+1; ranges = fn | cli.splitSeek(n, weights=[nodeId2Cpu[applyCl.nodeId()], *nodeIds | cli.lookup(nodeId2Cpu)]) | cli.splitSeek.window()\n",
    "        for chunks in ranges[1:] | ~cli.apply(lambda a,b: [cli.cat(fn, False, True, sB=a, eB=b), b'' | cli.repeat()] | cli.joinStreams()) | cli.transpose():\n",
    "            if chunks | cli.apply(len) | cli.toSum() == 0: break\n",
    "            [nodeIds, chunks] | cli.transpose() | applyCl(lambda chunk: chunk >> cli.file(fn) | cli.deref(), pre=True) | cli.deref()\n",
    "        with open(fn, 'a') as f: f.truncate(ranges[0][1])\n",
    "    @staticmethod\n",
    "    def cat(fn:str, f:Callable, timeout:float=30, keepNodeIds:bool=False, multiplier:int=1):\n",
    "        \"\"\"Reads a file distributedly, does some operation on them, collects and\n",
    "returns all of the data together. Example::\n",
    "\n",
    "    fn = \"~/repos/labs/k1lib/k1lib/cli/test/applyCl.cat.data\"\n",
    "    (\"0123456789\"*5 + \"\\n\") * 1000 | file(fn)\n",
    "    applyCl.splitFile(fn)\n",
    "    applyCl.cat(fn, shape(0), keepNodeIds=True) | deref()\n",
    "\n",
    "That returns something like this (for a 2-node cluster, with 2 (node A) and 4 (node B) cpus respectively)::\n",
    "\n",
    "    [['7bb387b2920694abe9f7d2a2ed939b6d31843faf91d174d0221e871d', 167],\n",
    "     ['7bb387b2920694abe9f7d2a2ed939b6d31843faf91d174d0221e871d', 167],\n",
    "     ['1051dafd2b0dac13561c46fe052f561400592f0723df2cd746a41068', 166],\n",
    "     ['1051dafd2b0dac13561c46fe052f561400592f0723df2cd746a41068', 167],\n",
    "     ['1051dafd2b0dac13561c46fe052f561400592f0723df2cd746a41068', 166],\n",
    "     ['1051dafd2b0dac13561c46fe052f561400592f0723df2cd746a41068', 167]]\n",
    "\n",
    "Here, we're creating an initial file with 1000 lines. Then we'll split it up into\n",
    "2 fragments: 334 lines and 667 lines and store them on the respective nodes. Then,\n",
    "on node A, we'll split the file up into 2 parts, each with 167 lines. On node B,\n",
    "we'll split the file up into 4 parts, each with around 166 lines. Then we'll\n",
    "schedule 6 processes total, each dealing with 166 lines. After all of that, results\n",
    "are collected together and returned.\n",
    "\n",
    ":param fn: file name\n",
    ":param f: function to execute in every process\n",
    ":param timeout: kills the processes if it takes longer than this amount of seconds\n",
    ":param keepNodeIds: whether to keep the node id column or not\n",
    ":param multiplier: by default, each node will spawn as many process as there\n",
    "    are cpus. Sometimes you want to spawn more process, change this to a higher number\n",
    "\"\"\"\n",
    "        checkpoints = None | applyCl.aS(lambda: fn | cli.splitSeek(int(applyCl.meta()[\"Resources\"][\"CPU\"]*multiplier)) | cli.splitSeek.window() | cli.deref()) | cli.ungroup(single=True, begin=True) | cli.deref()\n",
    "        postprocess = cli.iden() if keepNodeIds else cli.cut(1)\n",
    "        return checkpoints | applyCl(~aS(lambda x,y: cli.cat(fn, sB=x, eB=y) | f), pre=True, timeout=timeout, num_cpus=1) | postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f60cc37-d65c-4133-a025-e643c6f8d134",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-03 14:01:03,177\tINFO worker.py:1364 -- Connecting to existing Ray cluster at address: 192.168.1.35:6379...\n",
      "2023-05-03 14:01:03,181\tINFO worker.py:1544 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.9.15</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.3.1</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://127.0.0.1:8265\" target=\"_blank\">http://127.0.0.1:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='127.0.0.1:8265', python_version='3.9.15', ray_version='2.3.1', ray_commit='5f14cee8dfc6d61ec4fd3bc2c440f9944e92b33a', address_info={'node_ip_address': '192.168.1.35', 'raylet_ip_address': '192.168.1.35', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2023-05-02_10-06-32_529251_3206162/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2023-05-02_10-06-32_529251_3206162/sockets/raylet', 'webui_url': '127.0.0.1:8265', 'session_dir': '/tmp/ray/session_2023-05-02_10-06-32_529251_3206162', 'metrics_export_port': 45551, 'gcs_address': '192.168.1.35:6379', 'address': '192.168.1.35:6379', 'dashboard_agent_listen_port': 52365, 'node_id': '1051dafd2b0dac13561c46fe052f561400592f0723df2cd746a41068'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "340991fa-88ae-4d5e-afe8-6bd314f9de12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1051dafd2b0dac13561c46fe052f561400592f0723df2cd746a41068', 91815002],\n",
       " ['7bb387b2920694abe9f7d2a2ed939b6d31843faf91d174d0221e871d', 75841157]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "None | applyCl.aS(lambda: None | cli.cmd(\"ls ~\") | cli.filt(os.path.isfile) | cli.deref())\\\n",
    "| cli.ungroup(single=True, begin=True) | applyCl(cli.cat(text=False) | cli.shape(0), pre=True)\\\n",
    "| cli.groupBy(0, True) | apply(cli.item().all() | cli.toSum(), 1) | cli.deref()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4ff1cc5-f06f-436a-ad24-3ea8c5b9d155",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert [\"abc\", \"de\"] | applyCl(len) | cli.deref() == [3, 2]\n",
    "assert range(3) | applyCl(lambda x, bias: x**2+bias, bias=5) | cli.deref() == [5, 6, 9]\n",
    "someList = [1, 2, 3]\n",
    "assert [\"abc\", \"de\"] | applyCl(lambda s: someList) | cli.deref() == [[1, 2, 3], [1, 2, 3]]\n",
    "fn = \"/home/kelvin/repos/labs/k1lib/k1lib/cli/test/applyCl.data\"\n",
    "range(10) | cli.repeatFrom(5) | cli.join(\"\") | cli.repeat(2) | cli.join(\"\\n\") | cli.file(fn)\n",
    "applyCl.splitFile(fn)\n",
    "assert None | applyCl.aS(lambda: cli.cat(fn, False) | cli.shape(0)) | cli.cut(1) | cli.toProd() == 2550\n",
    "fn = \"~/repos/labs/k1lib/k1lib/cli/test/applyCl.cat.data\"\n",
    "(\"0123456789\"*5 + \"\\n\") * 1000 | cli.file(fn)\n",
    "applyCl.splitFile(fn); assert applyCl.cat(fn, cli.shape(0)) | cli.shape(0) == 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9697db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "thEmptySentinel = object()\n",
    "class applyTh(BaseCli):\n",
    "    def __init__(self, f, prefetch:int=None, timeout:float=5, bs:int=1):\n",
    "        \"\"\"Kinda like the same as :class:`applyMp`, but executes ``f`` on multiple\n",
    "threads, instead of on multiple processes. Advantages:\n",
    "\n",
    "- Relatively low overhead for thread creation\n",
    "- Fast, if ``f`` is io-bound\n",
    "- Does not have to serialize and deserialize the result, meaning iterators can be\n",
    "  exchanged\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "- Still has thread creation overhead, so it's still recommended to specify ``bs``\n",
    "- Is slow if ``f`` has to obtain the GIL to be able to do anything\n",
    "\n",
    "All examples from :class:`applyMp` should work perfectly here.\"\"\"\n",
    "        fs = [f]; super().__init__(fs=fs); self.f = fs[0]; self.bs = bs\n",
    "        self.prefetch = prefetch or int(1e9); self.timeout = timeout\n",
    "    def __ror__(self, it):\n",
    "        if self.bs > 1:\n",
    "            yield from (it | cli.batched(self.bs, True) | applyTh(apply(self.f), self.prefetch, self.timeout) | cli.joinStreams()); return\n",
    "        datas = deque(); it = iter(it)\n",
    "        innerF = fastF(self.f); timeout = self.timeout\n",
    "        def f(line, wrapper): wrapper.value = innerF(line)\n",
    "        for _, line in zip(range(self.prefetch), it):\n",
    "            w = k1lib.Wrapper(thEmptySentinel)\n",
    "            t = threading.Thread(target=f, args=(line,w))\n",
    "            t.start(); datas.append((t, w))\n",
    "        for line in it:\n",
    "            data = datas.popleft(); data[0].join(timeout)\n",
    "            if data[1].value is thEmptySentinel:\n",
    "                for data in datas: data[0].join(0.01)\n",
    "                raise RuntimeError(\"Thread timed out!\")\n",
    "            yield data[1].value; w = k1lib.Wrapper(thEmptySentinel)\n",
    "            t = threading.Thread(target=f, args=(line,w))\n",
    "            t.start(); datas.append((t, w))\n",
    "        for i in range(len(datas)): # do it this way so that python can remove threads early, due to ref counting\n",
    "            data = datas.popleft(); data[0].join(timeout)\n",
    "            if data[1].value is thEmptySentinel:\n",
    "                for data in datas: data[0].join(0.01)\n",
    "                raise RuntimeError(\"Thread timed out!\")\n",
    "            yield data[1].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd890f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with k1lib.timer() as t1:\n",
    "    range(10000) | applyTh(lambda x: x**2) | cli.toList()\n",
    "with k1lib.timer() as t2:\n",
    "    range(10000) | applyTh(lambda x: x**2, bs=32) | cli.toList()\n",
    "assert t1() > t2()*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d485b77-eb0e-4b1b-aabc-7db185e082fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class applySerial(BaseCli):\n",
    "    def __init__(self, f, *args, **kwargs):\n",
    "        \"\"\"Applies a function repeatedly. First yields input iterator ``x``. Then\n",
    "yields ``f(x)``, then ``f(f(x))``, then ``f(f(f(x)))`` and so on. Example::\n",
    "\n",
    "    # returns [2, 4, 8, 16, 32]\n",
    "    2 | applySerial(op()*2) | head(5) | deref()\n",
    "\n",
    "If the result of your operation is an iterator, you might want to\n",
    ":class:`~k1lib.cli.utils.deref` it, like this::\n",
    "\n",
    "    rs = iter(range(8)) | applySerial(rows()[::2])\n",
    "    # returns [0, 2, 4, 6]\n",
    "    rs | rows(1) | item() | deref()\n",
    "    # returns []. This is because all the elements are taken by the previous deref()\n",
    "    rs | item() | deref()\n",
    "    # returns [[2, 8], [10, -6], [4, 16], [20, -12]]\n",
    "    [2, 8] | ~applySerial(lambda a, b: (a + b, a - b)) | head(4) | deref()\n",
    "\n",
    "    rs = iter(range(8)) | applySerial(rows()[::2] | deref())\n",
    "    # returns [0, 2, 4, 6]\n",
    "    rs | rows(1) | item()\n",
    "    # returns [0, 4]\n",
    "    rs | item() # or `next(rs)`\n",
    "    # returns [0]\n",
    "    rs | item() # or `next(rs)`\n",
    "\n",
    ":param f: function to apply repeatedly\"\"\"\n",
    "        fs = [f]; super().__init__(fs=fs); self.f = fs[0]\n",
    "        self.unpack = False; self.args = args; self.kwargs = kwargs\n",
    "    def __ror__(self, it):\n",
    "        f = fastF(self.f)\n",
    "        if self.unpack:\n",
    "            while True: yield it; it = f(*it, *self.args, **self.kwargs)\n",
    "        else:\n",
    "            while True: yield it; it = f(it, *self.args, **self.kwargs)\n",
    "    def __invert__(self):\n",
    "        ans = applySerial(self.f, *self.args, **self.kwargs)\n",
    "        ans.unpack = True; return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f239ddd0-f039-4ff2-bfb3-4514109c7f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 2 | applySerial(cli.op()*2) | cli.head(5) | cli.deref() == [2, 4, 8, 16, 32]\n",
    "rs = iter(range(8)) | applySerial(cli.rows()[::2])\n",
    "assert rs | cli.rows(1) | cli.item() | cli.deref() == [0, 2, 4, 6]\n",
    "assert rs | cli.item() | cli.deref() == []\n",
    "rs = iter(range(8)) | applySerial(cli.rows()[::2] | cli.deref())\n",
    "assert rs | cli.rows(1) | cli.item() == [0, 2, 4, 6]\n",
    "assert next(rs) == [0, 4]; assert next(rs) == [0]\n",
    "assert [2, 8] | ~applySerial(lambda a, b: (a + b, a - b)) | cli.head(4) | cli.deref() == [[2, 8], [10, -6], [4, 16], [20, -12]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "238ff6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class sort(BaseCli):\n",
    "    def __init__(self, column:int=0, numeric=True, reverse=False):\n",
    "        \"\"\"Sorts all lines based on a specific `column`.\n",
    "Example::\n",
    "\n",
    "    # returns [[5, 'a'], [1, 'b']]\n",
    "    [[1, \"b\"], [5, \"a\"]] | ~sort(0) | deref()\n",
    "    # returns [[2, 3]]\n",
    "    [[1, \"b\"], [5, \"a\"], [2, 3]] | ~sort(1) | deref()\n",
    "    # errors out, as you can't really compare str with int\n",
    "    [[1, \"b\"], [2, 3], [5, \"a\"]] | sort(1, False) | deref()\n",
    "    # returns [-1, 2, 3, 5, 8]\n",
    "    [2, 5, 3, -1, 8] | sort(None) | deref()\n",
    "\n",
    ":param column: if None, sort rows based on themselves and not an element\n",
    ":param numeric: whether to convert column to float\n",
    ":param reverse: False for smaller to bigger, True for bigger to smaller. Use\n",
    "    :meth:`__invert__` to quickly reverse the order instead of using this param\"\"\"\n",
    "        self.column = column; self.reverse = reverse; self.numeric = numeric\n",
    "        self.filterF = (lambda x: float(x)) if numeric else (lambda x: x)\n",
    "    def __ror__(self, it:Iterator[str]):\n",
    "        c = self.column\n",
    "        if c is None:\n",
    "            return it | cli.wrapList() | cli.transpose() | sort(0, self.numeric, self.reverse) | cli.op()[0].all()\n",
    "        f = self.filterF\n",
    "        rows = (it | cli.isNumeric(c) if self.numeric else it) | cli.deref(maxDepth=2)\n",
    "        def sortF(row):\n",
    "            if len(row) > c: return f(row[c])\n",
    "            return float(\"inf\")\n",
    "        return sorted(rows, key=sortF, reverse=self.reverse)\n",
    "    def __invert__(self):\n",
    "        \"\"\"Creates a clone that has the opposite sort order\"\"\"\n",
    "        return sort(self.column, self.numeric, not self.reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1627b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert [[1, \"b\"], [5, \"a\"]] | ~sort(0) | cli.deref() == [[5, 'a'], [1, 'b']]\n",
    "assert [[1, \"b\"], [5, \"a\"], [2, 3]] | ~sort(1) | cli.deref() == [[2, 3]]\n",
    "try: [[1, \"b\"], [2, 3], [5, \"a\"]] | sort(1, False) | cli.deref()\n",
    "except TypeError: pass\n",
    "assert [2, 5, 3, -1, 8] | sort(None) | cli.deref() == [-1, 2, 3, 5, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "167a0ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class sortF(BaseCli):\n",
    "    def __init__(self, f:Callable[[T], float], column:int=None, reverse=False):\n",
    "        \"\"\"Sorts rows using a function.\n",
    "Example::\n",
    "\n",
    "    # returns ['a', 'aa', 'aaa', 'aaaa', 'aaaaa']\n",
    "    [\"a\", \"aaa\", \"aaaaa\", \"aa\", \"aaaa\"] | sortF(lambda r: len(r)) | deref()\n",
    "    # returns ['aaaaa', 'aaaa', 'aaa', 'aa', 'a']\n",
    "    [\"a\", \"aaa\", \"aaaaa\", \"aa\", \"aaaa\"] | ~sortF(lambda r: len(r)) | deref()\"\"\"\n",
    "        fs = [f]; super().__init__(fs=fs); self.f = fs[0]\n",
    "        self.column = column; self.reverse = reverse\n",
    "    def __ror__(self, it:Iterator[T]) -> Iterator[T]:\n",
    "        c = self.column; f = self.f\n",
    "        if c is None: return sorted(list(it), key=f, reverse=self.reverse)\n",
    "        def sortF(row):\n",
    "            if len(row) > c: return f(row[c])\n",
    "            return float(\"inf\")\n",
    "        return sorted(list(it), key=sortF, reverse=self.reverse)\n",
    "    def __invert__(self) -> \"sortF\":\n",
    "        return sortF(self.f, self.column, not self.reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87e43803",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert [\"a\", \"aaa\", \"aaaaa\", \"aa\", \"aaaa\"] | sortF(lambda r: len(r)) | cli.deref() == ['a', 'aa', 'aaa', 'aaaa', 'aaaaa']\n",
    "assert [\"a\", \"aaa\", \"aaaaa\", \"aa\", \"aaaa\"] | ~sortF(lambda r: len(r)) | cli.deref() == ['aaaaa', 'aaaa', 'aaa', 'aa', 'a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4032f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class consume(BaseCli):\n",
    "    def __init__(self, f:Union[BaseCli, Callable[[T], None]]):\n",
    "        r\"\"\"Consumes the iterator in a side stream. Returns the iterator.\n",
    "Kinda like the bash command ``tee``. Example::\n",
    "\n",
    "    # prints \"0\\n1\\n2\" and returns [0, 1, 2]\n",
    "    range(3) | consume(headOut()) | toList()\n",
    "    # prints \"range(0, 3)\" and returns [0, 1, 2]\n",
    "    range(3) | consume(lambda it: print(it)) | toList()\n",
    "\n",
    "This is useful whenever you want to mutate something, but don't want to\n",
    "include the function result into the main stream.\n",
    "\n",
    "See also: :class:`~k1lib.cli.output.tee`\"\"\"\n",
    "        fs = [f]; super().__init__(fs=fs); self.f = fs[0]\n",
    "    def __ror__(self, it:T) -> T:\n",
    "        self.f(it); return it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09844c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with k1lib.captureStdout() as out:\n",
    "    assert range(3) | consume(lambda it: print(it)) | cli.toList() == [0, 1, 2]\n",
    "assert out()[0] == \"range(0, 3)\"\n",
    "with k1lib.captureStdout() as out:\n",
    "    assert range(3) | consume(cli.headOut()) | cli.toList() == [0, 1, 2]\n",
    "assert \"\\n\".join(out()) == \"0\\n1\\n2\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4d7d52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class randomize(BaseCli):\n",
    "    def __init__(self, bs=100, seed=None):\n",
    "        \"\"\"Randomize input stream. In order to be efficient, this does not\n",
    "convert the input iterator to a giant list and yield random values from that.\n",
    "Instead, this fetches ``bs`` items at a time, randomizes them, returns and\n",
    "fetch another ``bs`` items. If you want to do the giant list, then just pass\n",
    "in ``float(\"inf\")``, or ``None``. Example::\n",
    "\n",
    "    # returns [0, 1, 2, 3, 4], effectively no randomize at all\n",
    "    range(5) | randomize(1) | deref()\n",
    "    # returns something like this: [1, 0, 2, 3, 5, 4, 6, 8, 7, 9]. You can clearly see the batches\n",
    "    range(10) | randomize(3) | deref()\n",
    "    # returns something like this: [7, 0, 5, 2, 4, 9, 6, 3, 1, 8]\n",
    "    range(10) | randomize(float(\"inf\")) | deref()\n",
    "    # same as above\n",
    "    range(10) | randomize(None) | deref()\n",
    "    # returns True, as the seed is the same\n",
    "    range(10) | randomize(seed=4) | deref() == range(10) | randomize(seed=4) | deref()\"\"\"\n",
    "        self.bs = bs if bs != None else float(\"inf\"); self.seed = seed; self._initGenn()\n",
    "    def _initGenn(self):\n",
    "        if hasTorch:\n",
    "            gen = torch.Generator().manual_seed(random.Random(self.seed).getrandbits(63))\n",
    "            self.genn = lambda n: torch.randperm(n, generator=gen)\n",
    "        else: self.genn = np.random.permutation\n",
    "    def __getstate__(self):\n",
    "        genn = self.genn; self.genn = None; return self.__dict__\n",
    "    def __setstate__(self, d): self.__dict__.update(d); self._initGenn()\n",
    "    def __ror__(self, it:Iterator[T]) -> Iterator[T]:\n",
    "        bs = self.bs\n",
    "        if isinstance(it, settings.arrayTypes):\n",
    "            if bs is None or len(it) <= bs: return it if len(it) == 1 else it[self.genn(len(it))]\n",
    "        def gen():\n",
    "            for batch in it | cli.batched(bs, True):\n",
    "                batch = list(batch); perms = self.genn(len(batch))\n",
    "                for idx in perms: yield batch[idx]\n",
    "        return gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "57699ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert range(10) | randomize(1) | cli.deref() == list(range(10))\n",
    "a = range(10) | randomize(3) | cli.deref()\n",
    "assert a[-1] == 9; assert len(a) == 10\n",
    "assert len(range(10) | randomize(float(\"inf\")) | cli.deref()) == 10\n",
    "assert len(range(10) | randomize(None) | cli.deref()) == 10\n",
    "assert range(10) | randomize(seed=4) | cli.deref() == range(10) | randomize(seed=4) | cli.deref()\n",
    "assert np.random.randn(9, 3) | randomize() | cli.aS(type) == np.ndarray\n",
    "assert np.random.randn(1, 3) | randomize() | cli.shape() == (1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e937a059",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class StaggeredStream:\n",
    "    def __init__(self, stream:Iterator[T], every:int):\n",
    "        \"\"\"Not intended to be instantiated by the end user. Use :class:`stagger`\n",
    "instead.\"\"\"\n",
    "        self.stream = stream; self.every = every\n",
    "    def __iter__(self):\n",
    "        for i, v in zip(range(self.every), self.stream): yield v\n",
    "    def __len__(self):\n",
    "        \"\"\"Length of window (length of result if you were to deref it).\"\"\"\n",
    "        return self.every\n",
    "class stagger(BaseCli):\n",
    "    def __init__(self, every:int):\n",
    "        \"\"\"Staggers input stream into multiple stream \"windows\" placed serially. Best\n",
    "explained with an example::\n",
    "\n",
    "    o = range(10) | stagger(3)\n",
    "    o | deref() # returns [0, 1, 2], 1st \"window\"\n",
    "    o | deref() # returns [3, 4, 5], 2nd \"window\"\n",
    "    o | deref() # returns [6, 7, 8]\n",
    "    o | deref() # returns [9]\n",
    "    o | deref() # returns []\n",
    "\n",
    "This might be useful when you're constructing a data loader::\n",
    "\n",
    "    dataset = [range(20), range(30, 50)] | transpose()\n",
    "    dl = dataset | batched(3) | (transpose() | toTensor()).all() | stagger(4)\n",
    "    for epoch in range(3):\n",
    "        for xb, yb in dl: # looping over a window\n",
    "            print(epoch)\n",
    "            # then something like: model(xb)\n",
    "\n",
    "The above code will print 6 lines. 4 of them is \"0\" (because we stagger every 4\n",
    "batches), and xb's shape' will be (3,) (because we batched every 3 samples).\n",
    "\n",
    "You should also keep in mind that this doesn't really change the property of the\n",
    "stream itself. Essentially, treat these pairs of statement as being the same thing::\n",
    "\n",
    "    o = range(11, 100)\n",
    "    \n",
    "    # both returns 11\n",
    "    o | stagger(20) | item()\n",
    "    o | item()\n",
    "\n",
    "    # both returns [11, 12, ..., 20]\n",
    "    o | head(10) | deref()\n",
    "    o | stagger(20) | head(10) | deref()\n",
    "\n",
    "Lastly, multiple iterators might be getting values from the same stream window,\n",
    "meaning::\n",
    "\n",
    "    o = range(11, 100) | stagger(10)\n",
    "    it1 = iter(o); it2 = iter(o)\n",
    "    next(it1) # returns 11\n",
    "    next(it2) # returns 12\n",
    "\n",
    "This may or may not be desirable. Also this should be obvious, but I want to\n",
    "mention this in case it's not clear to you.\"\"\"\n",
    "        self.every = int(every)\n",
    "    def __ror__(self, it:Iterator[T]) -> StaggeredStream:\n",
    "        return StaggeredStream(iter(it), self.every)\n",
    "    @staticmethod\n",
    "    def tv(every:int, ratio:float=0.8):\n",
    "        \"\"\"Convenience method to quickly stagger train and valid datasets.\n",
    "Example::\n",
    "\n",
    "    # returns [[16], [4]]\n",
    "    [range(100)]*2 | stagger.tv(20) | shape().all() | deref()\"\"\"\n",
    "        return stagger(round(every*ratio)) + stagger(round(every*(1-ratio)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e7102c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 12)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert [range(100)]*2 | stagger.tv(20) | cli.shape().all() | cli.deref() == [[16], [4]]\n",
    "o = range(11,100) | stagger(10)\n",
    "it1 = iter(o); it2 = iter(o)\n",
    "next(it1), next(it2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9143b796",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = range(10) | stagger(3); assert a | cli.deref() == [0, 1, 2]\n",
    "assert a | cli.deref() == [3, 4, 5]; assert a | cli.deref() == [6, 7, 8]\n",
    "assert a | cli.deref() == [9]; assert a | cli.deref() == []\n",
    "with k1lib.captureStdout() as outer:\n",
    "    dataset = [range(20), range(30, 50)] | cli.transpose()\n",
    "    dl = dataset | cli.batched(3) | (cli.transpose() | cli.toTensor()).all() | stagger(4)\n",
    "    for epoch in range(3):\n",
    "        for xb, yb in dl: print(epoch)\n",
    "assert outer() == [\"0\"] * 4 + [\"1\"] * 2 + [\"\"]\n",
    "o = range(11, 100)\n",
    "assert o | stagger(20) | cli.item() == o | cli.item()\n",
    "assert o | cli.head(10) | cli.deref() == o | stagger(20) | cli.head(10) | cli.deref()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae428316",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "compareOps = {\"__lt__\", \"__le__\", \"__eq__\", \"__ne__\", \"__gt__\", \"__ge__\"}\n",
    "class op(k1lib.Absorber, BaseCli):\n",
    "    def __init__(self):\n",
    "        \"\"\"Absorbs operations done on it and applies it on the stream. Based\n",
    "on :class:`~k1lib.Absorber`. Example::\n",
    "\n",
    "    # returns 16\n",
    "    4 | op()**2\n",
    "    # returns 16, equivalent to the above\n",
    "    4 | aS(lambda x: x**2)\n",
    "    # returns [0, 1, 4, 9, 16]\n",
    "    range(5) | apply(op()**2) | deref()\n",
    "    # returns [0, 1, 4, 9, 16], equivalent to the above\n",
    "    range(5) | apply(lambda x: x**2) | deref()\n",
    "\n",
    "Main advantage is that you don't have to waste keystrokes when you just want\n",
    "to do a simple operation. How it works underneath is a little magical, so just\n",
    "treat it as a blackbox. A more complex example::\n",
    "\n",
    "    t = torch.tensor([[1, 2, 3], [4, 5, 6.0]])\n",
    "    # returns [torch.tensor([[4., 5., 6., 7., 8., 9.]])]\n",
    "    [t] | (op() + 3).view(1, -1).all() | deref()\n",
    "\n",
    "Basically, you can treat ``op()`` as the input tensor. Tbh, you\n",
    "can do the same thing with this::\n",
    "\n",
    "    [t] | applyS(lambda t: (t+3).view(-1, 1)).all() | deref()\n",
    "\n",
    "But that's kinda long and may not be obvious. This can be surprisingly resilient, as\n",
    "you can still combine with other cli tools as usual, for example::\n",
    "\n",
    "    # returns [2, 3], demonstrating \"&\" operator\n",
    "    torch.randn(2, 3) | (op().shape & iden()) | deref() | item()\n",
    "\n",
    "    a = torch.tensor([[1, 2, 3], [7, 8, 9]])\n",
    "    # returns torch.tensor([4, 5, 6]), demonstrating \"+\" operator for clis and not clis\n",
    "    (a | op() + 3 + iden() | item() == torch.tensor([4, 5, 6])).all()\n",
    "\n",
    "    # returns [[3], [3]], demonstrating .all() and \"|\" serial chaining\n",
    "    torch.randn(2, 3) | (op().shape.all() | deref())\n",
    "    \n",
    "    # returns [[8, 18], [9, 19]], demonstrating you can treat `op()` as a regular function\n",
    "    [range(10), range(10, 20)] | transpose() | filt(op() > 7, 0) | deref()\n",
    "    \n",
    "    # returns [3, 4, 5, 6, 7, 8, 9], demonstrating bounds comparison\n",
    "    range(100) | filt(3 <= op() < 10) | deref()\n",
    "\n",
    "This can only deal with simple operations only. For complex operations, resort\n",
    "to the longer version ``aS(lambda x: ...)`` instead!\n",
    "\n",
    "There are also operations that are difficult to achieve, like\n",
    "``len(op())``, as Python is expecting an integer output, so\n",
    "``op()`` can't exactly take over. Instead, you have to use :class:`aS`,\n",
    "or do ``op().ab_len()``. Get a list of all of these special operations\n",
    "in the source of :class:`~k1lib.Absorber`.\n",
    "\n",
    "Performance-wise, in most cases, there are no degradation, so don't worry\n",
    "about it. Everything is pretty much on par with native lambdas::\n",
    "\n",
    "    n = 10_000_000\n",
    "    # takes 1.48s\n",
    "    for i in range(n): i**2\n",
    "    # takes 1.89s, 1.28x worse than for loop\n",
    "    range(n) | apply(lambda x: x**2) | ignore()\n",
    "    # takes 1.86s, 1.26x worse than for loop\n",
    "    range(n) | apply(op()**2) | ignore()\n",
    "    # takes 1.86s\n",
    "    range(n) | (op()**2).all() | ignore()\n",
    "\n",
    "More complex operations still retains the same speeds, as there's a JIT compiler embedded in::\n",
    "\n",
    "    # takes 2.15s\n",
    "    for i in range(n): (i**2-3)*0.1\n",
    "    # takes 2.53s, 1.18x worse than for loop\n",
    "    range(n) | apply(lambda x: (x**2-3)*0.1) | ignore()\n",
    "    # takes 2.46s, 1.14x worse than for loop\n",
    "    range(n) | apply((op()**2-3)*0.1) | ignore()\n",
    "\n",
    "Reserved operations that are not absorbed are:\n",
    "\n",
    "- all\n",
    "- __ror__ (__or__ still works!)\n",
    "- ab_solidify\n",
    "- op_hint\"\"\"\n",
    "        super().__init__({\"_hint\": None})\n",
    "    @staticmethod\n",
    "    def solidify(f):\n",
    "        \"\"\"Static equivalent of ``a.ab_solidify()``.\n",
    "Example::\n",
    "        \n",
    "    f = op()**2\n",
    "    f = op.solidify(f)\n",
    "\n",
    "If ``f`` is not an ``op``, then just return it without doing anything to it\"\"\"\n",
    "        if f.__class__.__name__.split(\".\")[-1] == \"op\": f.ab_solidify()\n",
    "        return f\n",
    "    def __ror__(self, it):\n",
    "        return self.ab_operate(it)\n",
    "    def __or__(self, o):\n",
    "        if isinstance(o, BaseCli): return super(k1lib.Absorber, self).__or__(o)\n",
    "        return super().__add__(o)\n",
    "    def __add__(self, o):\n",
    "        if isinstance(o, BaseCli): return super(k1lib.Absorber, self).__add__(o)\n",
    "        return super().__add__(o)\n",
    "    def __and__(self, o):\n",
    "        if isinstance(o, BaseCli): return super(k1lib.Absorber, self).__and__(o)\n",
    "        return super().__and__(o)\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        if self._ab_solidified: return self.ab_operate(*args, **kwargs)\n",
    "        return super().__call__(*args, **kwargs)\n",
    "    def _typehint(self, inp):\n",
    "        return self._hint if self._hint is not None else tAny()\n",
    "    def op_hint(self, _hint):\n",
    "        \"\"\"Specify output type hint\"\"\"\n",
    "        self._ab_sentinel = True; self._hint = _hint\n",
    "        self._ab_sentinel = False; return self\n",
    "cli.op = op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44eab5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([[1, 2, 3], [4, 5, 6.0]])\n",
    "assert torch.all([t] | (op() + 3).view(1, -1).all() | cli.deref() | cli.item() == torch.tensor([[4., 5., 6., 7., 8., 9.]]))\n",
    "assert torch.randn(2, 3) | (op().shape & cli.iden()) | cli.deref() | cli.item() == [2, 3]\n",
    "a = torch.tensor([[1, 2, 3], [7, 8, 9]])\n",
    "assert (a | op() + 3 + cli.iden() | cli.item() == torch.tensor([4, 5, 6])).all()\n",
    "assert torch.randn(2, 3) | op().shape.all() | cli.deref() == [[3], [3]]\n",
    "assert torch.randn(2, 3) | (op().shape.all() | cli.deref()) == [[3], [3]]\n",
    "o = op()(56); o.ab_solidify(); assert o(lambda x: x+20) == 76\n",
    "assert [range(10), range(10, 20)] | cli.transpose() | cli.filt(op() > 7, 0) | cli.deref() == [[8, 18], [9, 19]]\n",
    "f = (op()**2).ab_solidify(); assert f(3) == 9\n",
    "assert range(100) | cli.filt(3 <= op() < 10) | cli.deref() == [3, 4, 5, 6, 7, 8, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ce6d17b-93e1-4701-963a-3f095648b213",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class integrate(BaseCli):\n",
    "    def __init__(self, dt=1):\n",
    "        \"\"\"Integrates the input.\n",
    "Example::\n",
    "\n",
    "    # returns [0, 1, 3, 6, 10, 15, 21, 28, 36, 45]\n",
    "    range(10) | integrate() | deref()\n",
    "    # returns [0, 2, 6, 12, 20, 30, 42, 56, 72, 90]\n",
    "    range(10) | integrate(2) | deref()\n",
    "\n",
    ":param dt: Optional small step\"\"\"\n",
    "        self.dt = dt\n",
    "    def __ror__(self, it):\n",
    "        if self.dt == 1:\n",
    "            s = 0\n",
    "            for e in it: s += e; yield s\n",
    "        else:\n",
    "            dt = self.dt; s = 0\n",
    "            for e in it: s += e*dt; yield s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "873a2c6e-d3e8-4fb5-a8e4-83f0e99bbe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert range(10) | integrate() | cli.deref() == [0, 1, 3, 6, 10, 15, 21, 28, 36, 45]\n",
    "assert range(10) | integrate(2) | cli.deref() == [0, 2, 6, 12, 20, 30, 42, 56, 72, 90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7119be2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current dir: /home/kelvin/repos/labs/k1lib, /home/kelvin/repos/labs/k1lib/k1lib/cli/../../export.py\n",
      "rm: cannot remove '__pycache__': No such file or directory\n",
      "Found existing installation: k1lib 1.3.6.3\n",
      "Uninstalling k1lib-1.3.6.3:\n",
      "  Successfully uninstalled k1lib-1.3.6.3\n",
      "running install\n",
      "/home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "/home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages/setuptools/command/easy_install.py:144: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "creating k1lib.egg-info\n",
      "writing k1lib.egg-info/PKG-INFO\n",
      "writing dependency_links to k1lib.egg-info/dependency_links.txt\n",
      "writing requirements to k1lib.egg-info/requires.txt\n",
      "writing top-level names to k1lib.egg-info/top_level.txt\n",
      "writing manifest file 'k1lib.egg-info/SOURCES.txt'\n",
      "reading manifest file 'k1lib.egg-info/SOURCES.txt'\n",
      "adding license file 'LICENSE'\n",
      "writing manifest file 'k1lib.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "creating build/lib/k1lib\n",
      "copying k1lib/_learner.py -> build/lib/k1lib\n",
      "copying k1lib/fmt.py -> build/lib/k1lib\n",
      "copying k1lib/_k1a.py -> build/lib/k1lib\n",
      "copying k1lib/_context.py -> build/lib/k1lib\n",
      "copying k1lib/selector.py -> build/lib/k1lib\n",
      "copying k1lib/imports.py -> build/lib/k1lib\n",
      "copying k1lib/_baseClasses.py -> build/lib/k1lib\n",
      "copying k1lib/_basics.py -> build/lib/k1lib\n",
      "copying k1lib/viz.py -> build/lib/k1lib\n",
      "copying k1lib/_higher.py -> build/lib/k1lib\n",
      "copying k1lib/__init__.py -> build/lib/k1lib\n",
      "copying k1lib/_monkey.py -> build/lib/k1lib\n",
      "copying k1lib/knn.py -> build/lib/k1lib\n",
      "copying k1lib/p5.py -> build/lib/k1lib\n",
      "copying k1lib/graphEqn.py -> build/lib/k1lib\n",
      "copying k1lib/schedule.py -> build/lib/k1lib\n",
      "copying k1lib/_perlin.py -> build/lib/k1lib\n",
      "copying k1lib/eqn.py -> build/lib/k1lib\n",
      "creating build/lib/k1lib/_hidden\n",
      "copying k1lib/_hidden/hiddenFile.py -> build/lib/k1lib/_hidden\n",
      "copying k1lib/_hidden/__init__.py -> build/lib/k1lib/_hidden\n",
      "creating build/lib/k1lib/cli\n",
      "copying k1lib/cli/bio.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/cif.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/structural.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/modifier.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/gb.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/output.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/kxml.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/nb.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/inp.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/mol.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/mgi.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/grep.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/sam.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/trace.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/__init__.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/typehint.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/filt.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/utils.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/init.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/conv.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/optimizations.py -> build/lib/k1lib/cli\n",
      "copying k1lib/cli/kcsv.py -> build/lib/k1lib/cli\n",
      "creating build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/loss_accuracy.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/progress.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/limits.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/hookParam.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/profiler.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/callbacks.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/paramFinder.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/core.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/__init__.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/landscape.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/confusionMatrix.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/recorder.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/shorts.py -> build/lib/k1lib/callbacks\n",
      "copying k1lib/callbacks/hookModule.py -> build/lib/k1lib/callbacks\n",
      "creating build/lib/k1lib/callbacks/profilers\n",
      "copying k1lib/callbacks/profilers/time.py -> build/lib/k1lib/callbacks/profilers\n",
      "copying k1lib/callbacks/profilers/memory.py -> build/lib/k1lib/callbacks/profilers\n",
      "copying k1lib/callbacks/profilers/__init__.py -> build/lib/k1lib/callbacks/profilers\n",
      "copying k1lib/callbacks/profilers/io.py -> build/lib/k1lib/callbacks/profilers\n",
      "copying k1lib/callbacks/profilers/computation.py -> build/lib/k1lib/callbacks/profilers\n",
      "creating build/lib/k1lib/callbacks/lossFunctions\n",
      "copying k1lib/callbacks/lossFunctions/accuracy.py -> build/lib/k1lib/callbacks/lossFunctions\n",
      "copying k1lib/callbacks/lossFunctions/__init__.py -> build/lib/k1lib/callbacks/lossFunctions\n",
      "copying k1lib/callbacks/lossFunctions/shorts.py -> build/lib/k1lib/callbacks/lossFunctions\n",
      "creating build/lib/k1lib/_mo\n",
      "copying k1lib/_mo/atom.py -> build/lib/k1lib/_mo\n",
      "copying k1lib/_mo/parseM.py -> build/lib/k1lib/_mo\n",
      "copying k1lib/_mo/substance.py -> build/lib/k1lib/_mo\n",
      "copying k1lib/_mo/system.py -> build/lib/k1lib/_mo\n",
      "copying k1lib/_mo/__init__.py -> build/lib/k1lib/_mo\n",
      "creating build/lib/k1lib/serve\n",
      "copying k1lib/serve/suffix.py -> build/lib/k1lib/serve\n",
      "copying k1lib/serve/__init__.py -> build/lib/k1lib/serve\n",
      "copying k1lib/serve/main.py -> build/lib/k1lib/serve\n",
      "creating build/lib/k1lib/k1ui\n",
      "copying k1lib/k1ui/__init__.py -> build/lib/k1lib/k1ui\n",
      "copying k1lib/k1ui/main.py -> build/lib/k1lib/k1ui\n",
      "creating build/bdist.linux-x86_64\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/_learner.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "creating build/bdist.linux-x86_64/egg/k1lib/serve\n",
      "copying build/lib/k1lib/serve/suffix.py -> build/bdist.linux-x86_64/egg/k1lib/serve\n",
      "copying build/lib/k1lib/serve/__init__.py -> build/bdist.linux-x86_64/egg/k1lib/serve\n",
      "copying build/lib/k1lib/serve/main.py -> build/bdist.linux-x86_64/egg/k1lib/serve\n",
      "copying build/lib/k1lib/fmt.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/_k1a.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/_context.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/selector.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/imports.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "creating build/bdist.linux-x86_64/egg/k1lib/k1ui\n",
      "copying build/lib/k1lib/k1ui/__init__.py -> build/bdist.linux-x86_64/egg/k1lib/k1ui\n",
      "copying build/lib/k1lib/k1ui/main.py -> build/bdist.linux-x86_64/egg/k1lib/k1ui\n",
      "copying build/lib/k1lib/_baseClasses.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/_basics.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "creating build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/bio.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/cif.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/structural.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/modifier.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/gb.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/output.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/kxml.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/nb.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/inp.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/mol.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/mgi.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/grep.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/sam.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/trace.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/__init__.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/typehint.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/filt.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/utils.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/init.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/conv.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/optimizations.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/cli/kcsv.py -> build/bdist.linux-x86_64/egg/k1lib/cli\n",
      "copying build/lib/k1lib/viz.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/_higher.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/__init__.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/_monkey.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "creating build/bdist.linux-x86_64/egg/k1lib/_mo\n",
      "copying build/lib/k1lib/_mo/atom.py -> build/bdist.linux-x86_64/egg/k1lib/_mo\n",
      "copying build/lib/k1lib/_mo/parseM.py -> build/bdist.linux-x86_64/egg/k1lib/_mo\n",
      "copying build/lib/k1lib/_mo/substance.py -> build/bdist.linux-x86_64/egg/k1lib/_mo\n",
      "copying build/lib/k1lib/_mo/system.py -> build/bdist.linux-x86_64/egg/k1lib/_mo\n",
      "copying build/lib/k1lib/_mo/__init__.py -> build/bdist.linux-x86_64/egg/k1lib/_mo\n",
      "copying build/lib/k1lib/knn.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/p5.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/graphEqn.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "copying build/lib/k1lib/schedule.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "creating build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/loss_accuracy.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/progress.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/limits.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/hookParam.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/profiler.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/callbacks.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/paramFinder.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/core.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "creating build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers\n",
      "copying build/lib/k1lib/callbacks/profilers/time.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers\n",
      "copying build/lib/k1lib/callbacks/profilers/memory.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers\n",
      "copying build/lib/k1lib/callbacks/profilers/__init__.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers\n",
      "copying build/lib/k1lib/callbacks/profilers/io.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers\n",
      "copying build/lib/k1lib/callbacks/profilers/computation.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers\n",
      "copying build/lib/k1lib/callbacks/__init__.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/landscape.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/confusionMatrix.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/recorder.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/shorts.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "copying build/lib/k1lib/callbacks/hookModule.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks\n",
      "creating build/bdist.linux-x86_64/egg/k1lib/callbacks/lossFunctions\n",
      "copying build/lib/k1lib/callbacks/lossFunctions/accuracy.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks/lossFunctions\n",
      "copying build/lib/k1lib/callbacks/lossFunctions/__init__.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks/lossFunctions\n",
      "copying build/lib/k1lib/callbacks/lossFunctions/shorts.py -> build/bdist.linux-x86_64/egg/k1lib/callbacks/lossFunctions\n",
      "copying build/lib/k1lib/_perlin.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "creating build/bdist.linux-x86_64/egg/k1lib/_hidden\n",
      "copying build/lib/k1lib/_hidden/hiddenFile.py -> build/bdist.linux-x86_64/egg/k1lib/_hidden\n",
      "copying build/lib/k1lib/_hidden/__init__.py -> build/bdist.linux-x86_64/egg/k1lib/_hidden\n",
      "copying build/lib/k1lib/eqn.py -> build/bdist.linux-x86_64/egg/k1lib\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_learner.py to _learner.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/serve/suffix.py to suffix.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/serve/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/serve/main.py to main.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/fmt.py to fmt.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_k1a.py to _k1a.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_context.py to _context.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/selector.py to selector.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/imports.py to imports.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/k1ui/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/k1ui/main.py to main.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_baseClasses.py to _baseClasses.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_basics.py to _basics.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/bio.py to bio.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/cif.py to cif.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/structural.py to structural.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/modifier.py to modifier.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/gb.py to gb.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/output.py to output.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/kxml.py to kxml.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/nb.py to nb.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/inp.py to inp.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/mol.py to mol.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/mgi.py to mgi.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/grep.py to grep.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/sam.py to sam.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/trace.py to trace.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/typehint.py to typehint.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/filt.py to filt.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/utils.py to utils.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/init.py to init.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/conv.py to conv.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/optimizations.py to optimizations.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/cli/kcsv.py to kcsv.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/viz.py to viz.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_higher.py to _higher.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_monkey.py to _monkey.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_mo/atom.py to atom.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_mo/parseM.py to parseM.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_mo/substance.py to substance.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_mo/system.py to system.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_mo/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/knn.py to knn.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/p5.py to p5.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/graphEqn.py to graphEqn.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/schedule.py to schedule.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/loss_accuracy.py to loss_accuracy.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/progress.py to progress.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/limits.py to limits.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/hookParam.py to hookParam.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/profiler.py to profiler.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/callbacks.py to callbacks.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/paramFinder.py to paramFinder.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/core.py to core.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers/time.py to time.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers/memory.py to memory.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers/io.py to io.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/profilers/computation.py to computation.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/landscape.py to landscape.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/confusionMatrix.py to confusionMatrix.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/recorder.py to recorder.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/shorts.py to shorts.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/hookModule.py to hookModule.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/lossFunctions/accuracy.py to accuracy.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/lossFunctions/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/callbacks/lossFunctions/shorts.py to shorts.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_perlin.py to _perlin.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_hidden/hiddenFile.py to hiddenFile.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/_hidden/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/k1lib/eqn.py to eqn.cpython-39.pyc\n",
      "installing package data to build/bdist.linux-x86_64/egg\n",
      "running install_data\n",
      "copying k1lib/serve/main.html -> build/bdist.linux-x86_64/egg/k1lib/serve\n",
      "copying k1lib/k1ui/mouseKey.pth -> build/bdist.linux-x86_64/egg/k1lib/k1ui\n",
      "copying k1lib/k1ui/256.model.state_dict.pth -> build/bdist.linux-x86_64/egg/k1lib/k1ui\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying k1lib.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying k1lib.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying k1lib.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying k1lib.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying k1lib.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "k1lib.cli.__pycache__.init.cpython-39: module MAY be using inspect.trace\n",
      "k1lib.k1ui.__pycache__.main.cpython-39: module MAY be using inspect.getabsfile\n",
      "k1lib.k1ui.__pycache__.main.cpython-39: module MAY be using inspect.stack\n",
      "k1lib.serve.__pycache__.main.cpython-39: module MAY be using inspect.getsource\n",
      "k1lib.serve.__pycache__.main.cpython-39: module MAY be using inspect.getabsfile\n",
      "creating dist\n",
      "creating 'dist/k1lib-1.3.6.3-py3.9.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing k1lib-1.3.6.3-py3.9.egg\n",
      "creating /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages/k1lib-1.3.6.3-py3.9.egg\n",
      "Extracting k1lib-1.3.6.3-py3.9.egg to /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Adding k1lib 1.3.6.3 to easy-install.pth file\n",
      "\n",
      "Installed /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages/k1lib-1.3.6.3-py3.9.egg\n",
      "Processing dependencies for k1lib==1.3.6.3\n",
      "Searching for wurlitzer==3.0.3\n",
      "Best match: wurlitzer 3.0.3\n",
      "Adding wurlitzer 3.0.3 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for forbiddenfruit==0.1.4\n",
      "Best match: forbiddenfruit 0.1.4\n",
      "Adding forbiddenfruit 0.1.4 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for dill==0.3.6\n",
      "Best match: dill 0.3.6\n",
      "Adding dill 0.3.6 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for matplotlib==3.7.1\n",
      "Best match: matplotlib 3.7.1\n",
      "Adding matplotlib 3.7.1 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for numpy==1.24.2\n",
      "Best match: numpy 1.24.2\n",
      "Adding numpy 1.24.2 to easy-install.pth file\n",
      "Installing f2py script to /home/kelvin/anaconda3/envs/ray2/bin\n",
      "Installing f2py3 script to /home/kelvin/anaconda3/envs/ray2/bin\n",
      "Installing f2py3.9 script to /home/kelvin/anaconda3/envs/ray2/bin\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for importlib-resources==5.12.0\n",
      "Best match: importlib-resources 5.12.0\n",
      "Adding importlib-resources 5.12.0 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for python-dateutil==2.8.2\n",
      "Best match: python-dateutil 2.8.2\n",
      "Adding python-dateutil 2.8.2 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for pyparsing==3.0.9\n",
      "Best match: pyparsing 3.0.9\n",
      "Adding pyparsing 3.0.9 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for Pillow==9.5.0\n",
      "Best match: Pillow 9.5.0\n",
      "Adding Pillow 9.5.0 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for packaging==23.1\n",
      "Best match: packaging 23.1\n",
      "Adding packaging 23.1 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for kiwisolver==1.4.4\n",
      "Best match: kiwisolver 1.4.4\n",
      "Adding kiwisolver 1.4.4 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for fonttools==4.39.3\n",
      "Best match: fonttools 4.39.3\n",
      "Adding fonttools 4.39.3 to easy-install.pth file\n",
      "Installing fonttools script to /home/kelvin/anaconda3/envs/ray2/bin\n",
      "Installing pyftmerge script to /home/kelvin/anaconda3/envs/ray2/bin\n",
      "Installing pyftsubset script to /home/kelvin/anaconda3/envs/ray2/bin\n",
      "Installing ttx script to /home/kelvin/anaconda3/envs/ray2/bin\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for cycler==0.11.0\n",
      "Best match: cycler 0.11.0\n",
      "Adding cycler 0.11.0 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for contourpy==1.0.7\n",
      "Best match: contourpy 1.0.7\n",
      "Adding contourpy 1.0.7 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for zipp==3.15.0\n",
      "Best match: zipp 3.15.0\n",
      "Adding zipp 3.15.0 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Searching for six==1.16.0\n",
      "Best match: six 1.16.0\n",
      "Adding six 1.16.0 to easy-install.pth file\n",
      "\n",
      "Using /home/kelvin/anaconda3/envs/ray2/lib/python3.9/site-packages\n",
      "Finished processing dependencies for k1lib==1.3.6.3\n"
     ]
    }
   ],
   "source": [
    "!../../export.py cli/modifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2e47c3-784f-4fe3-98ab-6deed4a1c382",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

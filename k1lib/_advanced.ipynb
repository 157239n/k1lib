{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74635845-9ed1-412d-9d58-e06b490e8b55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import k1lib, json, base64, threading, time, random, struct, collections, os, sys, tempfile, contextlib, math, functools, inspect, random, pprint, html; import k1lib.cli as cli; k1 = k1lib\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdec678-3482-4679-be76-d71c78c7a846",
   "metadata": {},
   "source": [
    "Kinda like _basics, but here, it's assumed that the environment is fully loaded, so I can use any functionality, not just pure Python alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed0d4f0e-3651-4b05-86cc-ec7d294191d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "__all__ = [\"log\", \"aes_encrypt\", \"aes_decrypt\", \"aes_encrypt_json\", \"aes_decrypt_json\", \"tempObj\", \"TimeSeries\", \"speed\", \"compileCExt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58e2c6dc-d7ea-40ed-a328-317d50b854b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "_logObj = {\"loaded\": False, \"logMsgs\": deque(), \"path\": None}\n",
    "def _thTarget():\n",
    "    import asyncio, base64, json; from k1lib import kws\n",
    "    async def main():\n",
    "        async with kws.WsClient(\"wss://ws.logs.mlexps.com/_k1_ingest\") as ws:\n",
    "            while True:\n",
    "                if len(_logObj[\"logMsgs\"]) == 0: await asyncio.sleep(0.01)\n",
    "                else: await ws.send(_logObj[\"logMsgs\"].popleft())\n",
    "    asyncio.new_event_loop().run_until_complete(main())\n",
    "def log(path:str, obj:\"any\"):\n",
    "    \"\"\"Logs random debug statements to logs.mlexps.com server.\n",
    "Example::\n",
    "\n",
    "    k1.log(\"ggdrive/topic1\", \"some message\")\n",
    "    k1.log(\"ggdrive/topic1/sub2\", {\"some\": \"json\", \"object\": 2})\n",
    "    \n",
    "    # I typically do it like this, so that I can filter down only the messages that I want based on severity\n",
    "    k1.log(\"ggdrive/info\", {\"some\": \"json\", \"object\": 2})\n",
    "    k1.log(\"ggdrive/error\", {\"some\": \"json\", \"object\": 2})\n",
    "\n",
    "Visit the website https://logs.mlexps.com/watch/ggdrive, or\n",
    "/watch/ggdrive/topic1, or /watch/ggdrive/topic1/sub2 to view all logs\n",
    "coming in.\"\"\"\n",
    "    if not _logObj[\"loaded\"]: _logObj[\"loaded\"] = True; threading.Thread(target=_thTarget).start()\n",
    "    if not isinstance(obj, (str, float, int)):\n",
    "        obj = base64.b64encode(json.dumps(obj).encode()).decode()\n",
    "    _logObj[\"logMsgs\"].append(f\"{path}/{obj}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c57864f-c60c-40b7-a1f9-4d7768b2ac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "if k1lib.settings.startup.import_optionals:\n",
    "    try:\n",
    "        from scipy import stats\n",
    "        __all__.append(\"pValue\")\n",
    "        def pValue(zScore):\n",
    "            \"\"\"2-sided p value of a particular z score. Requires :mod:`scipy`.\"\"\"\n",
    "            return stats.norm.sf(abs(zScore))*2\n",
    "    except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53c68f5a-1e52-4eac-ab47-b8ea80bf5ccc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "try:\n",
    "    Crypto = k1lib.dep(\"Crypto\", \"pycryptodome\", url=\"https://pycryptodome.readthedocs.io/en/latest/\")\n",
    "    def aes_encrypt(plaintext:bytes) -> str: Crypto.Cipher\n",
    "    def aes_decrypt(plaintext:bytes) -> str: Crypto.Cipher\n",
    "    def aes_encrypt_json(obj:dict) -> str: Crypto.Cipher\n",
    "    def aes_decrypt_json(ciphertext:str) -> dict: Crypto.Cipher\n",
    "    from Crypto.Cipher import AES\n",
    "    from Crypto.Random import get_random_bytes\n",
    "    from Crypto.Util.Padding import pad, unpad\n",
    "    def aes_encrypt(plaintext:bytes, key:bytes=None) -> str:\n",
    "        \"\"\"Encrypts a message using AES.\n",
    "Example::\n",
    "\n",
    "    res = k1.aes_encrypt(b\"some message\") # can return '3HV7PKKQL2DLWQWBBTETQTXNMC4Q6DJ2FSS73A7NCRAX6K4ZZKXQ===='\n",
    "    k1.aes_descrypt(res) # returns b\"some message\"\n",
    "\n",
    "After encrypting, this is encoded using base32, ready to be used in urls. This function\n",
    "is a convenience function meant for small messages here and there, and is not intended\n",
    "for heavy duty encryption.\n",
    "\n",
    "The key is automatically generated, and is configurable via ``settings.cred.aes.key``\n",
    "\n",
    "See also: :meth:`aes_encrypt_json`\n",
    "\n",
    ":param plaintext: plaintext to encrypt\n",
    ":param key: 128 bit key, if not specified then will auto generate one on library load at ``settings.cred.aes.key`` \"\"\"\n",
    "        if not isinstance(plaintext, bytes): plaintext = f\"{plaintext}\".encode()\n",
    "        cipher = AES.new(key or k1lib.settings.cred.aes.key, AES.MODE_CBC); ciphertext = cipher.encrypt(pad(plaintext, AES.block_size))\n",
    "        return base64.b32encode(cipher.iv + ciphertext).decode().replace(*\"/_\").replace(*\"+-\")\n",
    "    def aes_decrypt(ciphertext:str, key:bytes=None) -> bytes:\n",
    "        \"\"\"Decrypts a message using AES.\n",
    "See :meth:`aes_encrypt` for more information.\n",
    "\n",
    ":param ciphertext: ciphertext to decrypt\n",
    ":param key: 128 bit key, if not specified then will auto generate one on library load at ``settings.cred.aes.key``\"\"\"\n",
    "        ciphertext = base64.b32decode(ciphertext.replace(*\"-+\").replace(*\"_/\").encode()); iv = ciphertext[:AES.block_size]; cipher = AES.new(key or k1lib.settings.cred.aes.key, AES.MODE_CBC, iv)\n",
    "        return unpad(cipher.decrypt(ciphertext[AES.block_size:]), AES.block_size)\n",
    "    def aes_encrypt_json(obj:dict) -> str:\n",
    "        \"\"\"Encrypts a Python object using AES.\n",
    "Example::\n",
    "\n",
    "    a = k1.aes_encrypt_json({\"a\": 3})\n",
    "    k1.aes_decrypt_json(a) # returns {\"a\": 3}\n",
    "\n",
    "    k1.aes_decrypt_json(k1.aes_encrypt_json([1, 2, 3])) # returns [1, 2, 3]\n",
    "    k1.aes_decrypt_json(k1.aes_encrypt_json(\"abc\"))     # returns \"abc\"\n",
    "\n",
    "See also: :meth:`aes_encrypt`\"\"\"\n",
    "        return aes_encrypt(json.dumps(obj).encode())\n",
    "    def aes_decrypt_json(ciphertext:str) -> dict:\n",
    "        return json.loads(aes_decrypt(ciphertext).decode())\n",
    "    k1lib.settings.cred.add(\"aes\", k1lib.Settings().add(\"key\", get_random_bytes(16), \"16-byte aes key, used in aes_encrypt() and aes_decrypt()\", sensitive=True), \"anything related to AES block cipher\")\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21e19173-6771-4fad-8187-7f43555e96b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert aes_decrypt(aes_encrypt(b\"some message\")) == b\"some message\"\n",
    "assert aes_decrypt_json(aes_encrypt_json({\"a\": 3})) == {\"a\": 3}\n",
    "assert aes_decrypt_json(aes_encrypt_json([1, 2, 3])) == [1, 2, 3]\n",
    "assert aes_decrypt_json(aes_encrypt_json(\"abc\")) == \"abc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f43b832-81f9-4bfc-86dd-b025a511dd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "k1lib.settings.add(\"tempObjLifetime\", 60, \"Default lifetime in seconds used in k1.tempObj()\");\n",
    "_tempObjs = {}; _tempTimeouts = {}; _tempObj_autoInc = k1lib.AutoIncrement(prefix=\"_k1_tempObj_\"); _tempObjThreadStarted = [False]\n",
    "def tempObj(x, timeout=None):\n",
    "    \"\"\"Stores an object that's meant to exist for a short amount of time,\n",
    "and then will be automatically deleted. Example::\n",
    "\n",
    "    key = k1.tempObj(\"Suika Ibuki\", 10) # stores some string that will only last for 10 seconds\n",
    "    k1.tempObj(key)                     # returns \"Suika Ibuki\"\n",
    "    time.sleep(20)\n",
    "    k1.tempObj(key)                     # returns None\n",
    "\n",
    "The default timeout value is 60 seconds, configurable in :data:`~k1lib.settings`.tempObjLifetime\"\"\"\n",
    "    if not _tempObjThreadStarted[0]: k1lib.cron(delay=1)(_tempCleanupThread)\n",
    "    if isinstance(x, str) and x.startswith(\"_k1_tempObj_\"): return _tempObjs.get(x, None)\n",
    "    else:\n",
    "        k = _tempObj_autoInc()\n",
    "        if timeout is None: timeout = k1lib.settings.tempObjLifetime\n",
    "        _tempObjs[k] = x; _tempTimeouts[k] = time.time() + timeout; return k\n",
    "def _tempCleanupThread():\n",
    "    now = time.time()\n",
    "    for k,v in list(_tempTimeouts.items()):\n",
    "        if now > v: del _tempObjs[k]; del _tempTimeouts[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d74193f8-5a35-440a-a0eb-499286d7818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tempObj(\"Suika Ibuki\", 1); assert tempObj(x) == \"Suika Ibuki\"; time.sleep(2); assert tempObj(x) is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "045a09ee-040b-4a2f-a855-1b3db5f78a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb66985a-238d-42cf-90c0-2f465f98c766",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_time = time.time; _timeSeriesD = {}; _timeSeriesID = {}; _timeSeriesAutoInc = k1.AutoIncrement(prefix=\"_k1_ts_\"); _timeSeriesIdxAutoInc = k1.AutoIncrement()\n",
    "class TimeSeries:\n",
    "    def __init__(self, name:str=None, fn:str=None, storeRaw:bool=True, retention:int=7*86400, coldStore:bool=False):\n",
    "        \"\"\"Manages time series data, compresses them, back them up on disk if necessary.\n",
    "Example::\n",
    "\n",
    "    ts1 = k1.TimeSeries(name=\"ts1\")\n",
    "    ts1.append(3, 4, 5) # do this anywhere you'd like. This saves 1 data point containing 3 floats to the sqlite database\n",
    "    \n",
    "    for i in range(600): # deposits 600 samples over 1 minute time span\n",
    "        ts1.append(random.random(), random.random(), random.random())\n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    ts1.getRaw()  # returns something like [[1737213223.4139452, (3, 4, 5)], ...]\n",
    "    ts1.getRate() # returns something like [(1737213313.0752494, 10.066128035852211), ...]\n",
    "    ts1.getPert() # returns something like [[1737213568.9260075, [(0.009, 0.07, 0.47, 0.89, 0.99), (0.001, 0.11, 0.56, 0.90, 0.99), (0.0006, 0.08, 0.46, 0.89, 0.99)]], ...]\n",
    "\n",
    "For :meth:`getRate`, first number is the timestamp, second is the number of data points/second.\n",
    "For :meth:`getPert`, this will return the percentiles of the input data (0%, 10%, 50%, 90%, 100%) for each variable\n",
    "\n",
    "Why does this functionality exists? Well, it's because managing time series usually involves\n",
    "a lot of pain. You need to setup a time series database like Prometheus, or Postgresql to be\n",
    "extra simple. But setting up all that infrastructure takes a lot of effort, and again, if it's\n",
    "hard, you won't do it, or will be incentivised not to do it. So this class is meant to be an\n",
    "object that manages time series data. It manages it in such a way so that you can spam this\n",
    "all over the place and get lots of functionalities right out of the box, without an external\n",
    "server. All data is stored in several tables inside a sqlite file. Each time series gets its\n",
    "own sqlite file. Some performance numbers to keep in mind:\n",
    "\n",
    "- Data write speed: 100k data points/s\n",
    "- Data read speed:  400k data points/s\n",
    "- Disk space used: 50 bytes/data point for small amounts of variables (say ~3)\n",
    "\n",
    "Other features include the ability to auto delete old data so as not to accumulate over time.\n",
    "When old data is deleted, there's also an option to save the deleted data in a separate file\n",
    "for cold storage, so that it's more efficient storage-wise than sqlite, but harder to access.\n",
    "Cold storage space used: 14 + nVars * 4. This is 5x smaller than sqlite for 3 variables\n",
    "\n",
    "There will be scans every 10 seconds on another thread, that compresses the raw data into a\n",
    "usable form. If there's too few data points (<20 data points), then it will skip that scan\n",
    "cycle. Data (refined and raw) will be saved into a sqlite database, stored at the specified\n",
    "file name ``fn``. If no file name is specified, then this will create a temp file and turn\n",
    "that into a sqlite database.\n",
    "\n",
    "For every method, you can also specify an index number::\n",
    "\n",
    "    ts1 = k1.TimeSeries(name=\"ts1\")\n",
    "    ts1.appendIdx(2, 3, 4, 5) # index 2 with 3 values (3, 4, 5)\n",
    "    \n",
    "    ts1.getRaw(idx=2)  # returns all data points with idx=2, something like [[1737213223.4139452, (3, 4, 5)], ...]\n",
    "    ts1.getPert(idx=2) # returns all percentiles with idx=2, something like [[1737213568.9260075, [(0.009, 0.07, 0.47, 0.89, 0.99), (0.001, 0.11, 0.56, 0.90, 0.99), (0.0006, 0.08, 0.46, 0.89, 0.99)]], ...]\n",
    "\n",
    "This is useful in situations like when you have lots of sensors for different devices. Then\n",
    "each idx can be the device id, and so you can store lots of variables in 1 go for 1 specific\n",
    "device. Then you can query the time series later on for 1 specific device only.\n",
    "\n",
    "You can get all TimeSeries via :meth:`allData`.\n",
    "\n",
    ".. note::\n",
    "\n",
    "    Performance details\n",
    "    \n",
    "    This is a more detailed section going over what actually happens underneath in case you\n",
    "    care about performance. Everything is stored in sqlite. If file name is not given, then\n",
    "    it still uses sqlite, but in memory instead.\n",
    "    \n",
    "    When a new .append() happens, no database interaction happens at all. It's simply just\n",
    "    appended to a totally normal, internal list, so <1us. Then there are 2 background\n",
    "    threads to help collate and store the data. One is fast (10s scan) and one is slow\n",
    "    (60s scan). The fast one distributes new data points to 3 internal stacks, \"rawRaw\",\n",
    "    \"rateRaw\" and \"pertD\". If rawRaw has any elements, it will be stored in sqlite. If\n",
    "    rateRaw has at least 10 elements, it will calculate the rate and store in sqlite. If\n",
    "    pertD (indexed by idx) has at least 100 elements, it will calculate percentiles and\n",
    "    store in sqlite.\n",
    "    \n",
    "    This architecture has several ramifications:\n",
    "    \n",
    "    * Time taken to execute .append() is very fast\n",
    "    * If no .append() are called for a long time, no sqlite queries will be executed\n",
    "    * If too little .append() are called, data might not show up in rate and percentile views at all\n",
    "    * Might have to wait for at least 10 seconds before .getRaw() has the newest data\n",
    "    * If python process exited, there may still be data stored in memory that's not recorded on sqlite yet\n",
    "    \n",
    "    For the second loop, it grabs all rows from sqlite that was longer than ``retention``\n",
    "    seconds ago, compresses them to an efficient binary format, then appends to the cold\n",
    "    storage file. My code is not as bulletproof as sqlite, but still works fine. Because\n",
    "    the loop is very slow, it shouldn't affect performance much.\n",
    "\n",
    ":param name: just for cosmetic, to remind you what this does\n",
    ":param fn: sqlite file name to store this time series data. If not specified, then stores database in memory\n",
    ":param storeRaw: whether to store raw data points\n",
    ":param retention: seconds before deleting old data point permanently, default 1 week\n",
    ":param coldStore: if True, when data points past retention time, it will be\n",
    "    packed into a single binary file for cold storage\"\"\"\n",
    "        if coldStore and fn is None: raise Exception(\"If using cold storage, has to specify file name!\") # TODO: ts1 | aS(repr), ts1 | toHtml()\n",
    "        self._initialized = False; self.name = name or _timeSeriesAutoInc(); self.idx = _timeSeriesIdxAutoInc(); self.fn = fn; self.storeRaw = storeRaw; self.retention = retention; self.coldStore = coldStore; self.dbLock = threading.Lock()\n",
    "        if \"/\" in self.name: raise Exception(\"Can't have forward slash in the name\")\n",
    "        if self.name in _timeSeriesD: raise Exception(f\"Name '{self.name}' has appeared before. Please use a different name\")\n",
    "        self._raw = []; self._rawRaw = []; self._rateRaw = []; _timeSeriesD[self.name] = _timeSeriesID[self.idx] = self; self._setupDb(); self._pertD = collections.defaultdict(lambda: []); self._initialized = True # maps idx -> [time, values]\n",
    "        self._latest = [] # latest values\n",
    "    def _setupDb(self):\n",
    "        fn = self.fn\n",
    "        if fn is not None and os.path.exists(f\"{fn}.db\"): self._s = s = cli.sql(f\"{fn}.db\", mode=\"lite\")[\"default\"]\n",
    "        else: self._s = s = cli.sql(\":memory:\" if fn is None else f\"{fn}.db\", mode=\"lite\")[\"default\"]\n",
    "        s.query(\"CREATE TABLE IF NOT EXISTS rate (id INTEGER PRIMARY KEY AUTOINCREMENT, time INTEGER, rate REAL);\"); s.query(\"CREATE INDEX IF NOT EXISTS rate_time ON rate (time);\"); \n",
    "        s.query(\"CREATE TABLE IF NOT EXISTS raw (id INTEGER PRIMARY KEY AUTOINCREMENT, time INTEGER, idx INTEGER, data BLOB);\"); s.query(\"CREATE INDEX IF NOT EXISTS raw_time ON raw (time);\"); s.query(\"CREATE INDEX IF NOT EXISTS raw_idx ON raw (idx);\"); # .data is struct.pack(\"ffff\", values)\n",
    "        s.query(\"CREATE TABLE IF NOT EXISTS pert (id INTEGER PRIMARY KEY AUTOINCREMENT, time INTEGER, idx INTEGER, data BLOB);\"); s.query(\"CREATE INDEX IF NOT EXISTS pert_time ON pert (time);\"); s.query(\"CREATE INDEX IF NOT EXISTS pert_idx ON pert (idx);\"); # .data is struct.pack of [*n*[0, 10, 50, 90, 100]]\n",
    "        s.query(\"CREATE TABLE IF NOT EXISTS tfs (id INTEGER PRIMARY KEY AUTOINCREMENT, method INTEGER, idx INTEGER, dIdx INTEGER, coeffs BLOB, mplJson TEXT, docs TEXT);\"); s.query(\"CREATE INDEX IF NOT EXISTS tfs_idx ON tfs (idx);\"); s.query(\"CREATE INDEX IF NOT EXISTS tfs_dIdx ON tfs (dIdx);\"); # .data is struct.pack, depending on type, .method is the method to transform (0: linear, y = a*x+b)\n",
    "        while s[\"tfs\"] is None: print(\".\"); time.sleep(0.1) # hangs until tables are created\n",
    "        self._dbRaw = s[\"raw\"]; self._dbRate = s[\"rate\"]; self._dbPert = s[\"pert\"]; self._dbTfs = s[\"tfs\"]\n",
    "    @staticmethod\n",
    "    def allData(): return _timeSeriesD\n",
    "    @staticmethod\n",
    "    def allIData(): return _timeSeriesID\n",
    "    @k1.cache(timeout=10, name=\"ts_idxs\", docs=\"caches k1.TimeSeries idxs, aka all available idx\")\n",
    "    def idxs(self) -> \"list[int]\":\n",
    "        \"\"\"Grabs all available idxs\"\"\"\n",
    "        if self.storeRaw: return [x[0] for x in self._dbRaw.query(\"select distinct idx from raw\")]\n",
    "        return [x[0] for x in self._dbPert.query(\"select distinct idx from pert\")]\n",
    "    @k1.cache(timeout=30, name=\"ts_dIdx\", docs=\"caches k1.TimeSeries dIdx\")\n",
    "    def getDIdx(self, idx:int=0, timeStr:str=\"1 day\", limit:int=10000) -> int:\n",
    "        \"\"\"Grabs all available dIdx of a particular idx in the past 1 day.\n",
    "Internally, this scans for all raw data points and grab the largest length\"\"\"\n",
    "        x = [len(values) for t, values in self.getRaw(*k1.parseTimeStr(timeStr), idx=idx, limit=limit)]\n",
    "        return max(x) if len(x) > 0 else 0\n",
    "    def append(self, *values): sig = \"f\"*len(values); self._raw.append([_time(), 0, values, struct.pack(sig, *values)]); return values\n",
    "    def appendIdx(self, idx, *values): sig = \"f\"*len(values); self._raw.append([_time(), idx, values, struct.pack(sig, *values)]); return values\n",
    "    def getLatest(self, idx:int=0) -> \"float, list[float]\":\n",
    "        \"\"\"Grabs data of current instance that has been committed. Returns something like ``(1737213223.4139452, (3, 4, 5))``. If no data, returns ``(0, [])``\"\"\"\n",
    "        res = self._dbRaw.query(f\"select time, data from raw where idx = {idx} order by id desc limit 1\")\n",
    "        if len(res) == 0: return [0, []]\n",
    "        t, data = res[0]; return [t, struct.unpack((len(data)//4)*\"f\", data)]\n",
    "    def getLatestTf(self, idx:int=0) -> \"float, list[float]\":\n",
    "        res = self._dbRaw.query(f\"select time, data from raw where idx = {idx} order by id desc limit 1\")\n",
    "        if len(res) == 0: return [0, []]\n",
    "        t, data = res[0]; data = struct.unpack((len(data)//4)*\"f\", data)\n",
    "        return [t, [f(x) for x,f in zip(data, [self.getTf(idx, dIdx)[4] for dIdx in range(len(data))])]]\n",
    "    def setTf(self, idx:int=0, dIdx:int=0, method:int=0, coeffs:list[float]=None, mplJson:object=None, docs:str=\"\"):\n",
    "        coeffs = coeffs or [1, 0]; coeffs = struct.pack(len(coeffs)*\"f\", *coeffs); mplJson = json.dumps(mplJson or {}); res = self.getTf(idx, dIdx)\n",
    "        if res[0] is None: self._dbTfs.query(f\"insert into tfs (idx, dIdx, method, coeffs, mplJson, docs) values (?, ?, ?, ?, ?, ?)\", idx, dIdx, method, coeffs, mplJson, docs)\n",
    "        else: self._dbTfs.query(f\"update tfs set idx = ?, dIdx = ?, method = ?, coeffs = ?, mplJson = ?, docs = ? where id = {res[0]}\", idx, dIdx, method, coeffs, mplJson, docs)\n",
    "    @k1.cache(timeout=30, maxsize=300, name=\"ts_getTf\", docs=\"TimeSeries.getTf() cache\")\n",
    "    def getTf(self, idx:int=0, dIdx:int=0):\n",
    "        res = self._dbTfs.query(f\"select id, method, coeffs, mplJson, docs from tfs where idx = ? and dIdx = ?\", idx, dIdx)\n",
    "        if len(res) == 0: return [None, 0, [1, 0], {}, lambda x: x, \"\"]\n",
    "        tfId, method, coeffs, mplJson, docs = res[0]; f = lambda x: x\n",
    "        if method == 0: coeffs = struct.unpack(\"ff\", coeffs); a, b = coeffs; f = lambda x: x*a+b\n",
    "        return tfId, method, list(coeffs), json.loads(mplJson), f, docs\n",
    "    def getRaw(self, startTime:int=None, stopTime:int=None, idx:int=0, limit:int=1000_000):\n",
    "        \"\"\"Grabs raw data of this time series. Returns something like ``[[1737213223.4139452, (3, 4, 5)], ...]`` \"\"\"\n",
    "        if not self.storeRaw: raise Exception(\".storeRaw is False, so all raw data has been deleted\")\n",
    "        s = f\"select time, data from raw where true\"\n",
    "        if idx != \"all\": s += f\" and idx = {idx}\"\n",
    "        if startTime: s += f\" and time >= {startTime}\"\n",
    "        if stopTime:  s += f\" and time <  {stopTime}\"\n",
    "        s += f\" order by time limit {limit}\"; data = self._dbRaw.query(s)\n",
    "        if len(data) == 0: return []\n",
    "        s = (len(data[0][1])//4)*\"f\"; res = []\n",
    "        try: # fast way, caches \"s\" computation\n",
    "            for t, vs in data: res.append([t, struct.unpack(s, vs)])\n",
    "        except: # slow way, in case number of variables are different\n",
    "            for t, vs in data: res.append([t, struct.unpack((len(vs)//4)*\"f\", vs)])\n",
    "        return res\n",
    "    def getRawTf(self, startTime:int=None, stopTime:int=None, idx:int=0, limit:int=1000_000):\n",
    "        \"\"\"Grabs transformed data of this time series. Returns something like ``[[1737213223.4139452, (3, 4, 5)], ...]`` \"\"\"\n",
    "        if not self.storeRaw: raise Exception(\".storeRaw is False, so all raw data has been deleted\")\n",
    "        res = self.getRaw(startTime, stopTime, idx, limit); maxVars = max(len(x[1]) for x in res) if len(res) else 0; tfFs = [self.getTf(idx, i)[4] for i in range(maxVars)]\n",
    "        for t, values in res: yield t, [f(x) for x,f in zip(values, tfFs)]\n",
    "    def getRate(self, startTime:int=None, stopTime:int=None, limit:int=10000):\n",
    "        \"\"\"Grabs data ingest rate of this time series. Returns something like ``[(1737213313.0752494, 10.066128035852211), ...]``\"\"\"\n",
    "        s = f\"select time, rate from rate where true\"\n",
    "        if startTime: s += f\" and time >= {startTime}\"\n",
    "        if stopTime:  s += f\" and time  <  {stopTime}\"\n",
    "        s += f\" order by time limit {limit}\"; data = self._dbRate.query(s)\n",
    "        return data\n",
    "    def getPert(self, startTime:int=None, stopTime:int=None, idx:int=0, limit:int=10000):\n",
    "        \"\"\"Grabs data percentiles of this time series. Returns something like ``[[1737213568.9260075, [(0.009, 0.07, 0.47, 0.89, 0.99), (0.001, 0.11, 0.56, 0.90, 0.99), (0.0006, 0.08, 0.46, 0.89, 0.99)]], ...]``\"\"\"\n",
    "        def _batched(x): return [x[5*i:5*(i+1)] for i in range(len(x)//5)]\n",
    "        s = f\"select time, data from pert where idx = {idx}\"\n",
    "        if startTime: s += f\" and time >= {startTime}\"\n",
    "        if stopTime:  s += f\" and time <  {stopTime}\"\n",
    "        s += f\" order by time limit {limit}\"; data = self._dbPert.query(s)\n",
    "        if len(data) == 0: return []\n",
    "        nvars = len(data[0][1])//4; s = nvars*\"f\"; res = []\n",
    "        try: # fast way, caches \"s\" computation\n",
    "            for t, vs in data: x = struct.unpack(s, vs); res.append([t, [x[5*i:5*(i+1)] for i in range(nvars//5)]])\n",
    "        except: # slow way, in case number of variables are different between lines\n",
    "            for t, vs in data: x = struct.unpack((len(vs)//4)*\"f\", vs); res.append([t, [x[5*i:5*(i+1)] for i in range(len(x)//5)]])\n",
    "        return res\n",
    "    def _ls(self): return self.getRaw(limit=100)\n",
    "    @k1.cache(timeout=60, maxsize=1000, name=\"ts_len\", docs=\"caches k1.TimeSeries lengths\")\n",
    "    def __len__(self):\n",
    "        if not self.storeRaw: raise Exception(f\"TimeSeries '{self.name}'.storeRaw is False, no length available\")\n",
    "        res = self._dbRaw.query(\"\"\"select max(id) from raw limit 1;\"\"\"); return res[0][0] if len(res) > 0 else 0\n",
    "    def __repr__(self): return f\"<TimeSeries name='{self.name}' fn='{self.fn}' storeRaw={self.storeRaw} retention={self.retention} coldStore={self.coldStore}>\"\n",
    "    def plotRaw(self, startTime:float, stopTime:float, idx:int=0, dIdx:\"int|str\"=\"all\", window:int=1):\n",
    "        import matplotlib.pyplot as plt; s = self; data = s.getRaw(startTime, stopTime, idx=idx) | ~cli.apply(lambda x,y: [[x, e] for e in y]) | cli.T() | cli.apply(cli.T() | (cli.apply(cli.window(10) | cli.toMean().all()) if window > 1 else cli.iden())) | cli.deref()\n",
    "        with k1.mplLock:\n",
    "            if len(data) == 0: return \"No data available\"\n",
    "            if dIdx == \"all\": data | cli.apply(~cli.aS(plt.dplot, 7, True, \".-\")) | cli.ignore()\n",
    "            else: data | cli.rItem(dIdx) | ~cli.aS(plt.dplot, 7, True, \".-\")\n",
    "            plt.title(f\"Raw '{self.name}', idx {idx}, dIdx {dIdx}, window {window}\"); plt.tight_layout(); im = plt.gcf() | cli.toImg()\n",
    "        return im | cli.toHtml()\n",
    "    @staticmethod\n",
    "    def splotRaw(name:str, startTime:float, stopTime:float, idx:int=0, dIdx:\"int|str\"=\"all\", window:int=1):\n",
    "        d = k1.TimeSeries.allData(); s = d.get(name, None)\n",
    "        if s is None: return f\"No TimeSeries with the name '{name}' found\"\n",
    "        return s.plotRaw(startTime, stopTime, idx=idx, dIdx=dIdx, window=window)\n",
    "    def plotRawTf(self, startTime:float, stopTime:float, idx:int=0, dIdx:\"int|str\"=\"all\", window:int=1):\n",
    "        import matplotlib.pyplot as plt; s = self; data = s.getRawTf(startTime, stopTime, idx=idx) | ~cli.apply(lambda x,y: [[x, e] for e in y]) | cli.T() | cli.apply(cli.T() | (cli.apply(cli.window(10) | cli.toMean().all()) if window > 1 else cli.iden())) | cli.deref()\n",
    "        with k1.mplLock:\n",
    "            if len(data) == 0: return \"No data available\"\n",
    "            if dIdx == \"all\":\n",
    "                data | cli.apply(~cli.aS(plt.dplot, 7, True, \".-\")) | cli.ignore()\n",
    "                plt.title(f\"Raw tf '{self.name}', idx {idx}, dIdx {dIdx}, window {window}\")\n",
    "            else:\n",
    "                data | cli.rItem(dIdx) | ~cli.aS(plt.dplot, 7, True, \".-\"); tfId, method, coeffs, mplJson, f, docs = self.getTf(idx, dIdx)\n",
    "                if mplJson.get(\"header\", None): plt.title(mplJson[\"header\"])\n",
    "                if mplJson.get(\"ylabel\", None): plt.ylabel(mplJson[\"ylabel\"])\n",
    "                if mplJson.get(\"xlabel\", None): plt.ylabel(mplJson[\"xlabel\"])\n",
    "            plt.tight_layout(); im = plt.gcf() | cli.toImg()\n",
    "        return im | cli.toHtml()\n",
    "    @staticmethod\n",
    "    def splotRawTf(name:str, startTime:float, stopTime:float, idx:int=0, dIdx:\"int|str\"=\"all\", window:int=1):\n",
    "        d = k1.TimeSeries.allData(); s = d.get(name, None)\n",
    "        if s is None: return f\"No TimeSeries with the name '{name}' found\"\n",
    "        return s.plotRawTf(startTime, stopTime, idx=idx, dIdx=dIdx, window=window)\n",
    "    def plotRate(self, startTime:float, stopTime:float, window:int=1):\n",
    "        import matplotlib.pyplot as plt; s = self; data = s.getRate(startTime, stopTime) | (cli.T.wrap(cli.apply(cli.window(window) | cli.toMean().all())) if window > 1 else cli.iden()) | cli.T() | cli.deref()\n",
    "        with k1.mplLock:\n",
    "            if len(data) == 0: return \"No data available\"\n",
    "            data | ~cli.aS(plt.dplot, 7, True, \".-\"); plt.xlabel(\"Time\"); plt.ylabel(\"Rate (calls/s)\"); plt.title(f\"Rate '{self.name}', window {window}\"); plt.tight_layout(); im = plt.gcf() | cli.toImg()\n",
    "        return im | cli.toHtml()\n",
    "    @staticmethod\n",
    "    def splotRate(name:str, startTime:float, stopTime:float, window:int=1):\n",
    "        d = k1.TimeSeries.allData(); s = d.get(name, None)\n",
    "        if s is None: return f\"No TimeSeries with the name '{name}' found\"\n",
    "        return s.plotRate(startTime, stopTime, window=window)\n",
    "    def plotPert(self, startTime:float, stopTime:float, idx:int=0, dIdx:\"int|str\"=0, window:int=1):\n",
    "        import matplotlib.pyplot as plt; s = self; data = s.getPert(startTime, stopTime, idx) | cli.apply(lambda x: x[dIdx], 1) | ~cli.apply(lambda x,y: [[x, e] for e in y]) | cli.T() | cli.apply(cli.T() | (cli.apply(cli.window(window) | cli.toMean().all()) if window > 1 else cli.iden())) | cli.deref()\n",
    "        with k1.mplLock:\n",
    "            if len(data) == 0: return \"No data available\"\n",
    "            data | cli.apply(~cli.aS(plt.dplot, 7, True, \".-\")) | cli.ignore(); plt.legend([\"0%\", \"10%\", \"50%\", \"90%\", \"100%\"]); plt.xlabel(\"Time\"); plt.ylabel(\"Value\"); plt.title(f\"Percentile '{self.name}', idx {idx}, dIdx {dIdx}, window {window}\"); plt.tight_layout(); im = plt.gcf() | cli.toImg()\n",
    "        return im | cli.toHtml()\n",
    "    @staticmethod\n",
    "    def splotPert(name:str, startTime:float, stopTime:float, idx:int=0, dIdx:int=0, window:int=1):\n",
    "        d = k1.TimeSeries.allData(); s = d.get(name, None)\n",
    "        if s is None: return f\"No TimeSeries with the name '{name}' found\"\n",
    "        return s.plotPert(startTime, stopTime, idx=idx, dIdx=dIdx, window=window)\n",
    "    @staticmethod\n",
    "    def flask(app, **kwargs):\n",
    "        \"\"\"Attaches a TimeSeries management plane to a flask app.\n",
    "Example::\n",
    "\n",
    "    app = flask.Flask(__name__)\n",
    "    k1.TimeSeries.flask(app)\n",
    "    app.run(host=\"0.0.0.0\", port=80)\n",
    "\n",
    "Then, you can access the route \"/k1/ts\" to see an overview of all TimeSeries\n",
    "\n",
    ":param app: flask app object\n",
    ":param kwargs: extra random kwargs that you want to add to ``app.route()`` function\"\"\"\n",
    "        bootstrapJs = \"\"\"\n",
    "async function dynamicLoad(selector, endpoint, rawHtml=null) { // loads a remote endpoint containing html and put it to the selected element. If .rawHtml is available, then don't send any request, and just use that html directly\n",
    "    const elem = document.querySelector(selector); elem.innerHTML = rawHtml ? rawHtml : (await (await fetch(endpoint)).text());\n",
    "    await new Promise(r => setTimeout(r, 100)); let currentScript = \"\";\n",
    "    try { for (const script of elem.getElementsByTagName(\"script\")) { currentScript = script.innerHTML; eval(script.innerHTML); }\n",
    "    } catch (e) { console.log(`Error encountered: `, e, e.stack, currentScript); }\n",
    "}\"\"\"; bootstrapHtml = f\"\"\"\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\"><title>DHCP low level server</title><meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <link href=\"https://static.aigu.vn/daisyui.css\" rel=\"stylesheet\" type=\"text/css\" />\n",
    "    <style>\n",
    "        h1 {{ font-size: 2.25rem !important; line-height: 2.5rem !important; }}\n",
    "        h2 {{ font-size: 1.5rem !important; line-height: 2rem !important; margin: 10px 0px !important; }}\n",
    "        h3 {{ font-size: 1.125rem !important; line-height: 1.75rem !important; margin: 6px 0px !important; }}\n",
    "        textarea {{ border: 1px solid; padding: 8px 12px !important; border-radius: 10px !important; }}\n",
    "        body {{ padding: 12px; }}\n",
    "    </style><script>{bootstrapJs}</script>\n",
    "</head>\"\"\"; tss = k1.TimeSeries.allData()\n",
    "        # time series stuff\n",
    "        @app.route(\"/k1/ts\", **kwargs)\n",
    "        def k1_ts_index():\n",
    "            pre = cli.init._jsDAuto(); ui1 = tss.items() | ~cli.apply(lambda k,v: [k, v.fn, v.storeRaw, v.retention, v.coldStore, v | (cli.tryout() | cli.aS(len))]) | cli.deref() | (cli.toJsFunc(\"term\") | cli.grep(\"${term}\") | k1.viz.Table([\"name\", \"fn\", \"storeRaw\", \"retention\", \"coldStore\", \"#hits\"], height=600, onclickFName=f\"{pre}_select\", selectable=True, sortF=True)) | cli.op().interface() | cli.toHtml()\n",
    "            return f\"\"\"{bootstrapHtml}<h1>TimeSeries</h1><div style=\"overflow-x: auto; margin-top: 12px\">{ui1}</div><div id=\"{pre}_details\"></div>\n",
    "    <script>\\nfunction {pre}_select(row, i, e) {{ dynamicLoad(\"#{pre}_details\", `/k1/ts/fragment/${{row[0]}}`); }}</script>\"\"\"\n",
    "        @app.route(\"/k1/ts/fragment/<name>\", **kwargs)\n",
    "        def k1_ts_fragment_overview(name):\n",
    "            \"\"\"Gets overview of a particular TimeSeries\"\"\"\n",
    "            s = tss.get(name, None)\n",
    "            if s is None: return f\"No TimeSeries '{name}' found\"\n",
    "            idxs = s.idxs(); pre = cli.init._jsDAuto(); ui1 = idxs | cli.wrapList().all() | (cli.toJsFunc(\"idx\") | cli.grep(\"${idx}\") | k1.viz.Table(sortF=True, onclickFName=f\"{pre}_selectIdx\", height=400, selectable=True)) | cli.op().interface() | cli.toHtml(); return f\"\"\"\n",
    "<h2>TimeSeries '{s.name}'</h2><div style=\"border: 1px solid black; padding: 8px\">{ui1}</div>\n",
    "<div id=\"{pre}_details\"></div><script>function {pre}_selectIdx(row, i, e) {{ document.querySelector(\"#{pre}_details\").innerHTML = \"(loading...)\"; dynamicLoad(\"#{pre}_details\", `/k1/ts/fragment/{name}/${{row[0]}}`); }}</script>\"\"\"\n",
    "        @app.route(\"/k1/ts/fragment/<name>/<int:idx>\", **kwargs)\n",
    "        def k1_ts_fragment_idx_overview(name, idx:int):\n",
    "            pre = cli.init._jsDAuto(); s = tss.get(name, None)\n",
    "            if s is None: return f\"No TimeSeries '{name}' found\"\n",
    "            t, values = s.getLatestTf(idx); values = {i:x for i,x in enumerate(values)}\n",
    "            ui1 = range(s.getDIdx(idx)) | cli.apply(lambda dIdx: [dIdx, *s.getTf(idx, dIdx), values.get(dIdx, None)]) | cli.cut(0, 2, 3, 4, 6, 7) | (cli.aS(str) | cli.aS(html.escape)).all(2) | (cli.toJsFunc(\"term\") | cli.grep(\"${term}\") | k1.viz.Table([\"dIdx\", \"method\", \"coeff\", \"mplJson\", \"docs\", \"latest tf value\"], onclickFName=f\"{pre}_selectDIdx\", selectable=True, height=400)) | cli.op().interface() | cli.toHtml(); return f\"\"\"\n",
    "<h3>idx {idx}</h3><div style=\"border: 1px solid black; padding: 8px\">{ui1}</div>\n",
    "<div id=\"{pre}_details\"></div><script>function {pre}_selectDIdx(row, i, e) {{ document.querySelector(\"#{pre}_details\").innerHTML = \"(loading...)\"; dynamicLoad(\"#{pre}_details\", `/k1/ts/fragment/{name}/{idx}/${{row[0]}}`) }}</script>\"\"\"\n",
    "        @app.route(\"/k1/ts/fragment/<name>/<int:idx>/<int:dIdx>\", **kwargs)\n",
    "        def k1_ts_fragment_idx_dIdx_overview(name, idx:int, dIdx:int):\n",
    "            pre = cli.init._jsDAuto(); s = tss.get(name, None)\n",
    "            if s is None: return f\"No TimeSeries '{name}' found\"\n",
    "            tfId, method, coeffs, mplJson, f, docs = s.getTf(idx, dIdx); return f\"\"\"\n",
    "<h3>dIdx {dIdx}</h3>\n",
    "<div>Transform</div>\n",
    "<div style=\"display: grid; grid-template-columns: auto auto; row-gap: 8px; column-gap: 8px; align-items: center; margin-top: 12px; width: fit-content\">\n",
    "    <div>method: </div><input id=\"{pre}_method\" class=\"input input-bordered\" value=\"{method}\" />\n",
    "    <div>coeffs: </div><input id=\"{pre}_coeffs\" class=\"input input-bordered\" value=\"{coeffs}\" />\n",
    "    <div>mplJson: </div><textarea id=\"{pre}_mplJson\" class=\"textarea textarea-bordered\">{json.dumps(mplJson, ensure_ascii=False)}</textarea>\n",
    "    <div>docs: </div><textarea id=\"{pre}_docs\" class=\"textarea textarea-bordered\">{docs}</textarea>\n",
    "</div><button id=\"{pre}_saveTfBtn\" class=\"btn\" style=\"margin-top: 8px\">Save transform</button>\n",
    "<div>Plots</div>\n",
    "<div style=\"display: grid; grid-template-columns: auto auto; row-gap: 8px; column-gap: 8px; align-items: center; margin-top: 12px; width: fit-content\">\n",
    "    <div>timeStr: </div><input id=\"{pre}_timeStr\" class=\"input input-bordered\" value=\"1 day\" />\n",
    "    <div>window: </div><input id=\"{pre}_window\" class=\"input input-bordered\" value=\"1\" />\n",
    "</div><div style=\"margin: 8px 0px\">\n",
    "    <button id=\"{pre}_graphBtn\" class=\"btn\">Graph</button>\n",
    "    <button id=\"{pre}_rawBtn\" class=\"btn\" style=\"margin-left: 8px\">View raw</button>\n",
    "    <button id=\"{pre}_rawTfBtn\" class=\"btn\" style=\"margin-left: 8px\">View raw transformed</button>\n",
    "</div>\n",
    "<div id=\"{pre}_detailsRawTf\">{k1_ts_fragment_idx_rawTf(name, idx, dIdx, 1, '1 day')}</div>\n",
    "<div id=\"{pre}_detailsRate\">{k1_ts_fragment_idx_rate(name, 1, '1 day')}</div>\n",
    "<div id=\"{pre}_detailsPert\">{k1_ts_fragment_idx_pert(name, 1, dIdx, 1, '1 day')}</div>\n",
    "<div id=\"{pre}_rawRaw\"></div><script>\n",
    "    (async () => {{\n",
    "        let dS = (x) => document.querySelector(x); dS(\"#{pre}_graphBtn\").onclick = async () => {{\n",
    "            let window = dS(\"#{pre}_window\").value; let timeStr = dS(\"#{pre}_timeStr\").value;\n",
    "            dS(\"#{pre}_detailsRawTf\").innerHTML= \"(loading...)\"; dynamicLoad(\"#{pre}_detailsRawTf\",`/k1/ts/fragment/{name}/{idx}/rawTf/{dIdx}/${{window}}/${{timeStr}}`);\n",
    "            dS(\"#{pre}_detailsRate\").innerHTML = \"(loading...)\"; dynamicLoad(\"#{pre}_detailsRate\", `/k1/ts/fragment/{name}/0/rate/0/${{window}}/${{timeStr}}`);\n",
    "            dS(\"#{pre}_detailsPert\").innerHTML = \"(loading...)\"; dynamicLoad(\"#{pre}_detailsPert\", `/k1/ts/fragment/{name}/{idx}/pert/{dIdx}/${{window}}/${{timeStr}}`);\n",
    "        }}; dS(\"#{pre}_rawBtn\").onclick = async () => {{ let timeStr = dS(\"#{pre}_timeStr\").value; window.open(`/k1/ts/api/{name}/{idx}/raw/${{timeStr}}`, \"_blank\"); }};\n",
    "        dS(\"#{pre}_rawTfBtn\").onclick = async () => {{ let timeStr = dS(\"#{pre}_timeStr\").value; window.open(`/k1/ts/api/{name}/{idx}/rawTf/${{timeStr}}`, \"_blank\"); }};\n",
    "        dS(\"#{pre}_saveTfBtn\").onclick = async () => {{\n",
    "            await fetch(\"/k1/ts/api/{name}/{idx}/{dIdx}/saveTf\", {{ method: \"POST\", headers: {{ \"Content-Type\": \"application/json\" }}, body: JSON.stringify({{ method: dS(\"#{pre}_method\").value, coeffs: dS(\"#{pre}_coeffs\").value, mplJson: dS(\"#{pre}_mplJson\").value, docs: dS(\"#{pre}_docs\").value }}) }}); alert(\"Saved!\"); }}\n",
    "    }})();\n",
    "</script>\"\"\"\n",
    "        @app.route(\"/k1/ts/api/<name>/<int:idx>/<int:dIdx>/saveTf\", methods=[\"POST\"], **kwargs)\n",
    "        def k1_ts_api_idx_dIdx_saveTf(name, idx, dIdx):\n",
    "            from flask import request; js = request.json; pre = cli.init._jsDAuto(); s = tss.get(name, None)\n",
    "            if s is None: return f\"No TimeSeries '{name}' found\"\n",
    "            s.setTf(idx, dIdx, method=int(js[\"method\"]), coeffs=json.loads(js[\"coeffs\"]), mplJson=json.loads(js[\"mplJson\"]), docs=js[\"docs\"]); return \"ok\"\n",
    "        @app.route(\"/k1/ts/api/<name>/<int:idx>/latest\", **kwargs)\n",
    "        def k1_ts_api_idx_latest(name, idx):\n",
    "            \"\"\"Returns latest raw data, looks like [timestamp, [v1, v2, v3, ...]]\"\"\"\n",
    "            d = k1.TimeSeries.allData(); s = d.get(name, None); return f\"No TimeSeries with the name '{name}' found\" if s is None else s.getLatest(idx)\n",
    "        @app.route(\"/k1/ts/api/<name>/<int:idx>/latestTf\", **kwargs)\n",
    "        def k1_ts_api_idx_latestTf(name, idx):\n",
    "            \"\"\"Returns latest transformed data, looks like [timestamp, [v1, v2, v3, ...]]\"\"\"\n",
    "            d = k1.TimeSeries.allData(); s = d.get(name, None); return f\"No TimeSeries with the name '{name}' found\" if s is None else s.getLatestTf(idx)\n",
    "        @app.route(\"/k1/ts/api/<name>/<int:idx>/raw/<timeStr>\", **kwargs)\n",
    "        def k1_ts_api_idx_raw(name, idx, timeStr):\n",
    "            \"\"\"Returns raw data and present it in a pre\"\"\"\n",
    "            d = k1.TimeSeries.allData(); s = d.get(name, None)\n",
    "            if s is None: return f\"No TimeSeries with the name '{name}' found\"\n",
    "            return s.getRaw(*k1.parseTimeStr(timeStr), idx=idx)\n",
    "        @app.route(\"/k1/ts/fragment/<name>/<int:idx>/raw/<dIdx>/<int:window>/<timeStr>\", **kwargs)\n",
    "        def k1_ts_fragment_idx_raw(name, idx, dIdx, window, timeStr):\n",
    "            \"\"\"Plots raw data\"\"\"\n",
    "            return k1.TimeSeries.splotRaw(name, *k1.parseTimeStr(timeStr), idx, \"all\" if dIdx == \"all\" else int(dIdx), window)\n",
    "        @app.route(\"/k1/ts/api/<name>/<int:idx>/rawTf/<timeStr>\", **kwargs)\n",
    "        def k1_ts_api_idx_rawTf(name, idx, timeStr):\n",
    "            \"\"\"Returns raw data and present it in a pre\"\"\"\n",
    "            d = k1.TimeSeries.allData(); s = d.get(name, None)\n",
    "            if s is None: return f\"No TimeSeries with the name '{name}' found\"\n",
    "            return list(s.getRawTf(*k1.parseTimeStr(timeStr), idx=idx))\n",
    "        @app.route(\"/k1/ts/fragment/<name>/<int:idx>/rawTf/<dIdx>/<int:window>/<timeStr>\", **kwargs)\n",
    "        def k1_ts_fragment_idx_rawTf(name, idx, dIdx, window, timeStr):\n",
    "            \"\"\"Plots transformed data data\"\"\"\n",
    "            return k1.TimeSeries.splotRawTf(name, *k1.parseTimeStr(timeStr), idx, \"all\" if dIdx == \"all\" else int(dIdx), window)\n",
    "        @app.route(\"/k1/ts/fragment/<name>/0/rate/0/<int:window>/<timeStr>\", **kwargs)\n",
    "        def k1_ts_fragment_idx_rate(name, window, timeStr):\n",
    "            \"\"\"Plots call rate graph\"\"\"\n",
    "            return k1.TimeSeries.splotRate(name, *k1.parseTimeStr(timeStr), window)\n",
    "        @app.route(\"/k1/ts/fragment/<name>/<int:idx>/pert/<dIdx>/<int:window>/<timeStr>\", **kwargs)\n",
    "        def k1_ts_fragment_idx_pert(name, idx, dIdx, window, timeStr):\n",
    "            \"\"\"Plots percentile graph\"\"\"\n",
    "            if dIdx == \"all\": return \"(Only available with specific dIdx)\"\n",
    "            return k1.TimeSeries.splotPert(name, *k1.parseTimeStr(timeStr), idx, int(dIdx), window)\n",
    "    def dummyLoad(self, niter=600, frac=0.1):\n",
    "        \"\"\"Simulates a dummy load on this time series. Read source of\n",
    "this method to understand what it does.\n",
    "\n",
    ":param niter: number of iterations\n",
    ":param frac: fraction of new random numbers and extra time to wait. 0 for more deterministic, 1 for more chaotic\"\"\"\n",
    "        a = random.random(); b = random.random(); c = random.random()\n",
    "        for i in range(niter) | cli.tee().crt():\n",
    "            a += (random.random()-0.5)*frac; b += (random.random()-0.5)*frac; c += (random.random()-0.5)*frac\n",
    "            self.append(a, b, c); print(self.getRaw() | cli.shape(0), end=\"\"); time.sleep(0.1 + random.random()*frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09ac93b1-3c53-4689-9bba-30adbb36f4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@k1.cron(delay=11, daemon=True, delayedStart=5, name=\"ts_main\", docs=\"k1.TimeSeries fast scan thread\")\n",
    "def _timeSeriesThread():\n",
    "    for idx, ts in _timeSeriesD.items():\n",
    "        if not ts._initialized: continue\n",
    "        now = time.time() # raw format: [time, idx, values, pack values]\n",
    "        if len(ts._raw) > 0: # transfer new raw data to other buffers to be processed later\n",
    "            _raw = ts._raw; ts._raw = []; ts._rateRaw.extend(_raw); ts._rawRaw.extend(_raw)\n",
    "            for t,idx,vs,hvs in _raw: ts._pertD[idx].append([t, vs])\n",
    "        n = len(ts._rateRaw)\n",
    "        if n > 10: # at least 10 data points before collating, or 60 seconds passed and no more data\n",
    "            _rateRaw = ts._rateRaw; ts._rateRaw = []\n",
    "            _max = max(x[0] for x in _rateRaw); _min = min(x[0] for x in _rateRaw); deltaT = _max - _min\n",
    "            ts._dbRate.insert(time=_min, rate=len(_rateRaw)/deltaT)\n",
    "        for idx, tvs in list(ts._pertD.items()):\n",
    "            if len(tvs) > 100:\n",
    "                ts._pertD[idx] = []; n = len(tvs); data = tvs | cli.cut(1) | cli.T() | cli.sort(None).all() | cli.apply(lambda vs: [vs[0], vs[n//10], vs[n//2], vs[9*n//10], vs[-1]]) | cli.joinSt() | cli.aS(list)\n",
    "                ts._dbPert.insert(time=tvs[0][0], idx=idx, data=struct.pack(\"f\"*len(data), *data))\n",
    "        if ts.storeRaw and len(ts._rawRaw) > 0:\n",
    "            rr = ts._rawRaw; ts._rawRaw = []\n",
    "            ts._dbRaw.query(f\"\"\"INSERT INTO raw ( time, idx, data ) VALUES \"\"\" + \", \".join(f\"({t}, {idx}, ?)\" for t,idx,vs,hvs in rr), *[hvs for t,idx,vs,hvs in rr])\n",
    "@k1.cron(delay=61, daemon=True, delayedStart=11, name=\"ts_retention\", docs=\"k1.TimeSeries slow scan thread for retention control\")\n",
    "def _timeSeriesRetentionThread(): # scans to see whether there's old outdated data in sqlite, and delete them and store in cold storage\n",
    "    for idx, ts in list(_timeSeriesD.items()):\n",
    "        if not ts._initialized: continue\n",
    "        if ts._dbRaw is None: print(f\"TS retention thread: {ts.name} does not have _dbRaw!\"); continue\n",
    "        now = time.time(); data = ts._dbRaw.query(\"select time from raw order by time limit 1\")\n",
    "        if len(data) == 0: continue\n",
    "        beginTime = data[0][0]\n",
    "        if now - beginTime > ts.retention:\n",
    "            t = now - ts.retention # timestamp to slice off\n",
    "            if ts.coldStore: data = ts._dbRaw.query(f\"select time, idx, data from raw where time < {t} order by time\")\n",
    "            ts._dbRaw .query(f\"delete from raw  where time < {t}\"); ts._dbPert.query(f\"delete from pert where time < {t}\"); ts._dbRate.query(f\"delete from rate where time < {t}\")\n",
    "            if ts.coldStore: data | ~cli.apply(lambda t,idx,data: struct.pack(\"di\", t, idx) + data) | cli.apply(lambda x: b\"\\x00\" + struct.pack(\"B\", len(x)+2) + x) >> cli.file(f\"{ts.fn}.cold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68e4ad8c-a340-4bf6-ade3-f8a8351f3a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599) 599, 60s elapsed, throughput: 9.85 /s(558, 2)                       (0,)     (0,)                                                                      (15, 2)                              (15, 2)                                   (15, 2)                                                                           (15, 2)     (15, 2)                                                                                                                                                           (125, 2)                                                                 (125, 2)                    (125, 2)                                                                                                                                  (233, 2)                                                                                                                             (233, 2)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         (450, 2)                                                                                                                                                                                              "
     ]
    }
   ],
   "source": [
    "#notest\n",
    "import random\n",
    "s1 = TimeSeries(name=\"s1\", retention=60)\n",
    "for i in range(600) | cli.tee().crt():\n",
    "    s1.append(random.random(), random.random(), random.random())\n",
    "    print(s1.getRaw() | cli.shape(), end=\"\")\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b024da1a-2f8a-4160-bcbc-08095be9a008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(232, 2)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#notest\n",
    "while True: print(s1.getRaw() | cli.shape(), end=\"\\r\"); time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbecfef-4d87-42f2-a016-a6adac40457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_speedAutoInc = k1.AutoIncrement(prefix=\"_k1_speed_\"); _speedData = {} # Dict[idx -> {name, mod, fn, raw, refined}]\n",
    "class speed(cli.BaseCli):\n",
    "    def __init__(self, name=None, fn=None, docs=None, coldStore=False):\n",
    "        \"\"\"Tracks and benchmarks certain functions, and monitor them through time\n",
    "with reports in order to deploy them absolutely everywhere. Example::\n",
    "\n",
    "    @k1.speed(name=\"some func description\")\n",
    "    def f(x):\n",
    "        return x*3\n",
    "\n",
    "You can get a list of all speed k1.TimeSeries objects via ``k1.TimeSeries.allData``\n",
    "\n",
    ":param name: optional name to show up in :meth:`allData`\n",
    ":param fn: file name. If specified, will store speed data in sqlite database\n",
    "    at this path, else store in memory\n",
    ":param docs: optional docs to show up in :meth:`allData`\n",
    ":param coldStore: if True, stores old speed data in condensed binary file. See more at :class:`TimeSeries`\"\"\"\n",
    "        self.name = name or _speedAutoInc(); self.fn = fn; self.docs = docs; self.coldStore = coldStore\n",
    "        if \"/\" in self.name: raise Exception(\"Can't have forward slash in the name\")\n",
    "    def __call__(self, f):\n",
    "        if self.name in _speedData: raise Exception(f\"Name '{self.name}' has appeared before. Please use a different name\")\n",
    "        _speedData[self.name] = self.obj = {\"name\": self.name, \"docs\": self.docs, \"func\": f, \"ts\": k1.TimeSeries(name=f\"speed: {self.name}\", fn=self.fn, coldStore=self.coldStore)}\n",
    "        ts = self.obj[\"ts\"]; _time = time.time\n",
    "        def wrapper(*args, **kwargs): beginTime = _time(); res = f(*args, **kwargs); duration = _time() - beginTime; ts.append(duration); return res\n",
    "        functools.update_wrapper(wrapper, f); return wrapper\n",
    "    @staticmethod\n",
    "    def allData(): return _speedData\n",
    "    @staticmethod\n",
    "    def flask(app, **kwargs):\n",
    "        \"\"\"Attaches a speed management plane to a flask app.\n",
    "Example::\n",
    "\n",
    "    app = flask.Flask(__name__)\n",
    "    k1.speed.flask(app)\n",
    "    app.run(host=\"0.0.0.0\", port=80)\n",
    "\n",
    "Then, you can access the route \"/k1/speed\" to see an overview of all speed\n",
    "benchmarks. However, doing ``k1.TimeSeries.flask(app)`` and access at \"/k1/ts\"\n",
    "would be more beneficial, as that contains all the graphs and data\n",
    "\n",
    ":param app: flask app object\n",
    ":param kwargs: extra random kwargs that you want to add to ``app.route()`` function\"\"\"\n",
    "        @app.route(\"/k1/speed\", **kwargs)\n",
    "        def k1_speed_index():\n",
    "            d = k1.speed.allData(); ui1 = d.items() | ~cli.apply(lambda k,v: [k, v[\"func\"].__name__, inspect.getfile(v[\"func\"]), v[\"ts\"].name, v[\"docs\"]]) | cli.deref() | (cli.toJsFunc(\"term\") | cli.grep(\"${term}\") | k1.viz.Table([\"name\", \"func's name\", \"func's file name\", \"TimeSeries name\", \"docs\"], height=600, sortF=True)) | cli.op().interface() | cli.toHtml()\n",
    "            return f\"\"\"<h1>Speed</h1><div style=\"overflow-x: auto\">{ui1}</div>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cc7757f4-ceee-47bf-8bb9-9199f767b7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@contextlib.contextmanager\n",
    "def idenContext(): yield True\n",
    "_cextMods = {}; k1.settings.add(\"cExt\", k1.Settings().add(\"includes\", [\"fstream\", \"iostream\", \"sstream\", \"mutex\", \"string\", \"vector\", \"cmath\", \"random\"], \"header files to include\"), \"k1.compileCExt()-related settings\");\n",
    "def compileCExt(cppCode, moduleName, verbose=False):\n",
    "    \"\"\"Conveniently compiles a python C extension module and returns it.\n",
    "Example::\n",
    "\n",
    "    mod = k1.compileCExt(\\\"\\\"\\\"\n",
    "        // pure math func, simple data types\n",
    "        double func1(double x) { for (int i = 0; i < 1000000; i++) x = std::cos(x); return x; }\n",
    "        // takes in array\n",
    "        double func2(std::vector<double>& arr) { double sum = 0; for (auto v : arr) sum += v; return sum; }\n",
    "        // returns array\n",
    "        std::vector<int> func3(int x, int n) { std::vector<int> ans; for (int i = 0; i < n; i++) ans.push_back(x+i); return ans; }\n",
    "        // nested arrays\n",
    "        std::vector<std::vector<int>> func4(int x, int n) {\n",
    "            std::vector<std::vector<int>> ans; std::vector<int> ans1, ans2;\n",
    "            for (int i = 0; i < n; i++) ans1.push_back(x+i);\n",
    "            for (int i = 0; i < n; i++) ans2.push_back(x+i*2);\n",
    "            ans.push_back(ans1); ans.push_back(ans2); return ans;\n",
    "        }\n",
    "        // complex string manipulation, splitting things like \"A,3\\\\nB,4\", std::vector<std::pair<std::string, int>>\n",
    "        std::vector<std::pair<std::string, int>> func5(std::string text) {\n",
    "            std::vector<std::pair<std::string, int>> ans; std::string line;\n",
    "            std::istringstream f(text); std::pair<std::string, int> pair;\n",
    "            while (std::getline(f, line)) {\n",
    "                int pos = line.find(\",\"); pair.first = line.substr(0, pos);\n",
    "                pair.second = std::stoi(line.substr(pos+1)); ans.push_back(pair);\n",
    "            } return ans;\n",
    "        }\n",
    "        \n",
    "        PYBIND11_MODULE(genM1, m) {\n",
    "            m.def(\"func1\", &func1); m.def(\"func2\", &func2); m.def(\"func3\", &func3);\n",
    "            m.def(\"func4\", &func4); m.def(\"func5\", &func5);\n",
    "    }\\\"\\\"\\\", \"genM1\", verbose=True) # this takes around 15s to run. Yes it's slow, but it works\n",
    "\n",
    "    # python-equivalent functions\n",
    "    def func1(x):\n",
    "        for i in range(1000000): x = math.cos(x)\n",
    "        return x\n",
    "    def func2(arr): return sum(arr)\n",
    "    def func3(x, n): return [x+i for i in range(n)]\n",
    "    def func4(x, n): return [[x+i for i in range(n)], [x+i*2 for i in range(n)]]\n",
    "    def func5(s): return [(x, int(y)) for x,y in [x.split(\",\") for x in s.split(\"\\\\n\")]]\n",
    "\n",
    "    mod.func1(3)     # 22.8 ms  1.83 ms, 7.6x faster\n",
    "    func1(3)         # 174 ms  24.1 ms\n",
    "\n",
    "    x = list(range(100))\n",
    "    mod.func2(x)     # 7.25 s  761 ns, 3.1x slower\n",
    "    func2(x)         # 2.33 s  299 ns\n",
    "    \n",
    "    mod.func3(3, 10) # 1.16 s  97 ns, 1.2x slower\n",
    "    func3(3, 10)     # 946 ns  128 ns\n",
    "\n",
    "    mod.func4(3, 10) # 2.23 s  188 ns, 1.25x faster\n",
    "    func4(3, 10)     # 2.78 s  292 ns\n",
    "\n",
    "    s = \"A,3\\\\nB,4\\\\nC,5\\\\nD,6\\\\nE,7\\\\nF,8\\\\nG,9\"\n",
    "    mod.func5(s)     # 4.5 s  286 ns, 1.07x faster\n",
    "    func5(s)         # 4.81 s  866 ns\n",
    "\n",
    "Behind the scenes, this function generates a C source file, compiles it into a\n",
    "python C extension module, then loads it in the current interpreter session. So\n",
    "purpose of this is to very quickly drop down to C whenever the need arises.\n",
    "Solutions like Cython is neat and all, but it's quite awkward to code in, and\n",
    "doesn't have the full power of C++. Meanwhile, doing it like this gives you full\n",
    "C++ features, as well as an easy python binding interface via pybind11.\n",
    "\n",
    "Several header files are included by default, so you don't have to include them, like\n",
    "<string>, <fstream>, etc. A list of them are in ``settings.cExt.includes``. You can\n",
    "get a dict of all compiled modules via ``k1.compileCExt.mods()``\n",
    "\n",
    "Also, as you can see from the tiny benchmark results, it's not always faster to use\n",
    "the C version, if input and output translation operations takes longer than the\n",
    "function itself. So although there's a lot of potential for speedups, you have to\n",
    "be really careful about this, or else you risk slowing it down and wasting a bunch\n",
    "of time.\n",
    "\n",
    ":param cppCode: C++ source code. Common headers are included\n",
    ":param moduleName: name of the module\"\"\"\n",
    "    # code mostly written by ChatGPT 4o. Verified to work tho\n",
    "    import pybind11; from setuptools import setup, Extension; from setuptools.command.build_ext import build_ext; import importlib.util; temp_dir = tempfile.mkdtemp()\n",
    "    print(f\"temp_dir: {temp_dir}\\n\" if verbose else \"\", end=\"\"); incls = k1.settings.cExt.includes | cli.apply(lambda x: f\"#include <{x}>\") | cli.join(\"\\n\")\n",
    "    cpp_file = f\"\"\"#include <pybind11/pybind11.h>\\n#include <pybind11/stl.h>\\nnamespace py = pybind11;\\n{incls}\\n\"\"\" + cppCode | cli.file(os.path.join(temp_dir, f\"{moduleName}.cpp\"))\n",
    "    ext_modules = [Extension(moduleName, sources=[cpp_file], include_dirs=[pybind11.get_include()], language=\"c++\", extra_compile_args=[\"-O3\", \"-std=c++17\"])]\n",
    "    class BuildExt(build_ext):\n",
    "        def run(self): build_ext.run(self)\n",
    "        def build_extension(self, ext): ext_path = self.get_ext_fullpath(ext.name); os.makedirs(os.path.dirname(ext_path), exist_ok=True); build_ext.build_extension(self, ext)\n",
    "    with (idenContext() if verbose else k1.captureStdout()):\n",
    "        setup(name=moduleName, ext_modules=ext_modules, cmdclass={\"build_ext\": BuildExt}, script_args=[\"build_ext\", \"--inplace\"], options={\"build_ext\": {\"build_lib\": temp_dir}}); so_file = temp_dir | cli.ls() | cli.grep(\"cpython\") | cli.item()\n",
    "        spec = importlib.util.spec_from_file_location(moduleName, so_file); module = importlib.util.module_from_spec(spec); spec.loader.exec_module(module); _cextMods[moduleName] = module; return module\n",
    "compileCExt.mods = _cextMods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46c38147-3be5-45d1-a4d6-85d911ec1314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp_dir: /tmp/tmp40bnre6w\n",
      "CPU times: user 421 ms, sys: 219 ms, total: 640 ms\n",
      "Wall time: 16.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mod = compileCExt(\"\"\"\n",
    "// pure math func, simple data types\n",
    "double func1(double x) { for (int i = 0; i < 1000000; i++) x = std::cos(x); return x; }\n",
    "// takes in array\n",
    "double func2(std::vector<double>& arr) { double sum = 0; for (auto v : arr) sum += v; return sum; }\n",
    "// returns array\n",
    "std::vector<int> func3(int x, int n) { std::vector<int> ans; for (int i = 0; i < n; i++) ans.push_back(x+i); return ans; }\n",
    "// nested arrays\n",
    "std::vector<std::vector<int>> func4(int x, int n) {\n",
    "    std::vector<std::vector<int>> ans; std::vector<int> ans1, ans2;\n",
    "    for (int i = 0; i < n; i++) ans1.push_back(x+i);\n",
    "    for (int i = 0; i < n; i++) ans2.push_back(x+i*2);\n",
    "    ans.push_back(ans1); ans.push_back(ans2); return ans;\n",
    "}\n",
    "// complex string manipulation, splitting things like \"A,3\\\\nB,4\", std::vector<std::pair<std::string, int>>\n",
    "std::vector<std::pair<std::string, int>> func5(std::string text) {\n",
    "    std::vector<std::pair<std::string, int>> ans; std::string line;\n",
    "    std::istringstream f(text); std::pair<std::string, int> pair;\n",
    "    while (std::getline(f, line)) {\n",
    "        int pos = line.find(\",\"); pair.first = line.substr(0, pos);\n",
    "        pair.second = std::stoi(line.substr(pos+1)); ans.push_back(pair);\n",
    "    } return ans;\n",
    "}\n",
    "\n",
    "PYBIND11_MODULE(genM1, m) {\n",
    "    m.def(\"func1\", &func1); m.def(\"func2\", &func2); m.def(\"func3\", &func3);\n",
    "    m.def(\"func4\", &func4); m.def(\"func5\", &func5);\n",
    "}\"\"\", \"genM1\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f4ed4af-fe1a-4939-867d-1c68e3276c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func1(x):\n",
    "    for i in range(1000000): x = math.cos(x)\n",
    "    return x\n",
    "assert mod.func1(3) == func1(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a932459-8ab5-4d75-8c42-fbfbf2008599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.8 ms  1.83 ms per loop (mean  std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "mod.func1(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e1965d4-688a-4a58-9119-e05e59d31f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174 ms  24.1 ms per loop (mean  std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "func1(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f59677e-340f-4bee-b944-4cae5eb5bd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func2(arr): return sum(arr)\n",
    "arr = list(range(100)); assert mod.func2(arr) == func2(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61785d3e-9478-4ed6-be36-1ab6e16d8800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.25 s  761 ns per loop (mean  std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "mod.func2(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eaa9b09d-d87f-4f79-98b6-eff9b647eb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.33 s  299 ns per loop (mean  std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "func2(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47fc54f4-9e5f-4ee2-9f92-c553a672f0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func3(x, n): return [x+i for i in range(n)]\n",
    "assert mod.func3(3, 10) == func3(3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63f0341a-c0d4-427b-8bc6-1090f062c812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.16 s  97 ns per loop (mean  std. dev. of 7 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "mod.func3(3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd8442a4-74b1-4c78-b108-aaa7a69ba1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "946 ns  128 ns per loop (mean  std. dev. of 7 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "func3(3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "36baa5f8-3862-4150-9108-d258fd7e009c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func4(x, n): return [[x+i for i in range(n)], [x+i*2 for i in range(n)]]\n",
    "assert mod.func4(3, 10) == func4(3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dede3716-ee82-4eb3-b193-e2855fdb3e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.23 s  188 ns per loop (mean  std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "mod.func4(3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69b34816-c7a3-42e1-81ea-dbc5b1eac906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.78 s  292 ns per loop (mean  std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "func4(3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "519e98d5-a8b1-41a9-83d4-6c3dd51bf3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func5(s): return [(x, int(y)) for x,y in [x.split(\",\") for x in s.split(\"\\n\")]]\n",
    "s = \"A,3\\nB,4\\nC,5\\nD,6\\nE,7\\nF,8\\nG,9\"; assert mod.func5(s) == func5(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3c1fb680-4cd1-4a4b-b893-7781a4380347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5 s  286 ns per loop (mean  std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "mod.func5(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02175e6d-570b-4841-8661-9e3c6d14ecff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.81 s  866 ns per loop (mean  std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "func5(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a8dc47-d0d9-4572-b6a1-8f7e16227623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ec5484-98a3-47ad-b313-95d29ae8af7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "340e431e-1a95-4fdc-a905-50c79563d01f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./export started up - /home/quang/miniforge3/bin/python\n",
      "----- exportAll\n",
      "17034   0   60%   \n",
      "11269   1   40%   \n",
      "installing...\n",
      "Found existing installation: k1lib 1.8\n",
      "Uninstalling k1lib-1.8:\n",
      "  Successfully uninstalled k1lib-1.8\n",
      "\u001b[33mDEPRECATION: Loading egg at /home/quang/miniforge3/lib/python3.12/site-packages/aigu-0.1-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, http://10.104.0.3:3141/\n",
      "Processing /home/quang/k1lib\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14 in /home/quang/miniforge3/lib/python3.12/site-packages (from k1lib==1.8) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=2.0 in /home/quang/miniforge3/lib/python3.12/site-packages (from k1lib==1.8) (3.9.2)\n",
      "Requirement already satisfied: dill in /home/quang/miniforge3/lib/python3.12/site-packages (from k1lib==1.8) (0.3.8)\n",
      "Requirement already satisfied: forbiddenfruit in /home/quang/miniforge3/lib/python3.12/site-packages (from k1lib==1.8) (0.1.4)\n",
      "Requirement already satisfied: wurlitzer in /home/quang/miniforge3/lib/python3.12/site-packages (from k1lib==1.8) (3.1.1)\n",
      "Requirement already satisfied: validators in /home/quang/miniforge3/lib/python3.12/site-packages (from k1lib==1.8) (0.34.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/quang/miniforge3/lib/python3.12/site-packages (from matplotlib>=2.0->k1lib==1.8) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/quang/miniforge3/lib/python3.12/site-packages (from matplotlib>=2.0->k1lib==1.8) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/quang/miniforge3/lib/python3.12/site-packages (from matplotlib>=2.0->k1lib==1.8) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/quang/miniforge3/lib/python3.12/site-packages (from matplotlib>=2.0->k1lib==1.8) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/quang/miniforge3/lib/python3.12/site-packages (from matplotlib>=2.0->k1lib==1.8) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /home/quang/miniforge3/lib/python3.12/site-packages (from matplotlib>=2.0->k1lib==1.8) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/quang/miniforge3/lib/python3.12/site-packages (from matplotlib>=2.0->k1lib==1.8) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/quang/miniforge3/lib/python3.12/site-packages (from matplotlib>=2.0->k1lib==1.8) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/quang/miniforge3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=2.0->k1lib==1.8) (1.16.0)\n",
      "Building wheels for collected packages: k1lib\n",
      "  Building wheel for k1lib (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for k1lib: filename=k1lib-1.8-py3-none-any.whl size=5145459 sha256=f6c9d35cec912a76e8a535a511517291f20de84515d7523cdfcac664aa536b75\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-21_gp2hr/wheels/b5/32/67/e20c84dce16d707fb881c12d405f70adfaa36fe7dae9021380\n",
      "Successfully built k1lib\n",
      "Installing collected packages: k1lib\n",
      "Successfully installed k1lib-1.8\n",
      "installed\n",
      "uploading...\n",
      "uploaded\n"
     ]
    }
   ],
   "source": [
    "!../export.py _advanced --upload=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "10a2655d-8df6-43fb-b498-2eb75d078f03",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/quang/k1lib/k1lib/../export.py\", line 7, in <module>\n",
      "    import json, fire, os, re, warnings, traceback, sys\n",
      "  File \"/home/quang/miniforge3/lib/python3.12/site-packages/fire/__init__.py\", line 21, in <module>\n",
      "    from fire.core import Fire\n",
      "  File \"/home/quang/miniforge3/lib/python3.12/site-packages/fire/core.py\", line 74, in <module>\n",
      "    from fire.console import console_io\n",
      "  File \"/home/quang/miniforge3/lib/python3.12/site-packages/fire/console/console_io.py\", line 27, in <module>\n",
      "    from fire.console import console_attr\n",
      "  File \"/home/quang/miniforge3/lib/python3.12/site-packages/fire/console/console_attr.py\", line 99, in <module>\n",
      "    from fire.console import console_attr_os\n",
      "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1322, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 1262, in _find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1528, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1502, in _get_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1601, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 147, in _path_stat\n",
      "KeyboardInterrupt\n",
      "Error in callback <function _draw_all_if_interactive at 0x7fc141fa79c0> (for post_execute), with arguments args (),kwargs {}:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!../export.py _advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dcca3901-c517-4825-8467-c3bf9fed2d49",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./export started up - /home/quang/miniforge3/bin/python\n",
      "----- bootstrapping\n",
      "Current dir: /home/quang/k1lib, /home/quang/k1lib/k1lib/../export.py\n",
      "installing...\n",
      "Found existing installation: k1lib 1.8\n",
      "Uninstalling k1lib-1.8:\n",
      "  Successfully uninstalled k1lib-1.8\n",
      "\u001b[33mDEPRECATION: Loading egg at /home/quang/miniforge3/lib/python3.12/site-packages/aigu-0.1-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, http://10.104.0.3:3141/\n",
      "Processing /home/quang/k1lib\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14 in /home/quang/miniforge3/lib/python3.12/site-packages (from k1lib==1.8) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=2.0 in /home/quang/miniforge3/lib/python3.12/site-packages (from k1lib==1.8) (3.9.2)\n",
      "Requirement already satisfied: dill in /home/quang/miniforge3/lib/python3.12/site-packages (from k1lib==1.8) (0.3.8)\n",
      "Requirement already satisfied: forbiddenfruit in /home/quang/miniforge3/lib/python3.12/site-packages (from k1lib==1.8) (0.1.4)\n",
      "Requirement already satisfied: wurlitzer in /home/quang/miniforge3/lib/python3.12/site-packages (from k1lib==1.8) (3.1.1)\n",
      "Requirement already satisfied: validators in /home/quang/miniforge3/lib/python3.12/site-packages (from k1lib==1.8) (0.34.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/quang/miniforge3/lib/python3.12/site-packages (from matplotlib>=2.0->k1lib==1.8) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/quang/miniforge3/lib/python3.12/site-packages (from matplotlib>=2.0->k1lib==1.8) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/quang/miniforge3/lib/python3.12/site-packages (from matplotlib>=2.0->k1lib==1.8) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/quang/miniforge3/lib/python3.12/site-packages (from matplotlib>=2.0->k1lib==1.8) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/quang/miniforge3/lib/python3.12/site-packages (from matplotlib>=2.0->k1lib==1.8) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /home/quang/miniforge3/lib/python3.12/site-packages (from matplotlib>=2.0->k1lib==1.8) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/quang/miniforge3/lib/python3.12/site-packages (from matplotlib>=2.0->k1lib==1.8) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/quang/miniforge3/lib/python3.12/site-packages (from matplotlib>=2.0->k1lib==1.8) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/quang/miniforge3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=2.0->k1lib==1.8) (1.16.0)\n",
      "Building wheels for collected packages: k1lib\n",
      "  Building wheel for k1lib (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for k1lib: filename=k1lib-1.8-py3-none-any.whl size=5135457 sha256=835a5c176fde2d4187d5dedf9e95613cccd2603439893134abdebb5d3f04bcf2\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-tulwy2kl/wheels/b5/32/67/e20c84dce16d707fb881c12d405f70adfaa36fe7dae9021380\n",
      "Successfully built k1lib\n",
      "Installing collected packages: k1lib\n",
      "Successfully installed k1lib-1.8\n",
      "installed\n"
     ]
    }
   ],
   "source": [
    "!../export.py _advanced --bootstrap=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4be377-a8d2-41d5-9129-421e4ffaa154",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

# AUTOGENERATED FILE! PLEASE DON'T EDIT
from k1lib.callbacks import Callback, Callbacks
import k1lib
@k1lib.patch(Callback.cls)
class BatchLimit(Callback):
    """Cancels the epoch after executed certain number of batches"""
    def __init__(self, limit):
        super().__init__()
        self.limit = limit if limit != None else float("inf")
    def startEpoch(self):
        self.currentBatch = 0
    def startBatch(self):
        if self.currentBatch >= self.limit:
            raise k1lib.CancelEpochException()
    def endBatch(self):
        self.currentBatch += 1
@k1lib.patch(Callbacks, docs=BatchLimit)
def withBatchLimit(self, limit, name=None): return self.append(BatchLimit(limit), name)
@k1lib.patch(Callback.cls)
class EpochLimit(Callback):
    """Cancels the run after executed certain number of epochs"""
    def __init__(self, limit):
        super().__init__()
        self.limit = limit if limit != None else float("inf")
    def startRun(self):
        self.currentEpoch = 0
    def startEpoch(self):
        if self.currentEpoch >= self.limit:
            raise k1lib.CancelRunException()
    def endEpoch(self):
        self.currentEpoch += 1
@k1lib.patch(Callbacks, docs=EpochLimit)
def withEpochLimit(self, limit, name=None): return self.append(EpochLimit(limit), name)
@k1lib.patch(Callback.cls)
class CancelOnExplosion(Callback):
    """Cancels the run if any of the parameters are larger than a certain limit"""
    def __init__(self, limit=1e6):
        super().__init__()
        self.order = 18; self.limit = limit
        self.progress = 0; self.triggered = False
    def startRun(self): self.triggered = False
    def startBatch(self):
        self.progress = self.learner.progress
        for p in self.model.parameters():
            o = p.detach()
            if o.max() > self.limit or o.min() < -self.limit:
                self.triggered = True
                raise k1lib.CancelRunException("Explosion detected!")
    def __repr__(self):
        return f"""{self._reprHead}, use...
- cb.triggered: to see if there was an explosion on the last run
- cb.progress: to see current progress at explosion time
{self._reprCan}"""
@k1lib.patch(Callbacks, docs=CancelOnExplosion)
def withCancelOnExplosion(self, limit=1e6):
    return self.append(CancelOnExplosion(limit))
@k1lib.patch(Callback.cls)
class CancelOnLowLoss(Callback):
    """Cancels the run if loss is lower than amount specified.
Args:
    loss (float): <obv>
    epochMode (bool): false if use batch loss, true if use valid epoch loss"""
    def __init__(self, loss, epochMode=False):
        super().__init__()
        self.loss = loss
        self.epochMode = epochMode
    def endBatch(self):
        if self.epochMode:
            if not hasattr(self, "Loss"): return
            data = self.Loss.epoch.valid
            if len(data) > 0 and data[-1] < self.loss:
                raise k1lib.CancelRunException(f"Low loss {self.loss} achieved!")
        elif self.learner.loss < self.loss:
            raise k1lib.CancelRunException(f"Low loss {self.loss} achieved!")
@k1lib.patch(Callbacks, docs=CancelOnLowLoss)
def withCancelOnLowLoss(self, loss, epochMode=False):
    return self.append(CancelOnLowLoss(loss, epochMode))
@k1lib.patch(Callback.cls)
class DontTrain(Callback):
    def startBackward(self): return True
    def startStep(self): return True
@k1lib.patch(Callbacks)
def withDontTrain(self, name=None): return self.append(DontTrain(), name)